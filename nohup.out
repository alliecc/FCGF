./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22
Host:  bb8
Conda  /home/allie/miniconda3/bin/conda
/home/allie/code/benchmark/FCGF
Version:  5002ea8a5a10230c9c771aa8ac7991fcc03b0502
Git diff

diff --git a/lib/data_loaders.py b/lib/data_loaders.py
index e0e264d..e40a571 100644
--- a/lib/data_loaders.py
+++ b/lib/data_loaders.py
@@ -692,7 +692,7 @@ class KITTIMapDataset(PairDataset):
         self.split = phase
         self.config = config
 
-        self.path_map_dict = os.path.join(root, "kitti_map_files_d3feat_%s.pkl" % self.split)
+        self.path_map_dict = os.path.join(root, "kitti_map_files_d3feat_%s_fcgf.pkl" % self.split)
         self.read_map_data()
         self.prepare_kitti_ply()#split=split)
        
@@ -712,10 +712,10 @@ class KITTIMapDataset(PairDataset):
         for id_log in subset_names:
             path_map = os.path.join(self.root, "kitti_maps_cmr_new", "map-%02d_0.05.ply" % (int(id_log)))
             print("Load map : ", path_map)
-            pcd = open3d.io.read_point_cloud(path_map)
-            pcd = pcd.voxel_down_sample(self.config.first_subsampling_dl)
-            pcd, ind = pcd.remove_radius_outlier(nb_points=7, radius=self.config.first_subsampling_dl*2)
-            self.dict_maps[id_log] = torch.Tensor(np.asarray(pcd.points))#.to(self.config.device)
+            pcd = o3d.io.read_point_cloud(path_map)
+            pcd = pcd.voxel_down_sample(self.config.voxel_size)
+            pcd, ind = pcd.remove_radius_outlier(nb_points=7, radius=self.config.voxel_size*2)
+            self.dict_maps[id_log] = np.asarray(pcd.points)#torch.Tensor(np.asarray(pcd.points))#.to(self.config.device)
 
 
         with open(self.path_map_dict, 'wb') as f: 
@@ -724,7 +724,7 @@ class KITTIMapDataset(PairDataset):
             print('Saved!')    
 
     def get_local_map(self,T_lidar, drive):#, force_select_points=False):
-        dist = torch.sqrt(((self.dict_maps[drive] - T_lidar[0:3,3])**2).sum(axis=1))
+        dist = np.sqrt(((self.dict_maps[drive] - T_lidar[0:3,3])**2).sum(axis=1))
         ind_valid_local = dist < self.config.depth_max
 
         return self.dict_maps[drive][ind_valid_local]
@@ -780,7 +780,7 @@ class KITTIMapDataset(PairDataset):
             xyz1 = scale * xyz1
 
         # Voxelization
-        xyz0_th = xyz0#torch.from_numpy(xyz0)
+        xyz0_th = torch.from_numpy(xyz0)#xyz0#torch.from_numpy(xyz0)
         xyz1_th = torch.from_numpy(xyz1)
     
         sel0 = ME.utils.sparse_quantize(xyz0_th / self.voxel_size, return_index=True)
@@ -792,8 +792,8 @@ class KITTIMapDataset(PairDataset):
     
         # Get matches
         matches = get_matching_indices(pcd0, pcd1, trans, matching_search_voxel_size)
-        #if len(matches) < 1000:
-        #  raise ValueError(f"{drive}, {t0}, {t1}")
+        if len(matches) < 1000:
+            raise ValueError(f"{drive}, {idx}")
         #matches = np.array(matches)
 
 
@@ -818,8 +818,9 @@ class KITTIMapDataset(PairDataset):
         #print("single batch = ")
         #print(coords0.shape)
         #print(coords1.shape)
-        #print(len(matches) )        
+           
         if False:#len(matches) < 10:#coords0.shape[0] < 10 or coords1.shape[0] < 10:
+            print("num matches = ", len(matches) )     
             #print("matches shape = ", matches.shape)
 
             print(coords0)
@@ -850,7 +851,7 @@ class KITTIMapDataset(PairDataset):
             o3d.io.write_point_cloud("unique_xyz0_th_trans_%d.ply" % idx, pcd_target) 
 #    
 
-            #import pdb; pdb.set_trace()
+            import pdb; pdb.set_trace()
             #pcd_target = o3d.geometry.PointCloud()
             #pcd_target.points = o3d.utility.Vector3dVector(coords0)
             #o3d.io.write_point_cloud("coords0.ply" , pcd_target) 
diff --git a/lib/trainer.py b/lib/trainer.py
index e6299f8..fbb110f 100644
--- a/lib/trainer.py
+++ b/lib/trainer.py
@@ -332,7 +332,7 @@ class ContrastiveLossTrainer(AlignmentTrainer):
 
       matching_timer.tic()
       xyz0, xyz1, T_gt = input_dict['pcd0'], input_dict['pcd1'], input_dict['T_gt']
-      xyz0_corr, xyz1_corr = self.find_corr(xyz0, xyz1, F0, F1, subsample_size=5000)
+      xyz0_corr, xyz1_corr = self.find_corr(xyz0, xyz1, F0, F1, subsample_size=10000)#5000)
       T_est = te.est_quad_linear_robust(xyz0_corr, xyz1_corr)
 
       loss = corr_dist(T_est, T_gt, xyz0, xyz1, weight=None)
@@ -484,7 +484,6 @@ class HardestContrastiveLossTrainer(ContrastiveLossTrainer):
             coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
 
         F1 = self.model(sinput1).F
-
         pos_pairs = input_dict['correspondences']
         pos_loss, neg_loss = self.contrastive_hardest_negative_loss(
             F0,
diff --git a/nohup.out b/nohup.out
index 887d1c2..875f981 100644
--- a/nohup.out
+++ b/nohup.out
@@ -1,1504 +1,95 @@
-./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b8i1-modelnout16/2020-11-02_17-08-48
+./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22
 Host:  bb8
-Conda  /home/allie/miniconda3/condabin/conda
+Conda  /home/allie/miniconda3/bin/conda
 /home/allie/code/benchmark/FCGF
-Version:  f0863a9ba4a29f677c0ddd2248cf4e56b9318add
+Version:  5002ea8a5a10230c9c771aa8ac7991fcc03b0502
 Git diff
 
-diff --git a/config.py b/config.py
-index 476402d..87abb73 100644
---- a/config.py
-+++ b/config.py
-@@ -112,14 +112,28 @@ data_arg.add_argument(
-     '--threed_match_dir', type=str, default="/home/chrischoy/datasets/FCGF/threedmatch")
- data_arg.add_argument(
-     '--kitti_root', type=str, default="/home/chrischoy/datasets/FCGF/kitti/")
-+
- data_arg.add_argument(
-     '--kitti_max_time_diff',
-     type=int,
-     default=3,
-     help='max time difference between pairs (non inclusive)')
-+
- data_arg.add_argument('--kitti_date', type=str, default='2011_09_26')
- 
- 
-+#arguments for KITTI map dataset
-+#for kitti ground truth poses (optimized by loop-closing SLAM)
-+data_arg.add_argument(
-+    '--path_cmrdata', type=str, default="/home/allie/dataset/cmr_original") 
-+data_arg.add_argument(
-+    '--depth_max', type=float, default=50) 
-+data_arg.add_argument(
-+    '--num_min_map_points', type=int, default=2e4) 
-+
-+
-+
-+
- def get_config():
-   args = parser.parse_args()
-   return args
 diff --git a/lib/data_loaders.py b/lib/data_loaders.py
-index 2bc475a..a45bee3 100644
+index e0e264d..e40a571 100644
 --- a/lib/data_loaders.py
 +++ b/lib/data_loaders.py
-@@ -18,10 +18,42 @@ import lib.transforms as t
- import MinkowskiEngine as ME
- 
- import open3d as o3d
-+import pickle
- 
- kitti_cache = {}
- kitti_icp_cache = {}
- 
-+eps = 1e-10
-+import csv
-+def read_csv_file(path_file):
-+    lines = []
-+    with open(path_file, "r") as f:
-+        reader = csv.reader(f, delimiter="\t")
-+        for i, line in enumerate(reader):
-+            if i >= 1:
-+                lines.append(np.asarray(line[0].split(',')[1:]).astype('float'))
-+    return lines
-+
-+
-+def pred_to_matrix_np(pred):
-+
-+    cam_T = np.tile(np.eye(4)[np.newaxis,:,:],[pred.shape[0], 1, 1])
-+    cam_T[:,0:3, 3] = pred[:, 0:3]
-+    s = np.tile(np.linalg.norm(pred[:,3:], axis=1)[:,np.newaxis],[1,4])
-+
-+    q = pred[:,3:] / (s+eps)
-+
-+    cam_T[:,0,0] = 1- 2*s[:,0]*(q[:,2]**2 + q[:,3]**2)
-+    cam_T[:,0,1] = 2   *s[:,0]*(q[:,1] * q[:,2] - q[:,3] * q[:,0])
-+    cam_T[:,0,2] = 2   *s[:,0]*(q[:,1] * q[:,3] + q[:,2] * q[:,0])
-+    cam_T[:,1,0] = 2   *s[:,0]*(q[:,1]*q[:,2] + q[:,3]*q[:,0])
-+    cam_T[:,1,1] = 1- 2*s[:,0]*(q[:,1]**2 + q[:,3]**2)
-+    cam_T[:,1,2] = 2   *s[:,0]*(q[:,2] * q[:,3] - q[:,1] * q[:,0])
-+    cam_T[:,2,0] = 2   *s[:,0]*(q[:,1] * q[:,3] - q[:,2] * q[:,0])
-+    cam_T[:,2,1] = 2   *s[:,0]*(q[:,2] * q[:,3] + q[:,1] * q[:,0])
-+    cam_T[:,2,2] = 1 -2*s[:,0]*(q[:,1]**2 + q[:,2]**2)
-+
-+    return cam_T
- 
- def collate_pair_fn(list_data):
-   xyz0, xyz1, coords0, coords1, feats0, feats1, matching_inds, trans = list(
-@@ -632,8 +664,278 @@ class ThreeDMatchPairDataset(IndoorPairDataset):
-       'test': './config/test_3dmatch.txt'
-   }
- 
-+class KITTIMapDataset(PairDataset):
-+    AUGMENT = None
-+    DATA_FILES = {
-+        'train': './config/train_kitti_map.txt', #log ids
-+        'val': './config/val_kitti_map.txt',
-+        'test': './config/test_kitti_map.txt'
-+    }
-+    TEST_RANDOM_ROTATION = False
-+    IS_ODOMETRY = True
-+    #MAX_TIME_DIFF = 3
-+
-+    def __init__(self,
-+               phase,
-+               transform=None,
-+               random_rotation=True,
-+               random_scale=True,
-+               manual_seed=False,
-+               config=None):
-+
-+
-+    #(self, root, split, config, input_threads=8, first_subsampling_dl=0.30):#, load_test=False):
-+        
-+        PairDataset.__init__(self, phase, transform, random_rotation, random_scale,
-+                         manual_seed, config)
-+
-+        self.root = root = os.path.join(config.kitti_root, 'dataset')
-+        self.split = phase
-+        self.config = config
-+
-+        self.path_map_dict = os.path.join(root, "kitti_map_files_d3feat_%s.pkl" % self.split)
-+        self.read_map_data()
-+        self.prepare_kitti_ply()#split=split)
-+       
-+
-+    def __len__(self):
-+        return self.num
-+
-+    def read_map_data(self):
-+        if os.path.exists(self.path_map_dict):
-+            with open(self.path_map_dict, 'rb') as f:
-+                self.dict_maps = pickle.load(f)
-+            return 
-+
-+
-+        subset_names = open(self.DATA_FILES[self.split]).read().split()
-+        self.dict_maps = {}
-+        for id_log in subset_names:
-+            path_map = os.path.join(self.root, "kitti_maps_cmr_new", "map-%02d_0.05.ply" % (int(id_log)))
-+            print("Load map : ", path_map)
-+            pcd = open3d.io.read_point_cloud(path_map)
-+            pcd = pcd.voxel_down_sample(self.config.first_subsampling_dl)
-+            pcd, ind = pcd.remove_radius_outlier(nb_points=7, radius=self.config.first_subsampling_dl*2)
-+            self.dict_maps[id_log] = torch.Tensor(np.asarray(pcd.points))#.to(self.config.device)
-+
-+
-+        with open(self.path_map_dict, 'wb') as f: 
-+            print('Saving map file to ', self.path_map_dict)
-+            pickle.dump(self.dict_maps, f)
-+            print('Saved!')    
-+
-+    def get_local_map(self,T_lidar, drive):#, force_select_points=False):
-+        dist = torch.sqrt(((self.dict_maps[drive] - T_lidar[0:3,3])**2).sum(axis=1))
-+        ind_valid_local = dist < self.config.depth_max
-+
-+        return self.dict_maps[drive][ind_valid_local]
-+
-+            
-+    def prepare_kitti_ply(self):#, split='train'):
-+        #max_time_diff = self.MAX_TIME_DIFF
-+        subset_names = open(self.DATA_FILES[self.split]).read().split()
-+        self.all_pos = []
-+        for dirname in subset_names:
-+            drive_id = int(dirname)
-+            fnames = glob.glob(self.root + '/sequences/%02d/velodyne/*.bin' % drive_id)
-+
-+            assert len(fnames) > 0, f"Make sure that the path {self.root} has data {dirname}"
-+            inames = sorted([int(os.path.split(fname)[-1][:-4]) for fname in fnames])
-+            path_poses = os.path.join(self.config.path_cmrdata, self.split, "kitti-%02d.csv" % drive_id)
-+            list_gt_poses = read_csv_file(path_poses)
-+
-+            for i in range(0,len(inames),2):# curr_time in inames:
-+                
-+
-+                T = pred_to_matrix_np(np.asarray(list_gt_poses[i][np.newaxis,[0,1,2,6,3,4,5]]))[0]
-+                xyz0 = self.get_local_map(T, dirname)
-+
-+                #use the local map as the source
-+                T = np.linalg.inv(T) 
-+                if xyz0.shape[0] < self.config.num_min_map_points:
-+                    continue
-+                
-+                self.files.append((drive_id, inames[i]))#, next_time))
-+                self.all_pos.append( torch.Tensor(T))#.to(self.config.device))
-+        self.num = len(self.files)
-+
-+    def __getitem__(self,idx):# split, idx):
-+        drive = self.files[idx][0]
-+        #t0, t1 = self.files[self.split][idx][1], self.files[self.split][idx][2]
-+
-+        #LiDAR is the target
-+        fname1 = self._get_velodyne_fn(drive,  self.files[idx][1])
-+        xyzr1 = np.fromfile(fname1, dtype=np.float32).reshape(-1, 4) 
-+        xyz1 = xyzr1[:, :3]
-+        
-+        #map is the source
-+        xyz0 = self.get_local_map( np.linalg.inv(self.all_pos[idx]), str(drive))
-+        trans = self.all_pos[idx]# M2
-+
-+        matching_search_voxel_size = self.matching_search_voxel_size
-+        if self.random_scale and random.random() < 0.95:
-+            scale = self.min_scale + \
-+                (self.max_scale - self.min_scale) * random.random()
-+            matching_search_voxel_size *= scale
-+            xyz0 = scale * xyz0
-+            xyz1 = scale * xyz1
-+
-+        # Voxelization
-+        xyz0_th = xyz0#torch.from_numpy(xyz0)
-+        xyz1_th = torch.from_numpy(xyz1)
-+    
-+        sel0 = ME.utils.sparse_quantize(xyz0_th / self.voxel_size, return_index=True)
-+        sel1 = ME.utils.sparse_quantize(xyz1_th / self.voxel_size, return_index=True)
-+    
-+        # Make point clouds using voxelized points
-+        pcd0 = make_open3d_point_cloud(xyz0[sel0])
-+        pcd1 = make_open3d_point_cloud(xyz1[sel1])
-+    
-+        # Get matches
-+        matches = get_matching_indices(pcd0, pcd1, trans, matching_search_voxel_size)
-+        #if len(matches) < 1000:
-+        #  raise ValueError(f"{drive}, {t0}, {t1}")
-+        matches = np.array(matches)
-+
-+
-+        # Get features
-+        npts0 = len(sel0)
-+        npts1 = len(sel1)
-+    
-+        feats_train0, feats_train1 = [], []
-+    
-+        unique_xyz0_th = xyz0_th[sel0]
-+        unique_xyz1_th = xyz1_th[sel1]
-+    
-+        feats_train0.append(torch.ones((npts0, 1)))
-+        feats_train1.append(torch.ones((npts1, 1)))
-+    
-+        feats0 = torch.cat(feats_train0, 1)
-+        feats1 = torch.cat(feats_train1, 1)
-+    
-+        coords0 = torch.floor(unique_xyz0_th / self.voxel_size)
-+        coords1 = torch.floor(unique_xyz1_th / self.voxel_size)
-+ 
-+        #print("matches shape = ", matches.shape)
-+        #print(coords0.shape)
-+        #print(coords1.shape)
-+        #print(coords0)
-+#
-+#
-+        #pcd_target = o3d.geometry.PointCloud()
-+        #pcd_target.points = o3d.utility.Vector3dVector(coords0)
-+        #o3d.io.write_point_cloud("coords0_before.ply" , pcd_target) 
-+#
-+        #pcd_target = o3d.geometry.PointCloud()
-+        #pcd_target.points = o3d.utility.Vector3dVector(coords1)
-+        #o3d.io.write_point_cloud("coords1_before.ply" , pcd_target) 
-+#
-+
-+        if self.transform:
-+          coords0, feats0 = self.transform(coords0, feats0)
-+          coords1, feats1 = self.transform(coords1, feats1)
-+    
-+        
-+        #pcd_target = o3d.geometry.PointCloud()
-+        #pcd_target.points = o3d.utility.Vector3dVector(coords0)
-+        #o3d.io.write_point_cloud("coords0.ply" , pcd_target) 
-+#
-+        #pcd_target = o3d.geometry.PointCloud()
-+        #pcd_target.points = o3d.utility.Vector3dVector(coords1)
-+        #o3d.io.write_point_cloud("coords1.ply" , pcd_target) 
-+#
-+#
-+
-+
-+        return (unique_xyz0_th.float(), unique_xyz1_th.float(), coords0.int(),
-+                coords1.int(), feats0.float(), feats1.float(), matches, trans)
-+    
-+            #return (anc_points, pos_points, unaligned_anc_points, unaligned_pos_points, matches, trans, True)
-+
-+    #def apply_transform(self, pts, trans):
-+    #    R = trans[:3, :3]
-+    #    T = trans[:3, 3]
-+    #    pts = pts @ R.T + T
-+    #    return pts
-+#
-+    #@property
-+    #def velo2cam(self):
-+    #    try:
-+    #        velo2cam = self._velo2cam
-+    #    except AttributeError:
-+    #        R = np.array([
-+    #            7.533745e-03, -9.999714e-01, -6.166020e-04, 1.480249e-02, 7.280733e-04,
-+    #            -9.998902e-01, 9.998621e-01, 7.523790e-03, 1.480755e-02
-+    #        ]).reshape(3, 3)
-+    #        T = np.array([-4.069766e-03, -7.631618e-02, -2.717806e-01]).reshape(3, 1)
-+    #        velo2cam = np.hstack([R, T])
-+    #        self._velo2cam = np.vstack((velo2cam, [0, 0, 0, 1])).T
-+    #    return self._velo2cam
-+#
-+    #def get_video_odometry(self, drive, indices=None, ext='.txt', return_all=False):
-+    #    if self.IS_ODOMETRY:
-+    #        data_path = self.root + '/poses/%02d.txt' % drive
-+    #        if data_path not in kitti_cache:
-+    #            kitti_cache[data_path] = np.genfromtxt(data_path)
-+    #        if return_all:
-+    #            return kitti_cache[data_path]
-+    #        else:
-+    #            return kitti_cache[data_path][indices]
-+    #    else:
-+    #        data_path = self.root + '/' + self.date + '_drive_%04d_sync/oxts/data' % drive
-+    #        odometry = []
-+    #        if indices is None:
-+    #            fnames = glob.glob(self.root + '/' + self.date +
-+    #                               '_drive_%04d_sync/velodyne_points/data/*.bin' % drive)
-+    #            indices = sorted([int(os.path.split(fname)[-1][:-4]) for fname in fnames])
-+#
-+    #        for index in indices:
-+    #            filename = os.path.join(data_path, '%010d%s' % (index, ext))
-+    #            if filename not in kitti_cache:
-+    #                kitti_cache[filename] = np.genfromtxt(filename)
-+    #                odometry.append(kitti_cache[filename])
-+#
-+    #        odometry = np.array(odometry)
-+    #        return odometry
-+#
-+    #def odometry_to_positions(self, odometry):
-+    #    if self.IS_ODOMETRY:
-+    #        T_w_cam0 = odometry.reshape(3, 4)
-+    #        T_w_cam0 = np.vstack((T_w_cam0, [0, 0, 0, 1]))
-+    #        return T_w_cam0
-+    #    else:
-+    #        lat, lon, alt, roll, pitch, yaw = odometry.T[:6]
-+#
-+    #        R = 6378137  # Earth's radius in metres
-+#
-+    #        # convert to metres
-+    #        lat, lon = np.deg2rad(lat), np.deg2rad(lon)
-+    #        mx = R * lon * np.cos(lat)
-+    #        my = R * lat
-+#
-+    #        times = odometry.T[-1]
-+    #        return np.vstack([mx, my, alt, roll, pitch, yaw, times]).T
-+#
-+    def _get_velodyne_fn(self, drive, t):
-+        if self.IS_ODOMETRY:
-+            fname = self.root + '/sequences/%02d/velodyne/%06d.bin' % (drive, t)
-+        else:
-+            fname = self.root + \
-+                    '/' + self.date + '_drive_%04d_sync/velodyne_points/data/%010d.bin' % (
-+                        drive, t)
-+        return fname
-+
-+    #def get_position_transform(self, pos0, pos1, invert=False):
-+    #    T0 = self.pos_transform(pos0)
-+    #    T1 = self.pos_transform(pos1)
-+    #    return (np.dot(T1, np.linalg.inv(T0)).T if not invert else np.dot(
-+    #        np.linalg.inv(T1), T0).T)
-+#
-+
-+
-+
- 
--ALL_DATASETS = [ThreeDMatchPairDataset, KITTIPairDataset, KITTINMPairDataset]
-+ALL_DATASETS = [ThreeDMatchPairDataset, KITTIPairDataset, KITTINMPairDataset, KITTIMapDataset]
- dataset_str_mapping = {d.__name__: d for d in ALL_DATASETS}
- 
- 
+@@ -692,7 +692,7 @@ class KITTIMapDataset(PairDataset):
+         self.split = phase
+         self.config = config
+ 
+-        self.path_map_dict = os.path.join(root, "kitti_map_files_d3feat_%s.pkl" % self.split)
++        self.path_map_dict = os.path.join(root, "kitti_map_files_d3feat_%s_fcgf.pkl" % self.split)
+         self.read_map_data()
+         self.prepare_kitti_ply()#split=split)
+        
+@@ -712,10 +712,10 @@ class KITTIMapDataset(PairDataset):
+         for id_log in subset_names:
+             path_map = os.path.join(self.root, "kitti_maps_cmr_new", "map-%02d_0.05.ply" % (int(id_log)))
+             print("Load map : ", path_map)
+-            pcd = open3d.io.read_point_cloud(path_map)
+-            pcd = pcd.voxel_down_sample(self.config.first_subsampling_dl)
+-            pcd, ind = pcd.remove_radius_outlier(nb_points=7, radius=self.config.first_subsampling_dl*2)
+-            self.dict_maps[id_log] = torch.Tensor(np.asarray(pcd.points))#.to(self.config.device)
++            pcd = o3d.io.read_point_cloud(path_map)
++            pcd = pcd.voxel_down_sample(self.config.voxel_size)
++            pcd, ind = pcd.remove_radius_outlier(nb_points=7, radius=self.config.voxel_size*2)
++            self.dict_maps[id_log] = np.asarray(pcd.points)#torch.Tensor(np.asarray(pcd.points))#.to(self.config.device)
+ 
+ 
+         with open(self.path_map_dict, 'wb') as f: 
+@@ -724,7 +724,7 @@ class KITTIMapDataset(PairDataset):
+             print('Saved!')    
+ 
+     def get_local_map(self,T_lidar, drive):#, force_select_points=False):
+-        dist = torch.sqrt(((self.dict_maps[drive] - T_lidar[0:3,3])**2).sum(axis=1))
++        dist = np.sqrt(((self.dict_maps[drive] - T_lidar[0:3,3])**2).sum(axis=1))
+         ind_valid_local = dist < self.config.depth_max
+ 
+         return self.dict_maps[drive][ind_valid_local]
+@@ -780,7 +780,7 @@ class KITTIMapDataset(PairDataset):
+             xyz1 = scale * xyz1
+ 
+         # Voxelization
+-        xyz0_th = xyz0#torch.from_numpy(xyz0)
++        xyz0_th = torch.from_numpy(xyz0)#xyz0#torch.from_numpy(xyz0)
+         xyz1_th = torch.from_numpy(xyz1)
+     
+         sel0 = ME.utils.sparse_quantize(xyz0_th / self.voxel_size, return_index=True)
+@@ -792,8 +792,8 @@ class KITTIMapDataset(PairDataset):
+     
+         # Get matches
+         matches = get_matching_indices(pcd0, pcd1, trans, matching_search_voxel_size)
+-        #if len(matches) < 1000:
+-        #  raise ValueError(f"{drive}, {t0}, {t1}")
++        if len(matches) < 1000:
++            raise ValueError(f"{drive}, {idx}")
+         #matches = np.array(matches)
+ 
+ 
+@@ -818,8 +818,9 @@ class KITTIMapDataset(PairDataset):
+         #print("single batch = ")
+         #print(coords0.shape)
+         #print(coords1.shape)
+-        #print(len(matches) )        
++           
+         if False:#len(matches) < 10:#coords0.shape[0] < 10 or coords1.shape[0] < 10:
++            print("num matches = ", len(matches) )     
+             #print("matches shape = ", matches.shape)
+ 
+             print(coords0)
+@@ -850,7 +851,7 @@ class KITTIMapDataset(PairDataset):
+             o3d.io.write_point_cloud("unique_xyz0_th_trans_%d.ply" % idx, pcd_target) 
+ #    
+ 
+-            #import pdb; pdb.set_trace()
++            import pdb; pdb.set_trace()
+             #pcd_target = o3d.geometry.PointCloud()
+             #pcd_target.points = o3d.utility.Vector3dVector(coords0)
+             #o3d.io.write_point_cloud("coords0.ply" , pcd_target) 
 diff --git a/lib/trainer.py b/lib/trainer.py
-index e4c230b..e6299f8 100644
+index e6299f8..fbb110f 100644
 --- a/lib/trainer.py
 +++ b/lib/trainer.py
-@@ -234,12 +234,12 @@ class ContrastiveLossTrainer(AlignmentTrainer):
-         # pairs consist of (xyz1 index, xyz0 index)
-         sinput0 = ME.SparseTensor(
-             input_dict['sinput0_F'].to(self.device),
--            coordinates=input_dict['sinput0_C'].to(self.device))
-+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
-         F0 = self.model(sinput0).F
- 
-         sinput1 = ME.SparseTensor(
-             input_dict['sinput1_F'].to(self.device),
--            coordinates=input_dict['sinput1_C'].to(self.device))
-+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
-         F1 = self.model(sinput1).F
- 
-         N0, N1 = len(sinput0), len(sinput1)
-@@ -316,14 +316,17 @@ class ContrastiveLossTrainer(AlignmentTrainer):
- 
-       # pairs consist of (xyz1 index, xyz0 index)
-       feat_timer.tic()
-+      
-+      coords=input_dict['sinput0_C'].to(self.device)
-       sinput0 = ME.SparseTensor(
-           input_dict['sinput0_F'].to(self.device),
--          coordinates=input_dict['sinput0_C'].to(self.device))
-+          coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
-+
-       F0 = self.model(sinput0).F
- 
-       sinput1 = ME.SparseTensor(
-           input_dict['sinput1_F'].to(self.device),
--          coordinates=input_dict['sinput1_C'].to(self.device))
-+          coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
-       F1 = self.model(sinput1).F
-       feat_timer.toc()
- 
-@@ -473,12 +476,12 @@ class HardestContrastiveLossTrainer(ContrastiveLossTrainer):
- 
-         sinput0 = ME.SparseTensor(
-             input_dict['sinput0_F'].to(self.device),
--            coordinates=input_dict['sinput0_C'].to(self.device))
-+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
-         F0 = self.model(sinput0).F
- 
-         sinput1 = ME.SparseTensor(
-             input_dict['sinput1_F'].to(self.device),
--            coordinates=input_dict['sinput1_C'].to(self.device))
-+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
- 
-         F1 = self.model(sinput1).F
- 
-@@ -604,12 +607,12 @@ class TripletLossTrainer(ContrastiveLossTrainer):
-         # pairs consist of (xyz1 index, xyz0 index)
-         sinput0 = ME.SparseTensor(
-             input_dict['sinput0_F'].to(self.device),
--            coordinates=input_dict['sinput0_C'].to(self.device))
-+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
-         F0 = self.model(sinput0).F
- 
-         sinput1 = ME.SparseTensor(
-             input_dict['sinput1_F'].to(self.device),
--            coordinates=input_dict['sinput1_C'].to(self.device))
-+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
-         F1 = self.model(sinput1).F
- 
-         pos_pairs = input_dict['correspondences']
-diff --git a/model/residual_block.py b/model/residual_block.py
-index f06fc5a..759597f 100644
---- a/model/residual_block.py
-+++ b/model/residual_block.py
-@@ -29,7 +29,7 @@ class BasicBlockBase(nn.Module):
-         kernel_size=3,
-         stride=1,
-         dilation=dilation,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm2 = get_norm(self.NORM_TYPE, planes, bn_momentum=bn_momentum, D=D)
-     self.downsample = downsample
-diff --git a/model/resunet.py b/model/resunet.py
-index 6a0e2e1..eb9a4e2 100644
---- a/model/resunet.py
-+++ b/model/resunet.py
-@@ -34,7 +34,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=conv1_kernel_size,
-         stride=1,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm1 = get_norm(NORM_TYPE, CHANNELS[1], bn_momentum=bn_momentum, D=D)
- 
-@@ -47,7 +47,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm2 = get_norm(NORM_TYPE, CHANNELS[2], bn_momentum=bn_momentum, D=D)
- 
-@@ -60,7 +60,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm3 = get_norm(NORM_TYPE, CHANNELS[3], bn_momentum=bn_momentum, D=D)
- 
-@@ -73,7 +73,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm4 = get_norm(NORM_TYPE, CHANNELS[4], bn_momentum=bn_momentum, D=D)
- 
-@@ -86,7 +86,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm4_tr = get_norm(NORM_TYPE, TR_CHANNELS[4], bn_momentum=bn_momentum, D=D)
- 
-@@ -99,7 +99,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm3_tr = get_norm(NORM_TYPE, TR_CHANNELS[3], bn_momentum=bn_momentum, D=D)
- 
-@@ -112,7 +112,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm2_tr = get_norm(NORM_TYPE, TR_CHANNELS[2], bn_momentum=bn_momentum, D=D)
- 
-@@ -125,7 +125,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=1,
-         stride=1,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
- 
-     # self.block1_tr = BasicBlockBN(TR_CHANNELS[1], TR_CHANNELS[1], bn_momentum=bn_momentum, D=D)
-@@ -136,7 +136,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=1,
-         stride=1,
-         dilation=1,
--        bias=True,
-+        has_bias=True,
-         dimension=D)
- 
-   def forward(self, x):
-@@ -187,8 +187,8 @@ class ResUNet2(ME.MinkowskiNetwork):
-     if self.normalize_feature:
-       return ME.SparseTensor(
-           out.F / torch.norm(out.F, p=2, dim=1, keepdim=True),
--          coordinate_map_key=out.coordinate_map_key,
--          coordinate_manager=out.coordinate_manager)
-+          coords_key=out.coords_key,#out.coordinate_map_key,
-+          coords_manager=out.coords_man)#out.coordinate_manager)
-     else:
-       return out
- 
-@@ -244,3 +244,8 @@ class ResUNetIN2D(ResUNetBN2D):
- class ResUNetIN2E(ResUNetBN2E):
-   NORM_TYPE = 'BN'
-   BLOCK_NORM_TYPE = 'IN'
-+
-+class ResUNetBN2C(ResUNet2):
-+  NORM_TYPE = 'BN'
-+  CHANNELS = [None, 32, 64, 128, 256]
-+  TR_CHANNELS = [None, 64, 64, 64, 128]
-\ No newline at end of file
-diff --git a/scripts/train_fcgf_kitti.sh b/scripts/train_fcgf_kitti.sh
-index de073fd..ed12044 100755
---- a/scripts/train_fcgf_kitti.sh
-+++ b/scripts/train_fcgf_kitti.sh
-@@ -3,7 +3,7 @@ export PATH_POSTFIX=$1
- export MISC_ARGS=$2
- 
- export DATA_ROOT="./outputs/Experiments"
--export DATASET=${DATASET:-KITTINMPairDataset}
-+export DATASET=${DATASET:-KITTIMapDataset} #KITTINMPairDataset}
- export TRAINER=${TRAINER:-HardestContrastiveLossTrainer}
- export MODEL=${MODEL:-ResUNetBN2C}
- export MODEL_N_OUT=${MODEL_N_OUT:-16}
-
-Mon Nov  2 17:08:49 2020       
-+-----------------------------------------------------------------------------+
-| NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |
-|-------------------------------+----------------------+----------------------+
-| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
-| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
-|===============================+======================+======================|
-|   0  GeForce GTX TIT...  On   | 00000000:05:00.0 Off |                  N/A |
-| 50%   83C    P2   117W / 250W |  12207MiB / 12211MiB |    100%      Default |
-+-------------------------------+----------------------+----------------------+
-|   1  GeForce GTX TIT...  On   | 00000000:06:00.0 Off |                  N/A |
-| 24%   63C    P8    17W / 250W |     11MiB / 12212MiB |      0%      Default |
-+-------------------------------+----------------------+----------------------+
-|   2  GeForce GTX TIT...  On   | 00000000:09:00.0 Off |                  N/A |
-| 53%   83C    P2   110W / 250W |   9515MiB / 12212MiB |     97%      Default |
-+-------------------------------+----------------------+----------------------+
-|   3  GeForce GTX TIT...  On   | 00000000:0A:00.0 Off |                  N/A |
-| 36%   70C    P8    21W / 250W |     11MiB / 12212MiB |      0%      Default |
-+-------------------------------+----------------------+----------------------+
-                                                                               
-+-----------------------------------------------------------------------------+
-| Processes:                                                       GPU Memory |
-|  GPU       PID   Type   Process name                             Usage      |
-|=============================================================================|
-|    0      4990      C   python3                                    12196MiB |
-|    2     14147      C   python3                                     9504MiB |
-+-----------------------------------------------------------------------------+
-11/02 17:08:50 ===> Configurations
-11/02 17:08:50     out_dir: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b8i1-modelnout16/2020-11-02_17-08-48
-11/02 17:08:50     trainer: HardestContrastiveLossTrainer
-11/02 17:08:50     save_freq_epoch: 1
-11/02 17:08:50     batch_size: 8
-11/02 17:08:50     val_batch_size: 1
-11/02 17:08:50     use_hard_negative: True
-11/02 17:08:50     hard_negative_sample_ratio: 0.05
-11/02 17:08:50     hard_negative_max_num: 3000
-11/02 17:08:50     num_pos_per_batch: 1024
-11/02 17:08:50     num_hn_samples_per_batch: 256
-11/02 17:08:50     neg_thresh: 1.4
-11/02 17:08:50     pos_thresh: 0.1
-11/02 17:08:50     neg_weight: 1
-11/02 17:08:50     use_random_scale: True
-11/02 17:08:50     min_scale: 0.8
-11/02 17:08:50     max_scale: 1.2
-11/02 17:08:50     use_random_rotation: True
-11/02 17:08:50     rotation_range: 360
-11/02 17:08:50     train_phase: train
-11/02 17:08:50     val_phase: val
-11/02 17:08:50     test_phase: test
-11/02 17:08:50     stat_freq: 40
-11/02 17:08:50     test_valid: True
-11/02 17:08:50     val_max_iter: 400
-11/02 17:08:50     val_epoch_freq: 1
-11/02 17:08:50     positive_pair_search_voxel_size_multiplier: 1.5
-11/02 17:08:50     hit_ratio_thresh: 0.3
-11/02 17:08:50     triplet_num_pos: 256
-11/02 17:08:50     triplet_num_hn: 512
-11/02 17:08:50     triplet_num_rand: 1024
-11/02 17:08:50     model: ResUNetBN2C
-11/02 17:08:50     model_n_out: 16
-11/02 17:08:50     conv1_kernel_size: 5
-11/02 17:08:50     normalize_feature: True
-11/02 17:08:50     dist_type: L2
-11/02 17:08:50     best_val_metric: feat_match_ratio
-11/02 17:08:50     optimizer: SGD
-11/02 17:08:50     max_epoch: 200
-11/02 17:08:50     lr: 0.1
-11/02 17:08:50     momentum: 0.8
-11/02 17:08:50     sgd_momentum: 0.9
-11/02 17:08:50     sgd_dampening: 0.1
-11/02 17:08:50     adam_beta1: 0.9
-11/02 17:08:50     adam_beta2: 0.999
-11/02 17:08:50     weight_decay: 0.0001
-11/02 17:08:50     iter_size: 1
-11/02 17:08:50     bn_momentum: 0.05
-11/02 17:08:50     exp_gamma: 0.99
-11/02 17:08:50     scheduler: ExpLR
-11/02 17:08:50     icp_cache_path: /home/chrischoy/datasets/FCGF/kitti/icp/
-11/02 17:08:50     use_gpu: True
-11/02 17:08:50     weights: None
-11/02 17:08:50     weights_dir: None
-11/02 17:08:50     resume: None
-11/02 17:08:50     resume_dir: None
-11/02 17:08:50     train_num_thread: 2
-11/02 17:08:50     val_num_thread: 1
-11/02 17:08:50     test_num_thread: 2
-11/02 17:08:50     fast_validation: False
-11/02 17:08:50     nn_max_n: 500
-11/02 17:08:50     dataset: KITTIMapDataset
-11/02 17:08:50     voxel_size: 0.3
-11/02 17:08:50     threed_match_dir: /home/chrischoy/datasets/FCGF/threedmatch
-11/02 17:08:50     kitti_root: /home/allie/dataset/kitti_odometry/
-11/02 17:08:50     kitti_max_time_diff: 3
-11/02 17:08:50     kitti_date: 2011_09_26
-11/02 17:08:50     path_cmrdata: /home/allie/dataset/cmr_original
-11/02 17:08:50     depth_max: 50
-11/02 17:08:50     num_min_map_points: 20000.0
-11/02 17:11:43 ResUNetBN2C(
-  (conv1): MinkowskiConvolution(in=1, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
-  (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block1): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=32, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=32, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv2): MinkowskiConvolution(in=32, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
-  (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block2): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv3): MinkowskiConvolution(in=64, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
-  (norm3): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block3): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv4): MinkowskiConvolution(in=128, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
-  (norm4): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block4): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=256, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=256, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv4_tr): MinkowskiConvolutionTranspose(in=256, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
-  (norm4_tr): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block4_tr): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv3_tr): MinkowskiConvolutionTranspose(in=256, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
-  (norm3_tr): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block3_tr): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv2_tr): MinkowskiConvolutionTranspose(in=128, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
-  (norm2_tr): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block2_tr): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv1_tr): MinkowskiConvolution(in=96, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
-  (final): MinkowskiConvolution(in=64, out=16, region_type=RegionType.HYPERCUBE, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
-)
-11/02 17:11:45 Resetting the data loader seed to 0
-/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/MinkowskiEngine/SparseTensor.py:260: UserWarning: Coords implicitly converted to torch.IntTensor. To remove this warning, use `.int()` to convert the coords into an torch.IntTensor
-  'To remove this warning, use `.int()` to convert the ' +
-/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/MinkowskiEngine/SparseTensor.py:267: UserWarning: Coords implicitly converted to CPU type. To remove this warning, use `.cpu()` to convert the coords into a CPU type
-  'To remove this warning, use `.cpu()` to convert the ' +
-11/02 17:18:03 Validation iter 101 / 400 : Data Loading Time: 2.147, Feature Extraction Time: 0.954, Matching Time: 0.619, Loss: 0.995, RTE: 257.727, RRE: 0.892, Hit Ratio: 0.000, Feat Match Ratio: 0.000
-11/02 17:24:23 Validation iter 201 / 400 : Data Loading Time: 2.181, Feature Extraction Time: 0.954, Matching Time: 0.631, Loss: 0.990, RTE: 228.406, RRE: 0.844, Hit Ratio: 0.000, Feat Match Ratio: 0.000
-11/02 17:31:11 Validation iter 301 / 400 : Data Loading Time: 2.429, Feature Extraction Time: 0.960, Matching Time: 0.641, Loss: 0.991, RTE: 222.431, RRE: 0.841, Hit Ratio: 0.000, Feat Match Ratio: 0.000
-11/02 17:37:29 Final Loss: 0.992, RTE: 228.734, RRE: 0.859, Hit Ratio: 0.000, Feat Match Ratio: 0.000
-/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:449: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
-  "please use `get_last_lr()`.", UserWarning)
-11/02 17:37:30  Epoch: 1, LR: [0.1]
-Traceback (most recent call last):
-  File "train.py", line 84, in <module>
-    main(config)
-  File "train.py", line 63, in main
-    trainer.train()
-  File "/home/allie/code/benchmark/FCGF/lib/trainer.py", line 132, in train
-    self._train_epoch(epoch)
-  File "/home/allie/code/benchmark/FCGF/lib/trainer.py", line 474, in _train_epoch
-    input_dict = data_loader_iter.next()
-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 435, in __next__
-    data = self._next_data()
-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1085, in _next_data
-    return self._process_data(data)
-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1111, in _process_data
-    data.reraise()
-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/_utils.py", line 428, in reraise
-    raise self.exc_type(msg)
-ValueError: Caught ValueError in DataLoader worker process 0.
-Original Traceback (most recent call last):
-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 198, in _worker_loop
-    data = fetcher.fetch(index)
-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 47, in fetch
-    return self.collate_fn(data)
-  File "/home/allie/code/benchmark/FCGF/lib/data_loaders.py", line 85, in collate_pair_fn
-    torch.from_numpy(np.array(matching_inds[batch_id]) + curr_start_inds))
-ValueError: operands could not be broadcast together with shapes (0,) (1,2) 
-
-Traceback (most recent call last):
-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/runpy.py", line 193, in _run_module_as_main
-    "__main__", mod_spec)
-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/runpy.py", line 85, in _run_code
-    exec(code, run_globals)
-  File "/home/allie/code/benchmark/FCGF/scripts/test_kitti.py", line 144, in <module>
-    main(config)
-  File "/home/allie/code/benchmark/FCGF/scripts/test_kitti.py", line 27, in main
-    config, config.test_phase, 1, num_threads=config.test_num_workers, shuffle=True)
-AttributeError: 'EasyDict' object has no attribute 'test_num_workers'
-./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-03_01-04-07
-Host:  bb8
-Conda  /home/allie/miniconda3/condabin/conda
-/home/allie/code/benchmark/FCGF
-Version:  f0863a9ba4a29f677c0ddd2248cf4e56b9318add
-Git diff
-
-diff --git a/config.py b/config.py
-index 476402d..6c9fb68 100644
---- a/config.py
-+++ b/config.py
-@@ -94,9 +94,9 @@ misc_arg.add_argument('--weights', type=str, default=None)
- misc_arg.add_argument('--weights_dir', type=str, default=None)
- misc_arg.add_argument('--resume', type=str, default=None)
- misc_arg.add_argument('--resume_dir', type=str, default=None)
--misc_arg.add_argument('--train_num_thread', type=int, default=2)
--misc_arg.add_argument('--val_num_thread', type=int, default=1)
--misc_arg.add_argument('--test_num_thread', type=int, default=2)
-+misc_arg.add_argument('--train_num_thread', type=int, default=8)#2)
-+misc_arg.add_argument('--val_num_thread', type=int, default=8)
-+misc_arg.add_argument('--test_num_thread', type=int, default=8)#2)
- misc_arg.add_argument('--fast_validation', type=str2bool, default=False)
- misc_arg.add_argument(
-     '--nn_max_n',
-@@ -112,14 +112,28 @@ data_arg.add_argument(
-     '--threed_match_dir', type=str, default="/home/chrischoy/datasets/FCGF/threedmatch")
- data_arg.add_argument(
-     '--kitti_root', type=str, default="/home/chrischoy/datasets/FCGF/kitti/")
-+
- data_arg.add_argument(
-     '--kitti_max_time_diff',
-     type=int,
-     default=3,
-     help='max time difference between pairs (non inclusive)')
-+
- data_arg.add_argument('--kitti_date', type=str, default='2011_09_26')
- 
+@@ -332,7 +332,7 @@ class ContrastiveLossTrainer(AlignmentTrainer):
  
-+#arguments for KITTI map dataset
-+#for kitti ground truth poses (optimized by loop-closing SLAM)
-+data_arg.add_argument(
-+    '--path_cmrdata', type=str, default="/home/allie/dataset/cmr_original") 
-+data_arg.add_argument(
-+    '--depth_max', type=float, default=50) 
-+data_arg.add_argument(
-+    '--num_min_map_points', type=int, default=2e4) 
-+
-+
-+
-+
- def get_config():
-   args = parser.parse_args()
-   return args
-diff --git a/lib/data_loaders.py b/lib/data_loaders.py
-index 2bc475a..e0e264d 100644
---- a/lib/data_loaders.py
-+++ b/lib/data_loaders.py
-@@ -18,10 +18,42 @@ import lib.transforms as t
- import MinkowskiEngine as ME
- 
- import open3d as o3d
-+import pickle
- 
- kitti_cache = {}
- kitti_icp_cache = {}
- 
-+eps = 1e-10
-+import csv
-+def read_csv_file(path_file):
-+    lines = []
-+    with open(path_file, "r") as f:
-+        reader = csv.reader(f, delimiter="\t")
-+        for i, line in enumerate(reader):
-+            if i >= 1:
-+                lines.append(np.asarray(line[0].split(',')[1:]).astype('float'))
-+    return lines
-+
-+
-+def pred_to_matrix_np(pred):
-+
-+    cam_T = np.tile(np.eye(4)[np.newaxis,:,:],[pred.shape[0], 1, 1])
-+    cam_T[:,0:3, 3] = pred[:, 0:3]
-+    s = np.tile(np.linalg.norm(pred[:,3:], axis=1)[:,np.newaxis],[1,4])
-+
-+    q = pred[:,3:] / (s+eps)
-+
-+    cam_T[:,0,0] = 1- 2*s[:,0]*(q[:,2]**2 + q[:,3]**2)
-+    cam_T[:,0,1] = 2   *s[:,0]*(q[:,1] * q[:,2] - q[:,3] * q[:,0])
-+    cam_T[:,0,2] = 2   *s[:,0]*(q[:,1] * q[:,3] + q[:,2] * q[:,0])
-+    cam_T[:,1,0] = 2   *s[:,0]*(q[:,1]*q[:,2] + q[:,3]*q[:,0])
-+    cam_T[:,1,1] = 1- 2*s[:,0]*(q[:,1]**2 + q[:,3]**2)
-+    cam_T[:,1,2] = 2   *s[:,0]*(q[:,2] * q[:,3] - q[:,1] * q[:,0])
-+    cam_T[:,2,0] = 2   *s[:,0]*(q[:,1] * q[:,3] - q[:,2] * q[:,0])
-+    cam_T[:,2,1] = 2   *s[:,0]*(q[:,2] * q[:,3] + q[:,1] * q[:,0])
-+    cam_T[:,2,2] = 1 -2*s[:,0]*(q[:,1]**2 + q[:,2]**2)
-+
-+    return cam_T
- 
- def collate_pair_fn(list_data):
-   xyz0, xyz1, coords0, coords1, feats0, feats1, matching_inds, trans = list(
-@@ -48,7 +80,6 @@ def collate_pair_fn(list_data):
-     xyz_batch1.append(to_tensor(xyz1[batch_id]))
- 
-     trans_batch.append(to_tensor(trans[batch_id]))
--
-     matching_inds_batch.append(
-         torch.from_numpy(np.array(matching_inds[batch_id]) + curr_start_inds))
-     len_batch.append([N0, N1])
-@@ -632,8 +663,231 @@ class ThreeDMatchPairDataset(IndoorPairDataset):
-       'test': './config/test_3dmatch.txt'
-   }
- 
-+class KITTIMapDataset(PairDataset):
-+    AUGMENT = None
-+    DATA_FILES = {
-+        'train': './config/train_kitti_map.txt', #log ids
-+        'val': './config/val_kitti_map.txt',
-+        'test': './config/test_kitti_map.txt'
-+    }
-+    TEST_RANDOM_ROTATION = False
-+    IS_ODOMETRY = True
-+    #MAX_TIME_DIFF = 3
-+
-+    def __init__(self,
-+               phase,
-+               transform=None,
-+               random_rotation=True,
-+               random_scale=True,
-+               manual_seed=False,
-+               config=None):
-+
-+
-+    #(self, root, split, config, input_threads=8, first_subsampling_dl=0.30):#, load_test=False):
-+        
-+        PairDataset.__init__(self, phase, transform, random_rotation, random_scale,
-+                         manual_seed, config)
-+
-+        self.root = root = os.path.join(config.kitti_root, 'dataset')
-+        self.split = phase
-+        self.config = config
-+
-+        self.path_map_dict = os.path.join(root, "kitti_map_files_d3feat_%s.pkl" % self.split)
-+        self.read_map_data()
-+        self.prepare_kitti_ply()#split=split)
-+       
-+
-+    def __len__(self):
-+        return self.num
-+
-+    def read_map_data(self):
-+        if os.path.exists(self.path_map_dict):
-+            with open(self.path_map_dict, 'rb') as f:
-+                self.dict_maps = pickle.load(f)
-+            return 
-+
-+
-+        subset_names = open(self.DATA_FILES[self.split]).read().split()
-+        self.dict_maps = {}
-+        for id_log in subset_names:
-+            path_map = os.path.join(self.root, "kitti_maps_cmr_new", "map-%02d_0.05.ply" % (int(id_log)))
-+            print("Load map : ", path_map)
-+            pcd = open3d.io.read_point_cloud(path_map)
-+            pcd = pcd.voxel_down_sample(self.config.first_subsampling_dl)
-+            pcd, ind = pcd.remove_radius_outlier(nb_points=7, radius=self.config.first_subsampling_dl*2)
-+            self.dict_maps[id_log] = torch.Tensor(np.asarray(pcd.points))#.to(self.config.device)
-+
-+
-+        with open(self.path_map_dict, 'wb') as f: 
-+            print('Saving map file to ', self.path_map_dict)
-+            pickle.dump(self.dict_maps, f)
-+            print('Saved!')    
-+
-+    def get_local_map(self,T_lidar, drive):#, force_select_points=False):
-+        dist = torch.sqrt(((self.dict_maps[drive] - T_lidar[0:3,3])**2).sum(axis=1))
-+        ind_valid_local = dist < self.config.depth_max
-+
-+        return self.dict_maps[drive][ind_valid_local]
-+
-+            
-+    def prepare_kitti_ply(self):#, split='train'):
-+        #max_time_diff = self.MAX_TIME_DIFF
-+        subset_names = open(self.DATA_FILES[self.split]).read().split()
-+        self.all_pos = []
-+        for dirname in subset_names:
-+            drive_id = int(dirname)
-+            fnames = glob.glob(self.root + '/sequences/%02d/velodyne/*.bin' % drive_id)
-+
-+            assert len(fnames) > 0, f"Make sure that the path {self.root} has data {dirname}"
-+            inames = sorted([int(os.path.split(fname)[-1][:-4]) for fname in fnames])
-+            path_poses = os.path.join(self.config.path_cmrdata, self.split, "kitti-%02d.csv" % drive_id)
-+            list_gt_poses = read_csv_file(path_poses)
-+
-+            for i in range(0,len(inames),2):# curr_time in inames:
-+                
-+
-+                T = pred_to_matrix_np(np.asarray(list_gt_poses[i][np.newaxis,[0,1,2,6,3,4,5]]))[0]
-+                xyz0 = self.get_local_map(T, dirname)
-+
-+                #use the local map as the source
-+                T = np.linalg.inv(T) 
-+                if xyz0.shape[0] < self.config.num_min_map_points:
-+                    continue
-+                
-+                self.files.append((drive_id, inames[i]))#, next_time))
-+                self.all_pos.append( torch.Tensor(T))#.to(self.config.device))
-+        self.num = len(self.files)
-+
-+    def __getitem__(self,idx):# split, idx):
-+        drive = self.files[idx][0]
-+        #t0, t1 = self.files[self.split][idx][1], self.files[self.split][idx][2]
-+
-+        #LiDAR is the target
-+        fname1 = self._get_velodyne_fn(drive,  self.files[idx][1])
-+        xyzr1 = np.fromfile(fname1, dtype=np.float32).reshape(-1, 4) 
-+        xyz1 = xyzr1[:, :3]
-+        
-+        #map is the source
-+        xyz0 = self.get_local_map( np.linalg.inv(self.all_pos[idx]), str(drive))
-+        trans = self.all_pos[idx]# M2
-+
-+        matching_search_voxel_size = self.matching_search_voxel_size
-+        if self.random_scale and random.random() < 0.95:
-+            scale = self.min_scale + \
-+                (self.max_scale - self.min_scale) * random.random()
-+            matching_search_voxel_size *= scale
-+            xyz0 = scale * xyz0
-+            xyz1 = scale * xyz1
-+
-+        # Voxelization
-+        xyz0_th = xyz0#torch.from_numpy(xyz0)
-+        xyz1_th = torch.from_numpy(xyz1)
-+    
-+        sel0 = ME.utils.sparse_quantize(xyz0_th / self.voxel_size, return_index=True)
-+        sel1 = ME.utils.sparse_quantize(xyz1_th / self.voxel_size, return_index=True)
-+    
-+        # Make point clouds using voxelized points
-+        pcd0 = make_open3d_point_cloud(xyz0[sel0])
-+        pcd1 = make_open3d_point_cloud(xyz1[sel1])
-+    
-+        # Get matches
-+        matches = get_matching_indices(pcd0, pcd1, trans, matching_search_voxel_size)
-+        #if len(matches) < 1000:
-+        #  raise ValueError(f"{drive}, {t0}, {t1}")
-+        #matches = np.array(matches)
-+
-+
-+        # Get features
-+        npts0 = len(sel0)
-+        npts1 = len(sel1)
-+    
-+        feats_train0, feats_train1 = [], []
-+    
-+        unique_xyz0_th = xyz0_th[sel0]
-+        unique_xyz1_th = xyz1_th[sel1]
-+    
-+        feats_train0.append(torch.ones((npts0, 1)))
-+        feats_train1.append(torch.ones((npts1, 1)))
-+    
-+        feats0 = torch.cat(feats_train0, 1)
-+        feats1 = torch.cat(feats_train1, 1)
-+    
-+        coords0 = torch.floor(unique_xyz0_th / self.voxel_size)
-+        coords1 = torch.floor(unique_xyz1_th / self.voxel_size)
-+
-+        #print("single batch = ")
-+        #print(coords0.shape)
-+        #print(coords1.shape)
-+        #print(len(matches) )        
-+        if False:#len(matches) < 10:#coords0.shape[0] < 10 or coords1.shape[0] < 10:
-+            #print("matches shape = ", matches.shape)
-+
-+            print(coords0)
-+#    
-+#    
-+            pcd_target = o3d.geometry.PointCloud()
-+            pcd_target.points = o3d.utility.Vector3dVector(coords0)
-+            o3d.io.write_point_cloud("coords0_before_%d.ply" % idx , pcd_target) 
-+#    
-+            pcd_target = o3d.geometry.PointCloud()
-+            pcd_target.points = o3d.utility.Vector3dVector(coords1)
-+            o3d.io.write_point_cloud("coords1_before_%d.ply" % idx, pcd_target) 
-+#    
-+    
-+            pcd_target = o3d.geometry.PointCloud()
-+            pcd_target.points = o3d.utility.Vector3dVector(unique_xyz1_th)
-+            o3d.io.write_point_cloud("unique_xyz1_th_%d.ply"% idx , pcd_target) 
-+#    
-+    
-+            pcd_target = o3d.geometry.PointCloud()
-+            pcd_target.points = o3d.utility.Vector3dVector(unique_xyz0_th)
-+            o3d.io.write_point_cloud("unique_xyz0_th_%d.ply"% idx , pcd_target)         
-+#    
-+            pcd_target = o3d.geometry.PointCloud()
-+            pcd_target.points = o3d.utility.Vector3dVector(unique_xyz0_th)
-+            pcd_target.transform(trans)
-+    
-+            o3d.io.write_point_cloud("unique_xyz0_th_trans_%d.ply" % idx, pcd_target) 
-+#    
-+
-+            #import pdb; pdb.set_trace()
-+            #pcd_target = o3d.geometry.PointCloud()
-+            #pcd_target.points = o3d.utility.Vector3dVector(coords0)
-+            #o3d.io.write_point_cloud("coords0.ply" , pcd_target) 
-+#    
-+            #pcd_target = o3d.geometry.PointCloud()
-+            #pcd_target.points = o3d.utility.Vector3dVector(coords1)
-+            #o3d.io.write_point_cloud("coords1.ply" , pcd_target) 
-+
-+
-+        if self.transform: #add noises to the point clouds
-+          coords0, feats0 = self.transform(coords0, feats0)
-+          coords1, feats1 = self.transform(coords1, feats1)
-+        
-+
-+        return (unique_xyz0_th.float(), unique_xyz1_th.float(), coords0.int(),
-+                coords1.int(), feats0.float(), feats1.float(), matches, trans)
-+
-+    def _get_velodyne_fn(self, drive, t):
-+        if self.IS_ODOMETRY:
-+            fname = self.root + '/sequences/%02d/velodyne/%06d.bin' % (drive, t)
-+        else:
-+            fname = self.root + \
-+                    '/' + self.date + '_drive_%04d_sync/velodyne_points/data/%010d.bin' % (
-+                        drive, t)
-+        return fname
-+
-+    #def get_position_transform(self, pos0, pos1, invert=False):
-+    #    T0 = self.pos_transform(pos0)
-+    #    T1 = self.pos_transform(pos1)
-+    #    return (np.dot(T1, np.linalg.inv(T0)).T if not invert else np.dot(
-+    #        np.linalg.inv(T1), T0).T)
-+#
-+
-+
-+
- 
--ALL_DATASETS = [ThreeDMatchPairDataset, KITTIPairDataset, KITTINMPairDataset]
-+ALL_DATASETS = [ThreeDMatchPairDataset, KITTIPairDataset, KITTINMPairDataset, KITTIMapDataset]
- dataset_str_mapping = {d.__name__: d for d in ALL_DATASETS}
- 
- 
-diff --git a/lib/trainer.py b/lib/trainer.py
-index e4c230b..e6299f8 100644
---- a/lib/trainer.py
-+++ b/lib/trainer.py
-@@ -234,12 +234,12 @@ class ContrastiveLossTrainer(AlignmentTrainer):
-         # pairs consist of (xyz1 index, xyz0 index)
-         sinput0 = ME.SparseTensor(
-             input_dict['sinput0_F'].to(self.device),
--            coordinates=input_dict['sinput0_C'].to(self.device))
-+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
-         F0 = self.model(sinput0).F
- 
-         sinput1 = ME.SparseTensor(
-             input_dict['sinput1_F'].to(self.device),
--            coordinates=input_dict['sinput1_C'].to(self.device))
-+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
-         F1 = self.model(sinput1).F
- 
-         N0, N1 = len(sinput0), len(sinput1)
-@@ -316,14 +316,17 @@ class ContrastiveLossTrainer(AlignmentTrainer):
- 
-       # pairs consist of (xyz1 index, xyz0 index)
-       feat_timer.tic()
-+      
-+      coords=input_dict['sinput0_C'].to(self.device)
-       sinput0 = ME.SparseTensor(
-           input_dict['sinput0_F'].to(self.device),
--          coordinates=input_dict['sinput0_C'].to(self.device))
-+          coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
-+
-       F0 = self.model(sinput0).F
- 
-       sinput1 = ME.SparseTensor(
-           input_dict['sinput1_F'].to(self.device),
--          coordinates=input_dict['sinput1_C'].to(self.device))
-+          coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
-       F1 = self.model(sinput1).F
-       feat_timer.toc()
- 
-@@ -473,12 +476,12 @@ class HardestContrastiveLossTrainer(ContrastiveLossTrainer):
- 
-         sinput0 = ME.SparseTensor(
-             input_dict['sinput0_F'].to(self.device),
--            coordinates=input_dict['sinput0_C'].to(self.device))
-+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
-         F0 = self.model(sinput0).F
- 
-         sinput1 = ME.SparseTensor(
-             input_dict['sinput1_F'].to(self.device),
--            coordinates=input_dict['sinput1_C'].to(self.device))
-+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
- 
-         F1 = self.model(sinput1).F
- 
-@@ -604,12 +607,12 @@ class TripletLossTrainer(ContrastiveLossTrainer):
-         # pairs consist of (xyz1 index, xyz0 index)
-         sinput0 = ME.SparseTensor(
-             input_dict['sinput0_F'].to(self.device),
--            coordinates=input_dict['sinput0_C'].to(self.device))
-+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
-         F0 = self.model(sinput0).F
- 
-         sinput1 = ME.SparseTensor(
-             input_dict['sinput1_F'].to(self.device),
--            coordinates=input_dict['sinput1_C'].to(self.device))
-+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
-         F1 = self.model(sinput1).F
- 
-         pos_pairs = input_dict['correspondences']
-diff --git a/model/residual_block.py b/model/residual_block.py
-index f06fc5a..759597f 100644
---- a/model/residual_block.py
-+++ b/model/residual_block.py
-@@ -29,7 +29,7 @@ class BasicBlockBase(nn.Module):
-         kernel_size=3,
-         stride=1,
-         dilation=dilation,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm2 = get_norm(self.NORM_TYPE, planes, bn_momentum=bn_momentum, D=D)
-     self.downsample = downsample
-diff --git a/model/resunet.py b/model/resunet.py
-index 6a0e2e1..eb9a4e2 100644
---- a/model/resunet.py
-+++ b/model/resunet.py
-@@ -34,7 +34,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=conv1_kernel_size,
-         stride=1,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm1 = get_norm(NORM_TYPE, CHANNELS[1], bn_momentum=bn_momentum, D=D)
- 
-@@ -47,7 +47,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm2 = get_norm(NORM_TYPE, CHANNELS[2], bn_momentum=bn_momentum, D=D)
- 
-@@ -60,7 +60,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm3 = get_norm(NORM_TYPE, CHANNELS[3], bn_momentum=bn_momentum, D=D)
- 
-@@ -73,7 +73,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm4 = get_norm(NORM_TYPE, CHANNELS[4], bn_momentum=bn_momentum, D=D)
- 
-@@ -86,7 +86,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm4_tr = get_norm(NORM_TYPE, TR_CHANNELS[4], bn_momentum=bn_momentum, D=D)
- 
-@@ -99,7 +99,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm3_tr = get_norm(NORM_TYPE, TR_CHANNELS[3], bn_momentum=bn_momentum, D=D)
- 
-@@ -112,7 +112,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm2_tr = get_norm(NORM_TYPE, TR_CHANNELS[2], bn_momentum=bn_momentum, D=D)
- 
-@@ -125,7 +125,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=1,
-         stride=1,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
- 
-     # self.block1_tr = BasicBlockBN(TR_CHANNELS[1], TR_CHANNELS[1], bn_momentum=bn_momentum, D=D)
-@@ -136,7 +136,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=1,
-         stride=1,
-         dilation=1,
--        bias=True,
-+        has_bias=True,
-         dimension=D)
- 
-   def forward(self, x):
-@@ -187,8 +187,8 @@ class ResUNet2(ME.MinkowskiNetwork):
-     if self.normalize_feature:
-       return ME.SparseTensor(
-           out.F / torch.norm(out.F, p=2, dim=1, keepdim=True),
--          coordinate_map_key=out.coordinate_map_key,
--          coordinate_manager=out.coordinate_manager)
-+          coords_key=out.coords_key,#out.coordinate_map_key,
-+          coords_manager=out.coords_man)#out.coordinate_manager)
-     else:
-       return out
- 
-@@ -244,3 +244,8 @@ class ResUNetIN2D(ResUNetBN2D):
- class ResUNetIN2E(ResUNetBN2E):
-   NORM_TYPE = 'BN'
-   BLOCK_NORM_TYPE = 'IN'
-+
-+class ResUNetBN2C(ResUNet2):
-+  NORM_TYPE = 'BN'
-+  CHANNELS = [None, 32, 64, 128, 256]
-+  TR_CHANNELS = [None, 64, 64, 64, 128]
-\ No newline at end of file
-diff --git a/scripts/train_fcgf_kitti.sh b/scripts/train_fcgf_kitti.sh
-index de073fd..64a0e8e 100755
---- a/scripts/train_fcgf_kitti.sh
-+++ b/scripts/train_fcgf_kitti.sh
-@@ -3,20 +3,20 @@ export PATH_POSTFIX=$1
- export MISC_ARGS=$2
- 
- export DATA_ROOT="./outputs/Experiments"
--export DATASET=${DATASET:-KITTINMPairDataset}
-+export DATASET=${DATASET:-KITTIMapDataset} #KITTINMPairDataset}
- export TRAINER=${TRAINER:-HardestContrastiveLossTrainer}
- export MODEL=${MODEL:-ResUNetBN2C}
- export MODEL_N_OUT=${MODEL_N_OUT:-16}
- export OPTIMIZER=${OPTIMIZER:-SGD}
- export LR=${LR:-1e-1}
- export MAX_EPOCH=${MAX_EPOCH:-200}
--export BATCH_SIZE=${BATCH_SIZE:-8}
-+export BATCH_SIZE=${BATCH_SIZE:-6}
- export ITER_SIZE=${ITER_SIZE:-1}
- export VOXEL_SIZE=${VOXEL_SIZE:-0.3}
- export POSITIVE_PAIR_SEARCH_VOXEL_SIZE_MULTIPLIER=${POSITIVE_PAIR_SEARCH_VOXEL_SIZE_MULTIPLIER:-1.5}
- export CONV1_KERNEL_SIZE=${CONV1_KERNEL_SIZE:-5}
- export EXP_GAMMA=${EXP_GAMMA:-0.99}
--export RANDOM_SCALE=${RANDOM_SCALE:-True}
-+export RANDOM_SCALE=${RANDOM_SCALE:-False} #scale doesn't work for the local map
- export TIME=$(date +"%Y-%m-%d_%H-%M-%S")
- export KITTI_PATH=${KITTI_PATH:-/home/chrischoy/datasets/KITTI_FCGF}
- export VERSION=$(git rev-parse HEAD)
-
-Tue Nov  3 01:04:07 2020       
-+-----------------------------------------------------------------------------+
-| NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |
-|-------------------------------+----------------------+----------------------+
-| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
-| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
-|===============================+======================+======================|
-|   0  GeForce GTX TIT...  On   | 00000000:05:00.0 Off |                  N/A |
-| 50%   83C    P2   139W / 250W |  12207MiB / 12211MiB |     93%      Default |
-+-------------------------------+----------------------+----------------------+
-|   1  GeForce GTX TIT...  On   | 00000000:06:00.0 Off |                  N/A |
-| 27%   65C    P8    17W / 250W |     11MiB / 12212MiB |      0%      Default |
-+-------------------------------+----------------------+----------------------+
-|   2  GeForce GTX TIT...  On   | 00000000:09:00.0 Off |                  N/A |
-| 52%   83C    P2   102W / 250W |   9539MiB / 12212MiB |      0%      Default |
-+-------------------------------+----------------------+----------------------+
-|   3  GeForce GTX TIT...  On   | 00000000:0A:00.0 Off |                  N/A |
-| 40%   77C    P5    25W / 250W |     11MiB / 12212MiB |      0%      Default |
-+-------------------------------+----------------------+----------------------+
-                                                                               
-+-----------------------------------------------------------------------------+
-| Processes:                                                       GPU Memory |
-|  GPU       PID   Type   Process name                             Usage      |
-|=============================================================================|
-|    0      4990      C   python3                                    12196MiB |
-|    2     14147      C   python3                                     9528MiB |
-+-----------------------------------------------------------------------------+
-11/03 01:04:09 ===> Configurations
-11/03 01:04:09     out_dir: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-03_01-04-07
-11/03 01:04:09     trainer: HardestContrastiveLossTrainer
-11/03 01:04:09     save_freq_epoch: 1
-11/03 01:04:09     batch_size: 6
-11/03 01:04:09     val_batch_size: 1
-11/03 01:04:09     use_hard_negative: True
-11/03 01:04:09     hard_negative_sample_ratio: 0.05
-11/03 01:04:09     hard_negative_max_num: 3000
-11/03 01:04:09     num_pos_per_batch: 1024
-11/03 01:04:09     num_hn_samples_per_batch: 256
-11/03 01:04:09     neg_thresh: 1.4
-11/03 01:04:09     pos_thresh: 0.1
-11/03 01:04:09     neg_weight: 1
-11/03 01:04:09     use_random_scale: False
-11/03 01:04:09     min_scale: 0.8
-11/03 01:04:09     max_scale: 1.2
-11/03 01:04:09     use_random_rotation: True
-11/03 01:04:09     rotation_range: 360
-11/03 01:04:09     train_phase: train
-11/03 01:04:09     val_phase: val
-11/03 01:04:09     test_phase: test
-11/03 01:04:09     stat_freq: 40
-11/03 01:04:09     test_valid: True
-11/03 01:04:09     val_max_iter: 400
-11/03 01:04:09     val_epoch_freq: 1
-11/03 01:04:09     positive_pair_search_voxel_size_multiplier: 1.5
-11/03 01:04:09     hit_ratio_thresh: 0.3
-11/03 01:04:09     triplet_num_pos: 256
-11/03 01:04:09     triplet_num_hn: 512
-11/03 01:04:09     triplet_num_rand: 1024
-11/03 01:04:09     model: ResUNetBN2C
-11/03 01:04:09     model_n_out: 16
-11/03 01:04:09     conv1_kernel_size: 5
-11/03 01:04:09     normalize_feature: True
-11/03 01:04:09     dist_type: L2
-11/03 01:04:09     best_val_metric: feat_match_ratio
-11/03 01:04:09     optimizer: SGD
-11/03 01:04:09     max_epoch: 200
-11/03 01:04:09     lr: 0.1
-11/03 01:04:09     momentum: 0.8
-11/03 01:04:09     sgd_momentum: 0.9
-11/03 01:04:09     sgd_dampening: 0.1
-11/03 01:04:09     adam_beta1: 0.9
-11/03 01:04:09     adam_beta2: 0.999
-11/03 01:04:09     weight_decay: 0.0001
-11/03 01:04:09     iter_size: 1
-11/03 01:04:09     bn_momentum: 0.05
-11/03 01:04:09     exp_gamma: 0.99
-11/03 01:04:09     scheduler: ExpLR
-11/03 01:04:09     icp_cache_path: /home/chrischoy/datasets/FCGF/kitti/icp/
-11/03 01:04:09     use_gpu: True
-11/03 01:04:09     weights: None
-11/03 01:04:09     weights_dir: None
-11/03 01:04:09     resume: None
-11/03 01:04:09     resume_dir: None
-11/03 01:04:09     train_num_thread: 8
-11/03 01:04:09     val_num_thread: 8
-11/03 01:04:09     test_num_thread: 8
-11/03 01:04:09     fast_validation: False
-11/03 01:04:09     nn_max_n: 500
-11/03 01:04:09     dataset: KITTIMapDataset
-11/03 01:04:09     voxel_size: 0.3
-11/03 01:04:09     threed_match_dir: /home/chrischoy/datasets/FCGF/threedmatch
-11/03 01:04:09     kitti_root: /home/allie/dataset/kitti_odometry/
-11/03 01:04:09     kitti_max_time_diff: 3
-11/03 01:04:09     kitti_date: 2011_09_26
-11/03 01:04:09     path_cmrdata: /home/allie/dataset/cmr_original
-11/03 01:04:09     depth_max: 50
-11/03 01:04:09     num_min_map_points: 20000.0
-11/03 01:06:57 ResUNetBN2C(
-  (conv1): MinkowskiConvolution(in=1, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
-  (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block1): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=32, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=32, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv2): MinkowskiConvolution(in=32, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
-  (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block2): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv3): MinkowskiConvolution(in=64, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
-  (norm3): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block3): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv4): MinkowskiConvolution(in=128, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
-  (norm4): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block4): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=256, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=256, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv4_tr): MinkowskiConvolutionTranspose(in=256, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
-  (norm4_tr): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block4_tr): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv3_tr): MinkowskiConvolutionTranspose(in=256, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
-  (norm3_tr): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block3_tr): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv2_tr): MinkowskiConvolutionTranspose(in=128, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
-  (norm2_tr): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block2_tr): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv1_tr): MinkowskiConvolution(in=96, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
-  (final): MinkowskiConvolution(in=64, out=16, region_type=RegionType.HYPERCUBE, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
-)
-11/03 01:07:00 Resetting the data loader seed to 0
-/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/MinkowskiEngine/SparseTensor.py:260: UserWarning: Coords implicitly converted to torch.IntTensor. To remove this warning, use `.int()` to convert the coords into an torch.IntTensor
-  'To remove this warning, use `.int()` to convert the ' +
-/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/MinkowskiEngine/SparseTensor.py:267: UserWarning: Coords implicitly converted to CPU type. To remove this warning, use `.cpu()` to convert the coords into a CPU type
-  'To remove this warning, use `.cpu()` to convert the ' +
-11/03 01:10:36 Validation iter 101 / 400 : Data Loading Time: 0.062, Feature Extraction Time: 1.172, Matching Time: 0.883, Loss: 0.999, RTE: 250.249, RRE: 0.855, Hit Ratio: 0.000, Feat Match Ratio: 0.000
-11/03 01:14:04 Validation iter 201 / 400 : Data Loading Time: 0.014, Feature Extraction Time: 1.170, Matching Time: 0.879, Loss: 0.998, RTE: 222.577, RRE: 0.821, Hit Ratio: 0.000, Feat Match Ratio: 0.000
-11/03 01:17:31 Validation iter 301 / 400 : Data Loading Time: 0.017, Feature Extraction Time: 1.159, Matching Time: 0.880, Loss: 0.995, RTE: 217.632, RRE: 0.824, Hit Ratio: 0.000, Feat Match Ratio: 0.000
-11/03 01:20:47 Final Loss: 0.995, RTE: 224.363, RRE: 0.844, Hit Ratio: 0.000, Feat Match Ratio: 0.000
-/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:449: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
-  "please use `get_last_lr()`.", UserWarning)
-11/03 01:20:47  Epoch: 1, LR: [0.1]
-11/03 01:21:22 Train Epoch: 1 [0/477], Current Loss: 1.704e+00 Pos: 0.724 Neg: 0.980	Data time: 26.4148, Train time: 8.3080, Iter time: 34.7228
-11/03 01:26:58 Train Epoch: 1 [40/477], Current Loss: 1.344e+00 Pos: 0.288 Neg: 1.057	Data time: 0.1094, Train time: 8.2677, Iter time: 8.3771
+       matching_timer.tic()
+       xyz0, xyz1, T_gt = input_dict['pcd0'], input_dict['pcd1'], input_dict['T_gt']
+-      xyz0_corr, xyz1_corr = self.find_corr(xyz0, xyz1, F0, F1, subsample_size=5000)
++      xyz0_corr, xyz1_corr = self.find_corr(xyz0, xyz1, F0, F1, subsample_size=10000)#5000)
+       T_est = te.est_quad_linear_robust(xyz0_corr,
\ No newline at end of file
diff --git a/scripts/train_fcgf_kitti.sh b/scripts/train_fcgf_kitti.sh
index 64a0e8e..09e4c81 100755
--- a/scripts/train_fcgf_kitti.sh
+++ b/scripts/train_fcgf_kitti.sh
@@ -13,7 +13,7 @@ export MAX_EPOCH=${MAX_EPOCH:-200}
 export BATCH_SIZE=${BATCH_SIZE:-6}
 export ITER_SIZE=${ITER_SIZE:-1}
 export VOXEL_SIZE=${VOXEL_SIZE:-0.3}
-export POSITIVE_PAIR_SEARCH_VOXEL_SIZE_MULTIPLIER=${POSITIVE_PAIR_SEARCH_VOXEL_SIZE_MULTIPLIER:-1.5}
+export POSITIVE_PAIR_SEARCH_VOXEL_SIZE_MULTIPLIER=${POSITIVE_PAIR_SEARCH_VOXEL_SIZE_MULTIPLIER:-0.5} #1,5 -> 0.5 otherwise it might generate too many pairs from the dense map
 export CONV1_KERNEL_SIZE=${CONV1_KERNEL_SIZE:-5}
 export EXP_GAMMA=${EXP_GAMMA:-0.99}
 export RANDOM_SCALE=${RANDOM_SCALE:-False} #scale doesn't work for the local map

Thu Nov  5 01:31:22 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX TIT...  On   | 00000000:05:00.0 Off |                  N/A |
| 23%   61C    P8    32W / 250W |      0MiB / 12211MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX TIT...  On   | 00000000:06:00.0 Off |                  N/A |
| 23%   62C    P8    17W / 250W |      0MiB / 12212MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX TIT...  On   | 00000000:09:00.0 Off |                  N/A |
| 53%   84C    P2   137W / 250W |  11247MiB / 12212MiB |    100%      Default |
+-------------------------------+----------------------+----------------------+
|   3  GeForce GTX TIT...  On   | 00000000:0A:00.0 Off |                  N/A |
| 22%   45C    P8    16W / 250W |      0MiB / 12212MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    2      6811      C   python3                                    11236MiB |
+-----------------------------------------------------------------------------+
11/05 01:31:24 ===> Configurations
11/05 01:31:24     out_dir: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22
11/05 01:31:24     trainer: HardestContrastiveLossTrainer
11/05 01:31:24     save_freq_epoch: 1
11/05 01:31:24     batch_size: 6
11/05 01:31:24     val_batch_size: 1
11/05 01:31:24     use_hard_negative: True
11/05 01:31:24     hard_negative_sample_ratio: 0.05
11/05 01:31:24     hard_negative_max_num: 3000
11/05 01:31:24     num_pos_per_batch: 1024
11/05 01:31:24     num_hn_samples_per_batch: 256
11/05 01:31:24     neg_thresh: 1.4
11/05 01:31:24     pos_thresh: 0.1
11/05 01:31:24     neg_weight: 1
11/05 01:31:24     use_random_scale: False
11/05 01:31:24     min_scale: 0.8
11/05 01:31:24     max_scale: 1.2
11/05 01:31:24     use_random_rotation: True
11/05 01:31:24     rotation_range: 360
11/05 01:31:24     train_phase: train
11/05 01:31:24     val_phase: val
11/05 01:31:24     test_phase: test
11/05 01:31:24     stat_freq: 40
11/05 01:31:24     test_valid: True
11/05 01:31:24     val_max_iter: 400
11/05 01:31:24     val_epoch_freq: 1
11/05 01:31:24     positive_pair_search_voxel_size_multiplier: 0.5
11/05 01:31:24     hit_ratio_thresh: 0.3
11/05 01:31:24     triplet_num_pos: 256
11/05 01:31:24     triplet_num_hn: 512
11/05 01:31:24     triplet_num_rand: 1024
11/05 01:31:24     model: ResUNetBN2C
11/05 01:31:24     model_n_out: 16
11/05 01:31:24     conv1_kernel_size: 5
11/05 01:31:24     normalize_feature: True
11/05 01:31:24     dist_type: L2
11/05 01:31:24     best_val_metric: feat_match_ratio
11/05 01:31:24     optimizer: SGD
11/05 01:31:24     max_epoch: 200
11/05 01:31:24     lr: 0.1
11/05 01:31:24     momentum: 0.8
11/05 01:31:24     sgd_momentum: 0.9
11/05 01:31:24     sgd_dampening: 0.1
11/05 01:31:24     adam_beta1: 0.9
11/05 01:31:24     adam_beta2: 0.999
11/05 01:31:24     weight_decay: 0.0001
11/05 01:31:24     iter_size: 1
11/05 01:31:24     bn_momentum: 0.05
11/05 01:31:24     exp_gamma: 0.99
11/05 01:31:24     scheduler: ExpLR
11/05 01:31:24     icp_cache_path: /home/chrischoy/datasets/FCGF/kitti/icp/
11/05 01:31:24     use_gpu: True
11/05 01:31:24     weights: None
11/05 01:31:24     weights_dir: None
11/05 01:31:24     resume: None
11/05 01:31:24     resume_dir: None
11/05 01:31:24     train_num_thread: 8
11/05 01:31:24     val_num_thread: 8
11/05 01:31:24     test_num_thread: 8
11/05 01:31:24     fast_validation: False
11/05 01:31:24     nn_max_n: 500
11/05 01:31:24     dataset: KITTIMapDataset
11/05 01:31:24     voxel_size: 0.3
11/05 01:31:24     threed_match_dir: /home/chrischoy/datasets/FCGF/threedmatch
11/05 01:31:24     kitti_root: /home/allie/dataset/kitti_odometry/
11/05 01:31:24     kitti_max_time_diff: 3
11/05 01:31:24     kitti_date: 2011_09_26
11/05 01:31:24     path_cmrdata: /home/allie/dataset/cmr_original
11/05 01:31:24     depth_max: 50
11/05 01:31:24     num_min_map_points: 20000.0
11/05 01:33:30 ResUNetBN2C(
  (conv1): MinkowskiConvolution(in=1, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block1): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=32, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=32, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv2): MinkowskiConvolution(in=32, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
  (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block2): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv3): MinkowskiConvolution(in=64, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
  (norm3): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block3): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv4): MinkowskiConvolution(in=128, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
  (norm4): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block4): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=256, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=256, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv4_tr): MinkowskiConvolutionTranspose(in=256, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
  (norm4_tr): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block4_tr): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv3_tr): MinkowskiConvolutionTranspose(in=256, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
  (norm3_tr): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block3_tr): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv2_tr): MinkowskiConvolutionTranspose(in=128, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
  (norm2_tr): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block2_tr): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv1_tr): MinkowskiConvolution(in=96, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
  (final): MinkowskiConvolution(in=64, out=16, region_type=RegionType.HYPERCUBE, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
)
11/05 01:33:31 Resetting the data loader seed to 0
/home/allie/miniconda3/lib/python3.7/site-packages/MinkowskiEngine-0.4.2-py3.7-linux-x86_64.egg/MinkowskiEngine/SparseTensor.py:229: UserWarning: Coords implicitly converted to torch.IntTensor. To remove this warning, use `.int()` to convert the coords into an torch.IntTensor
  'To remove this warning, use `.int()` to convert the ' +
/home/allie/miniconda3/lib/python3.7/site-packages/MinkowskiEngine-0.4.2-py3.7-linux-x86_64.egg/MinkowskiEngine/SparseTensor.py:236: UserWarning: Coords implicitly converted to CPU type. To remove this warning, use `.cpu()` to convert the coords into a CPU type
  'To remove this warning, use `.cpu()` to convert the ' +
11/05 01:36:51 Validation iter 101 / 400 : Data Loading Time: 0.030, Feature Extraction Time: 0.839, Matching Time: 1.087, Loss: 0.995, RTE: 232.597, RRE: 0.810, Hit Ratio: 0.000, Feat Match Ratio: 0.000
11/05 01:40:07 Validation iter 201 / 400 : Data Loading Time: 0.007, Feature Extraction Time: 0.843, Matching Time: 1.084, Loss: 0.995, RTE: 229.636, RRE: 0.849, Hit Ratio: 0.000, Feat Match Ratio: 0.000
11/05 01:44:00 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.864, Matching Time: 1.184, Loss: 0.993, RTE: 220.317, RRE: 0.829, Hit Ratio: 0.000, Feat Match Ratio: 0.000
11/05 01:47:07 Final Loss: 0.993, RTE: 223.164, RRE: 0.841, Hit Ratio: 0.000, Feat Match Ratio: 0.000
11/05 01:47:07  Epoch: 1, LR: [0.1]
11/05 01:47:28 Train Epoch: 1 [0/477], Current Loss: 1.658e+00 Pos: 0.642 Neg: 1.016	Data time: 13.5048, Train time: 7.0318, Iter time: 20.5366
11/05 01:51:45 Train Epoch: 1 [40/477], Current Loss: 1.283e+00 Pos: 0.297 Neg: 0.986	Data time: 0.0193, Train time: 6.4053, Iter time: 6.4246
11/05 01:55:51 Train Epoch: 1 [80/477], Current Loss: 1.049e+00 Pos: 0.391 Neg: 0.658	Data time: 0.0066, Train time: 6.1362, Iter time: 6.1427
11/05 01:59:56 Train Epoch: 1 [120/477], Current Loss: 1.096e+00 Pos: 0.432 Neg: 0.664	Data time: 0.0067, Train time: 6.1250, Iter time: 6.1317
11/05 02:04:02 Train Epoch: 1 [160/477], Current Loss: 1.013e+00 Pos: 0.369 Neg: 0.644	Data time: 0.0071, Train time: 6.1442, Iter time: 6.1513
11/05 02:08:07 Train Epoch: 1 [200/477], Current Loss: 1.013e+00 Pos: 0.329 Neg: 0.685	Data time: 0.0075, Train time: 6.1021, Iter time: 6.1096
11/05 02:12:17 Train Epoch: 1 [240/477], Current Loss: 9.379e-01 Pos: 0.435 Neg: 0.503	Data time: 0.0082, Train time: 6.2534, Iter time: 6.2616
11/05 02:16:58 Train Epoch: 1 [280/477], Current Loss: 9.943e-01 Pos: 0.347 Neg: 0.647	Data time: 0.0122, Train time: 6.9964, Iter time: 7.0085
11/05 02:21:03 Train Epoch: 1 [320/477], Current Loss: 9.331e-01 Pos: 0.398 Neg: 0.535	Data time: 0.0094, Train time: 6.1144, Iter time: 6.1238
11/05 02:25:18 Train Epoch: 1 [360/477], Current Loss: 8.968e-01 Pos: 0.392 Neg: 0.505	Data time: 0.0102, Train time: 6.3711, Iter time: 6.3813
11/05 02:29:20 Train Epoch: 1 [400/477], Current Loss: 8.934e-01 Pos: 0.401 Neg: 0.492	Data time: 0.0095, Train time: 6.0487, Iter time: 6.0582
11/05 02:33:31 Train Epoch: 1 [440/477], Current Loss: 9.321e-01 Pos: 0.453 Neg: 0.479	Data time: 0.0099, Train time: 6.2574, Iter time: 6.2672
11/05 02:37:06 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 02:37:06 Resetting the data loader seed to 0
11/05 02:40:33 Validation iter 101 / 400 : Data Loading Time: 0.030, Feature Extraction Time: 0.895, Matching Time: 1.103, Loss: 0.990, RTE: 181.130, RRE: 0.702, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 02:43:54 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.892, Matching Time: 1.102, Loss: 0.991, RTE: 178.359, RRE: 0.715, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 02:47:37 Validation iter 301 / 400 : Data Loading Time: 0.009, Feature Extraction Time: 0.898, Matching Time: 1.169, Loss: 0.986, RTE: 175.156, RRE: 0.669, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 02:51:10 Final Loss: 0.985, RTE: 172.728, RRE: 0.673, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 02:51:10 Saving the best val model with feat_match_ratio: 0.0
11/05 02:51:10 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/best_val_checkpoint.pth ...
11/05 02:51:10  Epoch: 2, LR: [0.099]
11/05 02:51:32 Train Epoch: 2 [0/477], Current Loss: 9.129e-01 Pos: 0.366 Neg: 0.547	Data time: 13.0873, Train time: 7.9353, Iter time: 21.0226
11/05 02:55:42 Train Epoch: 2 [40/477], Current Loss: 9.004e-01 Pos: 0.395 Neg: 0.505	Data time: 0.0094, Train time: 6.2390, Iter time: 6.2484
11/05 02:59:46 Train Epoch: 2 [80/477], Current Loss: 8.900e-01 Pos: 0.395 Neg: 0.495	Data time: 0.0071, Train time: 6.1057, Iter time: 6.1128
11/05 03:03:57 Train Epoch: 2 [120/477], Current Loss: 8.868e-01 Pos: 0.397 Neg: 0.490	Data time: 0.0074, Train time: 6.2503, Iter time: 6.2577
11/05 03:08:04 Train Epoch: 2 [160/477], Current Loss: 9.504e-01 Pos: 0.412 Neg: 0.538	Data time: 0.0076, Train time: 6.1656, Iter time: 6.1731
11/05 03:12:09 Train Epoch: 2 [200/477], Current Loss: 8.910e-01 Pos: 0.378 Neg: 0.513	Data time: 0.0082, Train time: 6.1207, Iter time: 6.1289
11/05 03:16:14 Train Epoch: 2 [240/477], Current Loss: 8.879e-01 Pos: 0.393 Neg: 0.495	Data time: 0.0083, Train time: 6.1114, Iter time: 6.1197
11/05 03:20:51 Train Epoch: 2 [280/477], Current Loss: 8.848e-01 Pos: 0.394 Neg: 0.491	Data time: 0.0113, Train time: 6.9163, Iter time: 6.9276
11/05 03:25:04 Train Epoch: 2 [320/477], Current Loss: 8.850e-01 Pos: 0.397 Neg: 0.488	Data time: 0.0090, Train time: 6.3269, Iter time: 6.3358
11/05 03:29:10 Train Epoch: 2 [360/477], Current Loss: 8.833e-01 Pos: 0.395 Neg: 0.488	Data time: 0.0092, Train time: 6.1391, Iter time: 6.1483
11/05 03:33:14 Train Epoch: 2 [400/477], Current Loss: 8.828e-01 Pos: 0.394 Neg: 0.488	Data time: 0.0097, Train time: 6.0900, Iter time: 6.0997
11/05 03:37:22 Train Epoch: 2 [440/477], Current Loss: 8.828e-01 Pos: 0.393 Neg: 0.489	Data time: 0.0097, Train time: 6.1900, Iter time: 6.1997
11/05 03:41:04 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 03:41:04 Resetting the data loader seed to 0
11/05 03:44:31 Validation iter 101 / 400 : Data Loading Time: 0.024, Feature Extraction Time: 0.883, Matching Time: 1.124, Loss: 0.991, RTE: 174.481, RRE: 0.671, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 03:47:48 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.880, Matching Time: 1.098, Loss: 0.990, RTE: 172.524, RRE: 0.681, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 03:51:15 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.882, Matching Time: 1.122, Loss: 0.987, RTE: 176.372, RRE: 0.699, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 03:55:07 Final Loss: 0.988, RTE: 173.064, RRE: 0.687, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 03:55:07 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/05 03:55:07  Epoch: 3, LR: [0.09801]
11/05 03:55:24 Train Epoch: 3 [0/477], Current Loss: 8.843e-01 Pos: 0.398 Neg: 0.487	Data time: 10.9499, Train time: 5.9981, Iter time: 16.9480
11/05 03:59:31 Train Epoch: 3 [40/477], Current Loss: 8.823e-01 Pos: 0.392 Neg: 0.491	Data time: 0.0115, Train time: 6.1442, Iter time: 6.1558
11/05 04:03:41 Train Epoch: 3 [80/477], Current Loss: 8.838e-01 Pos: 0.389 Neg: 0.495	Data time: 0.0067, Train time: 6.2617, Iter time: 6.2684
11/05 04:07:49 Train Epoch: 3 [120/477], Current Loss: 1.133e+00 Pos: 0.405 Neg: 0.729	Data time: 0.0067, Train time: 6.1930, Iter time: 6.1997
11/05 04:11:58 Train Epoch: 3 [160/477], Current Loss: 9.197e-01 Pos: 0.392 Neg: 0.528	Data time: 0.0069, Train time: 6.1965, Iter time: 6.2034
11/05 04:16:06 Train Epoch: 3 [200/477], Current Loss: 8.974e-01 Pos: 0.382 Neg: 0.515	Data time: 0.0073, Train time: 6.1923, Iter time: 6.1995
11/05 04:20:12 Train Epoch: 3 [240/477], Current Loss: 8.916e-01 Pos: 0.405 Neg: 0.486	Data time: 0.0081, Train time: 6.1546, Iter time: 6.1627
11/05 04:24:39 Train Epoch: 3 [280/477], Current Loss: 8.950e-01 Pos: 0.396 Neg: 0.499	Data time: 0.0118, Train time: 6.6580, Iter time: 6.6698
11/05 04:28:56 Train Epoch: 3 [320/477], Current Loss: 8.868e-01 Pos: 0.395 Neg: 0.492	Data time: 0.0103, Train time: 6.4156, Iter time: 6.4259
11/05 04:33:03 Train Epoch: 3 [360/477], Current Loss: 8.852e-01 Pos: 0.394 Neg: 0.491	Data time: 0.0093, Train time: 6.1682, Iter time: 6.1774
11/05 04:37:10 Train Epoch: 3 [400/477], Current Loss: 9.325e-01 Pos: 0.375 Neg: 0.557	Data time: 0.0091, Train time: 6.1511, Iter time: 6.1602
11/05 04:41:20 Train Epoch: 3 [440/477], Current Loss: 8.919e-01 Pos: 0.394 Neg: 0.498	Data time: 0.0091, Train time: 6.2471, Iter time: 6.2562
11/05 04:45:00 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 04:45:00 Resetting the data loader seed to 0
11/05 04:48:30 Validation iter 101 / 400 : Data Loading Time: 0.036, Feature Extraction Time: 0.905, Matching Time: 1.119, Loss: 0.983, RTE: 162.542, RRE: 0.750, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 04:51:55 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.904, Matching Time: 1.123, Loss: 0.985, RTE: 177.505, RRE: 0.743, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 04:55:04 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.888, Matching Time: 1.084, Loss: 0.987, RTE: 176.445, RRE: 0.714, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 04:59:06 Final Loss: 0.983, RTE: 174.797, RRE: 0.688, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 04:59:06 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/05 04:59:06  Epoch: 4, LR: [0.0970299]
11/05 04:59:31 Train Epoch: 4 [0/477], Current Loss: 8.895e-01 Pos: 0.398 Neg: 0.492	Data time: 16.7389, Train time: 7.9743, Iter time: 24.7132
11/05 05:03:40 Train Epoch: 4 [40/477], Current Loss: 8.881e-01 Pos: 0.386 Neg: 0.503	Data time: 0.0077, Train time: 6.2148, Iter time: 6.2225
11/05 05:07:44 Train Epoch: 4 [80/477], Current Loss: 8.971e-01 Pos: 0.396 Neg: 0.501	Data time: 0.0065, Train time: 6.0957, Iter time: 6.1022
11/05 05:11:50 Train Epoch: 4 [120/477], Current Loss: 8.873e-01 Pos: 0.390 Neg: 0.497	Data time: 0.0068, Train time: 6.1598, Iter time: 6.1667
11/05 05:15:54 Train Epoch: 4 [160/477], Current Loss: 8.878e-01 Pos: 0.398 Neg: 0.490	Data time: 0.0069, Train time: 6.0722, Iter time: 6.0790
11/05 05:20:01 Train Epoch: 4 [200/477], Current Loss: 8.852e-01 Pos: 0.400 Neg: 0.486	Data time: 0.0067, Train time: 6.1718, Iter time: 6.1786
11/05 05:24:08 Train Epoch: 4 [240/477], Current Loss: 9.090e-01 Pos: 0.436 Neg: 0.473	Data time: 0.0073, Train time: 6.1785, Iter time: 6.1858
11/05 05:28:33 Train Epoch: 4 [280/477], Current Loss: 9.067e-01 Pos: 0.376 Neg: 0.530	Data time: 0.0104, Train time: 6.6072, Iter time: 6.6176
11/05 05:33:02 Train Epoch: 4 [320/477], Current Loss: 8.999e-01 Pos: 0.407 Neg: 0.493	Data time: 0.0104, Train time: 6.7089, Iter time: 6.7193
11/05 05:37:13 Train Epoch: 4 [360/477], Current Loss: 8.866e-01 Pos: 0.395 Neg: 0.491	Data time: 0.0089, Train time: 6.2747, Iter time: 6.2836
11/05 05:41:21 Train Epoch: 4 [400/477], Current Loss: 9.009e-01 Pos: 0.408 Neg: 0.493	Data time: 0.0097, Train time: 6.1819, Iter time: 6.1916
11/05 05:45:33 Train Epoch: 4 [440/477], Current Loss: 8.922e-01 Pos: 0.397 Neg: 0.495	Data time: 0.0090, Train time: 6.2813, Iter time: 6.2903
11/05 05:49:12 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 05:49:12 Resetting the data loader seed to 0
11/05 05:52:32 Validation iter 101 / 400 : Data Loading Time: 0.035, Feature Extraction Time: 0.884, Matching Time: 1.048, Loss: 0.989, RTE: 167.465, RRE: 0.732, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 05:55:52 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.886, Matching Time: 1.069, Loss: 0.988, RTE: 174.527, RRE: 0.711, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 05:59:08 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.884, Matching Time: 1.065, Loss: 0.992, RTE: 174.237, RRE: 0.711, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 06:03:09 Final Loss: 0.988, RTE: 170.873, RRE: 0.685, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 06:03:09 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/05 06:03:09  Epoch: 5, LR: [0.096059601]
11/05 06:03:28 Train Epoch: 5 [0/477], Current Loss: 8.869e-01 Pos: 0.410 Neg: 0.477	Data time: 11.4992, Train time: 7.2910, Iter time: 18.7902
11/05 06:07:42 Train Epoch: 5 [40/477], Current Loss: 8.842e-01 Pos: 0.391 Neg: 0.493	Data time: 0.0303, Train time: 6.3039, Iter time: 6.3342
11/05 06:11:50 Train Epoch: 5 [80/477], Current Loss: 8.835e-01 Pos: 0.395 Neg: 0.488	Data time: 0.0063, Train time: 6.1970, Iter time: 6.2033
11/05 06:16:01 Train Epoch: 5 [120/477], Current Loss: 8.840e-01 Pos: 0.388 Neg: 0.496	Data time: 0.0069, Train time: 6.2830, Iter time: 6.2899
11/05 06:20:13 Train Epoch: 5 [160/477], Current Loss: 8.838e-01 Pos: 0.398 Neg: 0.486	Data time: 0.0064, Train time: 6.2881, Iter time: 6.2945
11/05 06:24:21 Train Epoch: 5 [200/477], Current Loss: 8.830e-01 Pos: 0.392 Neg: 0.491	Data time: 0.0075, Train time: 6.1966, Iter time: 6.2041
11/05 06:28:31 Train Epoch: 5 [240/477], Current Loss: 8.823e-01 Pos: 0.392 Neg: 0.490	Data time: 0.0081, Train time: 6.2357, Iter time: 6.2438
11/05 06:32:49 Train Epoch: 5 [280/477], Current Loss: 8.834e-01 Pos: 0.390 Neg: 0.494	Data time: 0.0101, Train time: 6.4473, Iter time: 6.4574
11/05 06:37:18 Train Epoch: 5 [320/477], Current Loss: 8.891e-01 Pos: 0.390 Neg: 0.499	Data time: 0.0104, Train time: 6.7055, Iter time: 6.7159
11/05 06:41:22 Train Epoch: 5 [360/477], Current Loss: 8.841e-01 Pos: 0.393 Neg: 0.491	Data time: 0.0087, Train time: 6.0856, Iter time: 6.0942
11/05 06:45:33 Train Epoch: 5 [400/477], Current Loss: 8.849e-01 Pos: 0.400 Neg: 0.485	Data time: 0.0100, Train time: 6.2590, Iter time: 6.2690
11/05 06:49:40 Train Epoch: 5 [440/477], Current Loss: 8.847e-01 Pos: 0.387 Neg: 0.498	Data time: 0.0094, Train time: 6.1638, Iter time: 6.1732
11/05 06:53:14 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 06:53:14 Resetting the data loader seed to 0
11/05 06:56:38 Validation iter 101 / 400 : Data Loading Time: 0.033, Feature Extraction Time: 0.910, Matching Time: 1.067, Loss: 0.984, RTE: 172.231, RRE: 0.722, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 06:59:58 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.892, Matching Time: 1.083, Loss: 0.983, RTE: 175.236, RRE: 0.740, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 07:03:09 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.885, Matching Time: 1.063, Loss: 0.984, RTE: 174.518, RRE: 0.711, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 07:07:04 Final Loss: 0.985, RTE: 173.632, RRE: 0.695, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 07:07:05 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/05 07:07:05  Epoch: 6, LR: [0.09509900499]
11/05 07:07:23 Train Epoch: 6 [0/477], Current Loss: 8.841e-01 Pos: 0.401 Neg: 0.483	Data time: 10.4744, Train time: 6.8869, Iter time: 17.3613
11/05 07:11:32 Train Epoch: 6 [40/477], Current Loss: 8.841e-01 Pos: 0.386 Neg: 0.498	Data time: 0.0104, Train time: 6.2199, Iter time: 6.2303
11/05 07:15:45 Train Epoch: 6 [80/477], Current Loss: 8.834e-01 Pos: 0.394 Neg: 0.489	Data time: 0.0070, Train time: 6.3155, Iter time: 6.3226
11/05 07:19:51 Train Epoch: 6 [120/477], Current Loss: 8.828e-01 Pos: 0.397 Neg: 0.485	Data time: 0.0063, Train time: 6.1492, Iter time: 6.1555
11/05 07:24:02 Train Epoch: 6 [160/477], Current Loss: 8.835e-01 Pos: 0.389 Neg: 0.495	Data time: 0.0065, Train time: 6.2786, Iter time: 6.2851
11/05 07:28:08 Train Epoch: 6 [200/477], Current Loss: 8.822e-01 Pos: 0.390 Neg: 0.492	Data time: 0.0069, Train time: 6.1362, Iter time: 6.1431
11/05 07:32:16 Train Epoch: 6 [240/477], Current Loss: 8.824e-01 Pos: 0.390 Neg: 0.492	Data time: 0.0086, Train time: 6.1787, Iter time: 6.1872
11/05 07:36:19 Train Epoch: 6 [280/477], Current Loss: 8.822e-01 Pos: 0.389 Neg: 0.493	Data time: 0.0085, Train time: 6.0679, Iter time: 6.0764
11/05 07:41:06 Train Epoch: 6 [320/477], Current Loss: 8.828e-01 Pos: 0.394 Neg: 0.489	Data time: 0.0118, Train time: 7.1636, Iter time: 7.1755
11/05 07:45:13 Train Epoch: 6 [360/477], Current Loss: 8.815e-01 Pos: 0.394 Neg: 0.488	Data time: 0.0085, Train time: 6.1835, Iter time: 6.1921
11/05 07:49:18 Train Epoch: 6 [400/477], Current Loss: 8.818e-01 Pos: 0.394 Neg: 0.488	Data time: 0.0094, Train time: 6.1027, Iter time: 6.1121
11/05 07:53:30 Train Epoch: 6 [440/477], Current Loss: 8.823e-01 Pos: 0.395 Neg: 0.488	Data time: 0.0093, Train time: 6.2863, Iter time: 6.2956
11/05 07:57:08 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 07:57:08 Resetting the data loader seed to 0
11/05 08:00:32 Validation iter 101 / 400 : Data Loading Time: 0.030, Feature Extraction Time: 0.887, Matching Time: 1.082, Loss: 0.986, RTE: 163.001, RRE: 0.748, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 08:03:55 Validation iter 201 / 400 : Data Loading Time: 0.009, Feature Extraction Time: 0.884, Matching Time: 1.105, Loss: 0.983, RTE: 168.516, RRE: 0.698, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 08:07:16 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.882, Matching Time: 1.106, Loss: 0.979, RTE: 172.493, RRE: 0.673, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 08:11:03 Final Loss: 0.982, RTE: 174.936, RRE: 0.697, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 08:11:03 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/05 08:11:03  Epoch: 7, LR: [0.0941480149401]
11/05 08:11:30 Train Epoch: 7 [0/477], Current Loss: 8.817e-01 Pos: 0.393 Neg: 0.489	Data time: 18.9043, Train time: 7.5805, Iter time: 26.4848
11/05 08:15:39 Train Epoch: 7 [40/477], Current Loss: 8.858e-01 Pos: 0.405 Neg: 0.481	Data time: 0.0213, Train time: 6.1867, Iter time: 6.2080
11/05 08:19:46 Train Epoch: 7 [80/477], Current Loss: 8.817e-01 Pos: 0.395 Neg: 0.487	Data time: 0.0068, Train time: 6.1713, Iter time: 6.1781
11/05 08:23:53 Train Epoch: 7 [120/477], Current Loss: 8.816e-01 Pos: 0.390 Neg: 0.492	Data time: 0.0064, Train time: 6.1722, Iter time: 6.1786
11/05 08:28:04 Train Epoch: 7 [160/477], Current Loss: 8.825e-01 Pos: 0.391 Neg: 0.491	Data time: 0.0079, Train time: 6.2705, Iter time: 6.2784
11/05 08:32:10 Train Epoch: 7 [200/477], Current Loss: 8.854e-01 Pos: 0.390 Neg: 0.496	Data time: 0.0067, Train time: 6.1348, Iter time: 6.1415
11/05 08:36:19 Train Epoch: 7 [240/477], Current Loss: 8.860e-01 Pos: 0.370 Neg: 0.516	Data time: 0.0087, Train time: 6.2290, Iter time: 6.2378
11/05 08:40:26 Train Epoch: 7 [280/477], Current Loss: 8.881e-01 Pos: 0.394 Neg: 0.494	Data time: 0.0081, Train time: 6.1514, Iter time: 6.1595
11/05 08:45:04 Train Epoch: 7 [320/477], Current Loss: 8.845e-01 Pos: 0.397 Neg: 0.487	Data time: 0.0137, Train time: 6.9357, Iter time: 6.9494
11/05 08:49:13 Train Epoch: 7 [360/477], Current Loss: 8.830e-01 Pos: 0.394 Neg: 0.489	Data time: 0.0090, Train time: 6.2344, Iter time: 6.2434
11/05 08:53:20 Train Epoch: 7 [400/477], Current Loss: 8.826e-01 Pos: 0.390 Neg: 0.493	Data time: 0.0090, Train time: 6.1488, Iter time: 6.1578
11/05 08:57:29 Train Epoch: 7 [440/477], Current Loss: 8.821e-01 Pos: 0.387 Neg: 0.495	Data time: 0.0095, Train time: 6.2234, Iter time: 6.2329
11/05 09:01:09 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 09:01:09 Resetting the data loader seed to 0
11/05 09:04:31 Validation iter 101 / 400 : Data Loading Time: 0.033, Feature Extraction Time: 0.887, Matching Time: 1.055, Loss: 0.981, RTE: 171.682, RRE: 0.655, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 09:07:52 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.884, Matching Time: 1.080, Loss: 0.986, RTE: 169.820, RRE: 0.668, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 09:11:10 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.887, Matching Time: 1.079, Loss: 0.985, RTE: 172.221, RRE: 0.689, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 09:14:31 Final Loss: 0.983, RTE: 173.452, RRE: 0.698, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 09:14:32 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/05 09:14:32  Epoch: 8, LR: [0.093206534790699]
11/05 09:15:00 Train Epoch: 8 [0/477], Current Loss: 8.816e-01 Pos: 0.392 Neg: 0.490	Data time: 19.9401, Train time: 8.0155, Iter time: 27.9556
11/05 09:19:22 Train Epoch: 8 [40/477], Current Loss: 8.817e-01 Pos: 0.393 Neg: 0.489	Data time: 0.0083, Train time: 6.5392, Iter time: 6.5475
11/05 09:23:30 Train Epoch: 8 [80/477], Current Loss: 8.814e-01 Pos: 0.391 Neg: 0.491	Data time: 0.0069, Train time: 6.1831, Iter time: 6.1900
11/05 09:27:36 Train Epoch: 8 [120/477], Current Loss: 8.818e-01 Pos: 0.384 Neg: 0.497	Data time: 0.0063, Train time: 6.1443, Iter time: 6.1506
11/05 09:31:45 Train Epoch: 8 [160/477], Current Loss: 8.816e-01 Pos: 0.387 Neg: 0.494	Data time: 0.0066, Train time: 6.2186, Iter time: 6.2252
11/05 09:35:56 Train Epoch: 8 [200/477], Current Loss: 8.813e-01 Pos: 0.395 Neg: 0.487	Data time: 0.0072, Train time: 6.2685, Iter time: 6.2757
11/05 09:40:04 Train Epoch: 8 [240/477], Current Loss: 8.813e-01 Pos: 0.392 Neg: 0.490	Data time: 0.0080, Train time: 6.2110, Iter time: 6.2190
11/05 09:44:13 Train Epoch: 8 [280/477], Current Loss: 8.856e-01 Pos: 0.359 Neg: 0.526	Data time: 0.0089, Train time: 6.2157, Iter time: 6.2246
11/05 09:48:57 Train Epoch: 8 [320/477], Current Loss: 8.849e-01 Pos: 0.374 Neg: 0.511	Data time: 0.0131, Train time: 7.0746, Iter time: 7.0877
11/05 09:53:08 Train Epoch: 8 [360/477], Current Loss: 8.824e-01 Pos: 0.395 Neg: 0.488	Data time: 0.0098, Train time: 6.2716, Iter time: 6.2814
11/05 09:57:18 Train Epoch: 8 [400/477], Current Loss: 8.817e-01 Pos: 0.394 Neg: 0.487	Data time: 0.0093, Train time: 6.2346, Iter time: 6.2439
11/05 10:01:25 Train Epoch: 8 [440/477], Current Loss: 8.817e-01 Pos: 0.393 Neg: 0.489	Data time: 0.0095, Train time: 6.1720, Iter time: 6.1814
11/05 10:05:04 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 10:05:04 Resetting the data loader seed to 0
11/05 10:08:31 Validation iter 101 / 400 : Data Loading Time: 0.032, Feature Extraction Time: 0.896, Matching Time: 1.104, Loss: 0.981, RTE: 173.654, RRE: 0.674, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 10:11:47 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.880, Matching Time: 1.089, Loss: 0.987, RTE: 181.810, RRE: 0.698, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 10:15:02 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.878, Matching Time: 1.077, Loss: 0.987, RTE: 173.696, RRE: 0.693, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 10:18:23 Final Loss: 0.984, RTE: 169.041, RRE: 0.683, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 10:18:24 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/05 10:18:24  Epoch: 9, LR: [0.09227446944279201]
11/05 10:18:50 Train Epoch: 9 [0/477], Current Loss: 8.846e-01 Pos: 0.390 Neg: 0.495	Data time: 18.6116, Train time: 7.6090, Iter time: 26.2206
11/05 10:23:22 Train Epoch: 9 [40/477], Current Loss: 8.818e-01 Pos: 0.392 Neg: 0.490	Data time: 0.0174, Train time: 6.7776, Iter time: 6.7950
11/05 10:27:28 Train Epoch: 9 [80/477], Current Loss: 8.812e-01 Pos: 0.393 Neg: 0.488	Data time: 0.0066, Train time: 6.1452, Iter time: 6.1518
11/05 10:31:35 Train Epoch: 9 [120/477], Current Loss: 8.819e-01 Pos: 0.390 Neg: 0.492	Data time: 0.0070, Train time: 6.1451, Iter time: 6.1521
11/05 10:35:46 Train Epoch: 9 [160/477], Current Loss: 8.811e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0077, Train time: 6.2890, Iter time: 6.2967
11/05 10:39:51 Train Epoch: 9 [200/477], Current Loss: 8.814e-01 Pos: 0.392 Neg: 0.490	Data time: 0.0066, Train time: 6.1037, Iter time: 6.1103
11/05 10:43:59 Train Epoch: 9 [240/477], Current Loss: 8.817e-01 Pos: 0.393 Neg: 0.489	Data time: 0.0086, Train time: 6.2046, Iter time: 6.2132
11/05 10:48:03 Train Epoch: 9 [280/477], Current Loss: 8.814e-01 Pos: 0.394 Neg: 0.487	Data time: 0.0087, Train time: 6.0788, Iter time: 6.0875
11/05 10:52:36 Train Epoch: 9 [320/477], Current Loss: 8.813e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0115, Train time: 6.8088, Iter time: 6.8203
11/05 10:56:46 Train Epoch: 9 [360/477], Current Loss: 8.813e-01 Pos: 0.390 Neg: 0.492	Data time: 0.0090, Train time: 6.2412, Iter time: 6.2501
11/05 11:00:55 Train Epoch: 9 [400/477], Current Loss: 8.817e-01 Pos: 0.381 Neg: 0.501	Data time: 0.0091, Train time: 6.2181, Iter time: 6.2272
11/05 11:05:04 Train Epoch: 9 [440/477], Current Loss: 8.813e-01 Pos: 0.392 Neg: 0.490	Data time: 0.0095, Train time: 6.2047, Iter time: 6.2142
11/05 11:08:42 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 11:08:42 Resetting the data loader seed to 0
11/05 11:12:09 Validation iter 101 / 400 : Data Loading Time: 0.027, Feature Extraction Time: 0.891, Matching Time: 1.110, Loss: 0.983, RTE: 167.406, RRE: 0.707, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 11:15:33 Validation iter 201 / 400 : Data Loading Time: 0.009, Feature Extraction Time: 0.892, Matching Time: 1.121, Loss: 0.978, RTE: 161.768, RRE: 0.661, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 11:18:52 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.889, Matching Time: 1.106, Loss: 0.984, RTE: 165.801, RRE: 0.678, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 11:21:58 Final Loss: 0.984, RTE: 171.113, RRE: 0.689, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 11:21:58 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/05 11:21:58  Epoch: 10, LR: [0.09135172474836409]
11/05 11:22:12 Train Epoch: 10 [0/477], Current Loss: 8.811e-01 Pos: 0.394 Neg: 0.487	Data time: 7.7318, Train time: 5.8223, Iter time: 13.5542
11/05 11:26:58 Train Epoch: 10 [40/477], Current Loss: 8.809e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0096, Train time: 7.1528, Iter time: 7.1623
11/05 11:31:09 Train Epoch: 10 [80/477], Current Loss: 8.808e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0064, Train time: 6.2452, Iter time: 6.2516
11/05 11:35:21 Train Epoch: 10 [120/477], Current Loss: 8.862e-01 Pos: 0.403 Neg: 0.483	Data time: 0.0066, Train time: 6.3108, Iter time: 6.3174
11/05 11:39:29 Train Epoch: 10 [160/477], Current Loss: 8.820e-01 Pos: 0.393 Neg: 0.489	Data time: 0.0068, Train time: 6.1860, Iter time: 6.1928
11/05 11:43:36 Train Epoch: 10 [200/477], Current Loss: 8.822e-01 Pos: 0.398 Neg: 0.484	Data time: 0.0074, Train time: 6.1725, Iter time: 6.1799
11/05 11:47:44 Train Epoch: 10 [240/477], Current Loss: 8.809e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0076, Train time: 6.1745, Iter time: 6.1821
11/05 11:51:46 Train Epoch: 10 [280/477], Current Loss: 8.815e-01 Pos: 0.393 Neg: 0.489	Data time: 0.0079, Train time: 6.0452, Iter time: 6.0531
11/05 11:56:25 Train Epoch: 10 [320/477], Current Loss: 8.811e-01 Pos: 0.387 Neg: 0.494	Data time: 0.0120, Train time: 6.9700, Iter time: 6.9820
11/05 12:00:36 Train Epoch: 10 [360/477], Current Loss: 8.810e-01 Pos: 0.394 Neg: 0.487	Data time: 0.0104, Train time: 6.2579, Iter time: 6.2683
11/05 12:04:45 Train Epoch: 10 [400/477], Current Loss: 8.820e-01 Pos: 0.398 Neg: 0.484	Data time: 0.0103, Train time: 6.2288, Iter time: 6.2392
11/05 12:08:49 Train Epoch: 10 [440/477], Current Loss: 8.809e-01 Pos: 0.394 Neg: 0.487	Data time: 0.0099, Train time: 6.0718, Iter time: 6.0818
11/05 12:12:25 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 12:12:25 Resetting the data loader seed to 0
11/05 12:15:47 Validation iter 101 / 400 : Data Loading Time: 0.024, Feature Extraction Time: 0.882, Matching Time: 1.075, Loss: 0.995, RTE: 183.224, RRE: 0.699, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 12:19:12 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.884, Matching Time: 1.108, Loss: 0.992, RTE: 177.374, RRE: 0.692, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 12:22:24 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.884, Matching Time: 1.078, Loss: 0.992, RTE: 176.745, RRE: 0.700, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 12:25:41 Final Loss: 0.991, RTE: 172.876, RRE: 0.689, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 12:25:42 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/05 12:25:42  Epoch: 11, LR: [0.09043820750088044]
11/05 12:26:06 Train Epoch: 11 [0/477], Current Loss: 8.809e-01 Pos: 0.391 Neg: 0.490	Data time: 16.0422, Train time: 8.1352, Iter time: 24.1773
11/05 12:30:44 Train Epoch: 11 [40/477], Current Loss: 8.808e-01 Pos: 0.393 Neg: 0.487	Data time: 0.0087, Train time: 6.9256, Iter time: 6.9343
11/05 12:34:54 Train Epoch: 11 [80/477], Current Loss: 8.810e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0063, Train time: 6.2544, Iter time: 6.2607
11/05 12:38:58 Train Epoch: 11 [120/477], Current Loss: 8.810e-01 Pos: 0.386 Neg: 0.495	Data time: 0.0074, Train time: 6.0774, Iter time: 6.0847
11/05 12:43:06 Train Epoch: 11 [160/477], Current Loss: 8.807e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0071, Train time: 6.1931, Iter time: 6.2002
11/05 12:47:12 Train Epoch: 11 [200/477], Current Loss: 8.810e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0074, Train time: 6.1612, Iter time: 6.1686
11/05 12:51:20 Train Epoch: 11 [240/477], Current Loss: 8.808e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0081, Train time: 6.1875, Iter time: 6.1956
11/05 12:55:32 Train Epoch: 11 [280/477], Current Loss: 8.807e-01 Pos: 0.394 Neg: 0.487	Data time: 0.0084, Train time: 6.2810, Iter time: 6.2893
11/05 13:00:06 Train Epoch: 11 [320/477], Current Loss: 8.807e-01 Pos: 0.388 Neg: 0.493	Data time: 0.0133, Train time: 6.8385, Iter time: 6.8518
11/05 13:04:23 Train Epoch: 11 [360/477], Current Loss: 8.808e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0095, Train time: 6.4221, Iter time: 6.4316
11/05 13:08:30 Train Epoch: 11 [400/477], Current Loss: 8.807e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0089, Train time: 6.1615, Iter time: 6.1704
11/05 13:12:37 Train Epoch: 11 [440/477], Current Loss: 8.808e-01 Pos: 0.389 Neg: 0.492	Data time: 0.0095, Train time: 6.1634, Iter time: 6.1729
11/05 13:16:13 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 13:16:13 Resetting the data loader seed to 0
11/05 13:19:40 Validation iter 101 / 400 : Data Loading Time: 0.030, Feature Extraction Time: 0.890, Matching Time: 1.113, Loss: 0.988, RTE: 167.626, RRE: 0.676, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 13:23:04 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.891, Matching Time: 1.118, Loss: 0.986, RTE: 176.729, RRE: 0.684, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 13:26:19 Validation iter 301 / 400 : Data Loading Time: 0.009, Feature Extraction Time: 0.893, Matching Time: 1.089, Loss: 0.987, RTE: 176.615, RRE: 0.678, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 13:29:36 Final Loss: 0.988, RTE: 172.702, RRE: 0.688, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 13:29:37 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/05 13:29:37  Epoch: 12, LR: [0.08953382542587164]
11/05 13:29:57 Train Epoch: 12 [0/477], Current Loss: 8.810e-01 Pos: 0.392 Neg: 0.489	Data time: 12.7240, Train time: 7.0835, Iter time: 19.8074
11/05 13:34:32 Train Epoch: 12 [40/477], Current Loss: 8.808e-01 Pos: 0.393 Neg: 0.488	Data time: 0.0120, Train time: 6.8637, Iter time: 6.8756
11/05 13:38:40 Train Epoch: 12 [80/477], Current Loss: 8.807e-01 Pos: 0.387 Neg: 0.493	Data time: 0.0060, Train time: 6.1956, Iter time: 6.2016
11/05 13:42:48 Train Epoch: 12 [120/477], Current Loss: 8.808e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0066, Train time: 6.1870, Iter time: 6.1936
11/05 13:46:54 Train Epoch: 12 [160/477], Current Loss: 8.808e-01 Pos: 0.394 Neg: 0.486	Data time: 0.0070, Train time: 6.1572, Iter time: 6.1642
11/05 13:51:07 Train Epoch: 12 [200/477], Current Loss: 8.806e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0077, Train time: 6.3077, Iter time: 6.3154
11/05 13:55:16 Train Epoch: 12 [240/477], Current Loss: 8.882e-01 Pos: 0.410 Neg: 0.478	Data time: 0.0085, Train time: 6.2139, Iter time: 6.2224
11/05 13:59:27 Train Epoch: 12 [280/477], Current Loss: 8.819e-01 Pos: 0.395 Neg: 0.486	Data time: 0.0099, Train time: 6.2597, Iter time: 6.2696
11/05 14:03:43 Train Epoch: 12 [320/477], Current Loss: 8.814e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0107, Train time: 6.3853, Iter time: 6.3961
11/05 14:08:11 Train Epoch: 12 [360/477], Current Loss: 8.809e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0112, Train time: 6.6861, Iter time: 6.6973
11/05 14:12:19 Train Epoch: 12 [400/477], Current Loss: 8.813e-01 Pos: 0.393 Neg: 0.488	Data time: 0.0095, Train time: 6.1948, Iter time: 6.2043
11/05 14:16:27 Train Epoch: 12 [440/477], Current Loss: 8.808e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0102, Train time: 6.2056, Iter time: 6.2158
11/05 14:20:06 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 14:20:07 Resetting the data loader seed to 0
11/05 14:23:26 Validation iter 101 / 400 : Data Loading Time: 0.028, Feature Extraction Time: 0.881, Matching Time: 1.049, Loss: 0.988, RTE: 158.605, RRE: 0.669, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 14:26:40 Validation iter 201 / 400 : Data Loading Time: 0.007, Feature Extraction Time: 0.882, Matching Time: 1.042, Loss: 0.988, RTE: 164.840, RRE: 0.672, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 14:29:58 Validation iter 301 / 400 : Data Loading Time: 0.007, Feature Extraction Time: 0.877, Matching Time: 1.058, Loss: 0.984, RTE: 167.664, RRE: 0.678, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 14:33:08 Final Loss: 0.987, RTE: 173.034, RRE: 0.696, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 14:33:08 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/05 14:33:08  Epoch: 13, LR: [0.08863848717161293]
11/05 14:33:30 Train Epoch: 13 [0/477], Current Loss: 8.809e-01 Pos: 0.390 Neg: 0.491	Data time: 14.4156, Train time: 7.0073, Iter time: 21.4229
11/05 14:38:04 Train Epoch: 13 [40/477], Current Loss: 8.812e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0249, Train time: 6.8284, Iter time: 6.8533
11/05 14:42:14 Train Epoch: 13 [80/477], Current Loss: 8.808e-01 Pos: 0.393 Neg: 0.488	Data time: 0.0066, Train time: 6.2453, Iter time: 6.2520
11/05 14:46:26 Train Epoch: 13 [120/477], Current Loss: 8.812e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0070, Train time: 6.2877, Iter time: 6.2947
11/05 14:50:32 Train Epoch: 13 [160/477], Current Loss: 8.807e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0068, Train time: 6.1607, Iter time: 6.1675
11/05 14:54:40 Train Epoch: 13 [200/477], Current Loss: 8.828e-01 Pos: 0.390 Neg: 0.492	Data time: 0.0081, Train time: 6.1805, Iter time: 6.1886
11/05 14:58:45 Train Epoch: 13 [240/477], Current Loss: 8.815e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0075, Train time: 6.1278, Iter time: 6.1353
11/05 15:02:53 Train Epoch: 13 [280/477], Current Loss: 8.813e-01 Pos: 0.389 Neg: 0.493	Data time: 0.0083, Train time: 6.1770, Iter time: 6.1854
11/05 15:06:59 Train Epoch: 13 [320/477], Current Loss: 8.817e-01 Pos: 0.394 Neg: 0.488	Data time: 0.0079, Train time: 6.1433, Iter time: 6.1512
11/05 15:11:38 Train Epoch: 13 [360/477], Current Loss: 8.814e-01 Pos: 0.392 Neg: 0.490	Data time: 0.0117, Train time: 6.9574, Iter time: 6.9691
11/05 15:15:45 Train Epoch: 13 [400/477], Current Loss: 8.809e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0097, Train time: 6.1817, Iter time: 6.1914
11/05 15:19:51 Train Epoch: 13 [440/477], Current Loss: 8.814e-01 Pos: 0.388 Neg: 0.493	Data time: 0.0090, Train time: 6.1265, Iter time: 6.1355
11/05 15:23:27 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 15:23:27 Resetting the data loader seed to 0
11/05 15:26:54 Validation iter 101 / 400 : Data Loading Time: 0.028, Feature Extraction Time: 0.885, Matching Time: 1.114, Loss: 0.995, RTE: 168.828, RRE: 0.698, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 15:30:10 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.886, Matching Time: 1.083, Loss: 0.994, RTE: 168.935, RRE: 0.664, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 15:33:28 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.883, Matching Time: 1.081, Loss: 0.995, RTE: 172.178, RRE: 0.665, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 15:36:38 Final Loss: 0.991, RTE: 171.223, RRE: 0.684, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 15:36:38 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/05 15:36:38  Epoch: 14, LR: [0.08775210229989679]
11/05 15:37:00 Train Epoch: 14 [0/477], Current Loss: 8.812e-01 Pos: 0.390 Neg: 0.491	Data time: 14.7927, Train time: 6.9810, Iter time: 21.7737
11/05 15:41:29 Train Epoch: 14 [40/477], Current Loss: 8.914e-01 Pos: 0.373 Neg: 0.518	Data time: 0.0308, Train time: 6.6740, Iter time: 6.7047
11/05 15:45:49 Train Epoch: 14 [80/477], Current Loss: 8.823e-01 Pos: 0.393 Neg: 0.489	Data time: 0.0073, Train time: 6.5114, Iter time: 6.5188
11/05 15:49:59 Train Epoch: 14 [120/477], Current Loss: 8.818e-01 Pos: 0.395 Neg: 0.487	Data time: 0.0067, Train time: 6.2194, Iter time: 6.2261
11/05 15:54:00 Train Epoch: 14 [160/477], Current Loss: 8.811e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0072, Train time: 6.0222, Iter time: 6.0294
11/05 15:58:13 Train Epoch: 14 [200/477], Current Loss: 8.817e-01 Pos: 0.387 Neg: 0.494	Data time: 0.0076, Train time: 6.3226, Iter time: 6.3302
11/05 16:02:20 Train Epoch: 14 [240/477], Current Loss: 8.813e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0085, Train time: 6.1562, Iter time: 6.1647
11/05 16:06:24 Train Epoch: 14 [280/477], Current Loss: 8.809e-01 Pos: 0.389 Neg: 0.492	Data time: 0.0088, Train time: 6.1037, Iter time: 6.1125
11/05 16:10:32 Train Epoch: 14 [320/477], Current Loss: 8.806e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0095, Train time: 6.1949, Iter time: 6.2043
11/05 16:15:13 Train Epoch: 14 [360/477], Current Loss: 8.810e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0138, Train time: 7.0081, Iter time: 7.0219
11/05 16:19:22 Train Epoch: 14 [400/477], Current Loss: 8.807e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0103, Train time: 6.2217, Iter time: 6.2320
11/05 16:23:26 Train Epoch: 14 [440/477], Current Loss: 8.805e-01 Pos: 0.391 Neg: 0.489	Data time: 0.0098, Train time: 6.0781, Iter time: 6.0879
11/05 16:27:08 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 16:27:08 Resetting the data loader seed to 0
11/05 16:30:33 Validation iter 101 / 400 : Data Loading Time: 0.035, Feature Extraction Time: 0.884, Matching Time: 1.091, Loss: 0.980, RTE: 173.041, RRE: 0.702, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 16:33:50 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.886, Matching Time: 1.078, Loss: 0.987, RTE: 181.814, RRE: 0.723, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 16:37:10 Validation iter 301 / 400 : Data Loading Time: 0.009, Feature Extraction Time: 0.879, Matching Time: 1.087, Loss: 0.990, RTE: 170.067, RRE: 0.681, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 16:40:19 Final Loss: 0.992, RTE: 172.631, RRE: 0.692, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 16:40:19 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/05 16:40:19  Epoch: 15, LR: [0.08687458127689783]
11/05 16:40:41 Train Epoch: 15 [0/477], Current Loss: 8.806e-01 Pos: 0.391 Neg: 0.490	Data time: 14.5528, Train time: 6.9915, Iter time: 21.5443
11/05 16:45:01 Train Epoch: 15 [40/477], Current Loss: 8.814e-01 Pos: 0.380 Neg: 0.501	Data time: 0.0386, Train time: 6.4623, Iter time: 6.5009
11/05 16:49:29 Train Epoch: 15 [80/477], Current Loss: 8.814e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0090, Train time: 6.6780, Iter time: 6.6869
11/05 16:53:34 Train Epoch: 15 [120/477], Current Loss: 8.808e-01 Pos: 0.386 Neg: 0.494	Data time: 0.0066, Train time: 6.1348, Iter time: 6.1414
11/05 16:57:43 Train Epoch: 15 [160/477], Current Loss: 8.808e-01 Pos: 0.390 Neg: 0.490	Data time: 0.0068, Train time: 6.2025, Iter time: 6.2093
11/05 17:01:50 Train Epoch: 15 [200/477], Current Loss: 8.817e-01 Pos: 0.391 Neg: 0.491	Data time: 0.0079, Train time: 6.1628, Iter time: 6.1707
11/05 17:05:53 Train Epoch: 15 [240/477], Current Loss: 8.807e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0077, Train time: 6.0786, Iter time: 6.0863
11/05 17:10:02 Train Epoch: 15 [280/477], Current Loss: 8.805e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0082, Train time: 6.2104, Iter time: 6.2187
11/05 17:14:11 Train Epoch: 15 [320/477], Current Loss: 8.805e-01 Pos: 0.390 Neg: 0.490	Data time: 0.0088, Train time: 6.2246, Iter time: 6.2333
11/05 17:18:46 Train Epoch: 15 [360/477], Current Loss: 8.811e-01 Pos: 0.388 Neg: 0.493	Data time: 0.0114, Train time: 6.8660, Iter time: 6.8773
11/05 17:22:56 Train Epoch: 15 [400/477], Current Loss: 8.807e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0086, Train time: 6.2241, Iter time: 6.2326
11/05 17:27:07 Train Epoch: 15 [440/477], Current Loss: 8.804e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0098, Train time: 6.2629, Iter time: 6.2728
11/05 17:30:46 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 17:30:46 Resetting the data loader seed to 0
11/05 17:34:09 Validation iter 101 / 400 : Data Loading Time: 0.039, Feature Extraction Time: 0.895, Matching Time: 1.059, Loss: 0.986, RTE: 185.579, RRE: 0.698, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 17:37:26 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.883, Matching Time: 1.069, Loss: 0.991, RTE: 178.818, RRE: 0.689, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 17:40:45 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.884, Matching Time: 1.073, Loss: 0.993, RTE: 174.277, RRE: 0.686, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 17:43:58 Final Loss: 0.990, RTE: 171.153, RRE: 0.682, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 17:43:58 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/05 17:43:58  Epoch: 16, LR: [0.08600583546412885]
11/05 17:44:17 Train Epoch: 16 [0/477], Current Loss: 8.806e-01 Pos: 0.388 Neg: 0.493	Data time: 11.5923, Train time: 6.7251, Iter time: 18.3174
11/05 17:48:25 Train Epoch: 16 [40/477], Current Loss: 8.804e-01 Pos: 0.392 Neg: 0.488	Data time: 0.0337, Train time: 6.1560, Iter time: 6.1897
11/05 17:53:05 Train Epoch: 16 [80/477], Current Loss: 8.807e-01 Pos: 0.394 Neg: 0.487	Data time: 0.0091, Train time: 7.0046, Iter time: 7.0137
11/05 17:57:15 Train Epoch: 16 [120/477], Current Loss: 8.804e-01 Pos: 0.391 Neg: 0.489	Data time: 0.0067, Train time: 6.2495, Iter time: 6.2563
11/05 18:01:21 Train Epoch: 16 [160/477], Current Loss: 8.806e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0070, Train time: 6.1339, Iter time: 6.1409
11/05 18:05:34 Train Epoch: 16 [200/477], Current Loss: 8.805e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0070, Train time: 6.3090, Iter time: 6.3160
11/05 18:09:46 Train Epoch: 16 [240/477], Current Loss: 1.393e+00 Pos: 0.393 Neg: 1.001	Data time: 0.0076, Train time: 6.2964, Iter time: 6.3040
11/05 18:13:51 Train Epoch: 16 [280/477], Current Loss: 8.888e-01 Pos: 0.403 Neg: 0.486	Data time: 0.0080, Train time: 6.1168, Iter time: 6.1248
11/05 18:17:58 Train Epoch: 16 [320/477], Current Loss: 1.271e+00 Pos: 0.545 Neg: 0.726	Data time: 0.0095, Train time: 6.1774, Iter time: 6.1869
11/05 18:22:41 Train Epoch: 16 [360/477], Current Loss: 8.975e-01 Pos: 0.359 Neg: 0.539	Data time: 0.0127, Train time: 7.0547, Iter time: 7.0675
11/05 18:26:52 Train Epoch: 16 [400/477], Current Loss: 8.897e-01 Pos: 0.387 Neg: 0.502	Data time: 0.0097, Train time: 6.2506, Iter time: 6.2603
11/05 18:30:55 Train Epoch: 16 [440/477], Current Loss: 8.837e-01 Pos: 0.393 Neg: 0.491	Data time: 0.0099, Train time: 6.0774, Iter time: 6.0873
11/05 18:34:31 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 18:34:31 Resetting the data loader seed to 0
11/05 18:37:57 Validation iter 101 / 400 : Data Loading Time: 0.035, Feature Extraction Time: 0.880, Matching Time: 1.103, Loss: 0.991, RTE: 172.263, RRE: 0.687, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 18:41:08 Validation iter 201 / 400 : Data Loading Time: 0.007, Feature Extraction Time: 0.879, Matching Time: 1.061, Loss: 0.992, RTE: 169.601, RRE: 0.696, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 18:44:16 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.872, Matching Time: 1.041, Loss: 0.990, RTE: 176.322, RRE: 0.706, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 18:47:28 Final Loss: 0.989, RTE: 179.219, RRE: 0.720, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 18:47:28 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/05 18:47:28  Epoch: 17, LR: [0.08514577710948756]
11/05 18:47:47 Train Epoch: 17 [0/477], Current Loss: 8.860e-01 Pos: 0.392 Neg: 0.494	Data time: 11.9883, Train time: 7.0213, Iter time: 19.0096
11/05 18:51:57 Train Epoch: 17 [40/477], Current Loss: 8.967e-01 Pos: 0.439 Neg: 0.458	Data time: 0.0358, Train time: 6.2052, Iter time: 6.2411
11/05 18:56:30 Train Epoch: 17 [80/477], Current Loss: 8.844e-01 Pos: 0.392 Neg: 0.492	Data time: 0.0087, Train time: 6.8224, Iter time: 6.8311
11/05 19:00:38 Train Epoch: 17 [120/477], Current Loss: 8.831e-01 Pos: 0.389 Neg: 0.494	Data time: 0.0068, Train time: 6.1771, Iter time: 6.1839
11/05 19:04:46 Train Epoch: 17 [160/477], Current Loss: 8.819e-01 Pos: 0.397 Neg: 0.485	Data time: 0.0074, Train time: 6.1937, Iter time: 6.2011
11/05 19:08:53 Train Epoch: 17 [200/477], Current Loss: 8.817e-01 Pos: 0.397 Neg: 0.484	Data time: 0.0071, Train time: 6.1762, Iter time: 6.1833
11/05 19:13:05 Train Epoch: 17 [240/477], Current Loss: 8.833e-01 Pos: 0.396 Neg: 0.488	Data time: 0.0081, Train time: 6.2972, Iter time: 6.3053
11/05 19:17:14 Train Epoch: 17 [280/477], Current Loss: 8.841e-01 Pos: 0.394 Neg: 0.490	Data time: 0.0085, Train time: 6.2130, Iter time: 6.2215
11/05 19:21:25 Train Epoch: 17 [320/477], Current Loss: 8.862e-01 Pos: 0.400 Neg: 0.486	Data time: 0.0090, Train time: 6.2516, Iter time: 6.2606
11/05 19:26:13 Train Epoch: 17 [360/477], Current Loss: 8.836e-01 Pos: 0.386 Neg: 0.497	Data time: 0.0109, Train time: 7.1955, Iter time: 7.2064
11/05 19:30:42 Train Epoch: 17 [400/477], Current Loss: 8.824e-01 Pos: 0.386 Neg: 0.496	Data time: 0.0123, Train time: 6.7216, Iter time: 6.7339
11/05 19:34:51 Train Epoch: 17 [440/477], Current Loss: 8.825e-01 Pos: 0.389 Neg: 0.493	Data time: 0.0106, Train time: 6.1990, Iter time: 6.2096
11/05 19:38:28 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 19:38:29 Resetting the data loader seed to 0
11/05 19:41:46 Validation iter 101 / 400 : Data Loading Time: 0.024, Feature Extraction Time: 0.881, Matching Time: 1.035, Loss: 0.986, RTE: 189.535, RRE: 0.665, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 19:45:06 Validation iter 201 / 400 : Data Loading Time: 0.009, Feature Extraction Time: 0.893, Matching Time: 1.055, Loss: 0.983, RTE: 182.189, RRE: 0.706, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 19:48:31 Validation iter 301 / 400 : Data Loading Time: 0.009, Feature Extraction Time: 0.900, Matching Time: 1.073, Loss: 0.987, RTE: 176.192, RRE: 0.707, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 19:51:44 Final Loss: 0.986, RTE: 172.314, RRE: 0.690, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 19:51:44 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/05 19:51:44  Epoch: 18, LR: [0.08429431933839268]
11/05 19:52:07 Train Epoch: 18 [0/477], Current Loss: 8.817e-01 Pos: 0.391 Neg: 0.491	Data time: 13.8892, Train time: 8.1406, Iter time: 22.0298
11/05 19:56:17 Train Epoch: 18 [40/477], Current Loss: 8.816e-01 Pos: 0.393 Neg: 0.488	Data time: 0.0157, Train time: 6.2321, Iter time: 6.2478
11/05 20:00:57 Train Epoch: 18 [80/477], Current Loss: 8.962e-01 Pos: 0.407 Neg: 0.489	Data time: 0.0084, Train time: 6.9832, Iter time: 6.9916
11/05 20:05:09 Train Epoch: 18 [120/477], Current Loss: 8.827e-01 Pos: 0.394 Neg: 0.489	Data time: 0.0072, Train time: 6.3050, Iter time: 6.3123
11/05 20:09:18 Train Epoch: 18 [160/477], Current Loss: 8.842e-01 Pos: 0.398 Neg: 0.486	Data time: 0.0080, Train time: 6.2072, Iter time: 6.2153
11/05 20:13:26 Train Epoch: 18 [200/477], Current Loss: 8.822e-01 Pos: 0.395 Neg: 0.488	Data time: 0.0076, Train time: 6.2102, Iter time: 6.2178
11/05 20:17:32 Train Epoch: 18 [240/477], Current Loss: 8.840e-01 Pos: 0.395 Neg: 0.489	Data time: 0.0074, Train time: 6.1234, Iter time: 6.1308
11/05 20:21:39 Train Epoch: 18 [280/477], Current Loss: 8.824e-01 Pos: 0.397 Neg: 0.485	Data time: 0.0085, Train time: 6.1657, Iter time: 6.1742
11/05 20:25:43 Train Epoch: 18 [320/477], Current Loss: 8.818e-01 Pos: 0.389 Neg: 0.493	Data time: 0.0085, Train time: 6.0892, Iter time: 6.0977
11/05 20:29:57 Train Epoch: 18 [360/477], Current Loss: 8.813e-01 Pos: 0.389 Neg: 0.492	Data time: 0.0096, Train time: 6.3475, Iter time: 6.3572
11/05 20:34:24 Train Epoch: 18 [400/477], Current Loss: 8.927e-01 Pos: 0.365 Neg: 0.528	Data time: 0.0111, Train time: 6.6555, Iter time: 6.6665
11/05 20:38:36 Train Epoch: 18 [440/477], Current Loss: 8.824e-01 Pos: 0.383 Neg: 0.500	Data time: 0.0094, Train time: 6.3034, Iter time: 6.3127
11/05 20:42:15 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 20:42:15 Resetting the data loader seed to 0
11/05 20:45:34 Validation iter 101 / 400 : Data Loading Time: 0.034, Feature Extraction Time: 0.883, Matching Time: 1.040, Loss: 0.991, RTE: 178.940, RRE: 0.727, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 20:48:51 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.881, Matching Time: 1.052, Loss: 0.986, RTE: 169.034, RRE: 0.685, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 20:52:06 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.882, Matching Time: 1.051, Loss: 0.989, RTE: 170.078, RRE: 0.695, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 20:55:13 Final Loss: 0.986, RTE: 172.015, RRE: 0.696, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 20:55:13 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/05 20:55:13  Epoch: 19, LR: [0.08345137614500875]
11/05 20:55:35 Train Epoch: 19 [0/477], Current Loss: 8.812e-01 Pos: 0.390 Neg: 0.491	Data time: 13.9650, Train time: 7.6797, Iter time: 21.6447
11/05 20:59:45 Train Epoch: 19 [40/477], Current Loss: 8.852e-01 Pos: 0.397 Neg: 0.488	Data time: 0.0086, Train time: 6.2358, Iter time: 6.2444
11/05 21:04:19 Train Epoch: 19 [80/477], Current Loss: 8.829e-01 Pos: 0.394 Neg: 0.489	Data time: 0.0080, Train time: 6.8406, Iter time: 6.8487
11/05 21:08:34 Train Epoch: 19 [120/477], Current Loss: 8.820e-01 Pos: 0.401 Neg: 0.481	Data time: 0.0078, Train time: 6.3755, Iter time: 6.3833
11/05 21:12:41 Train Epoch: 19 [160/477], Current Loss: 8.818e-01 Pos: 0.388 Neg: 0.494	Data time: 0.0071, Train time: 6.1553, Iter time: 6.1625
11/05 21:16:56 Train Epoch: 19 [200/477], Current Loss: 8.829e-01 Pos: 0.398 Neg: 0.484	Data time: 0.0079, Train time: 6.3762, Iter time: 6.3841
11/05 21:21:05 Train Epoch: 19 [240/477], Current Loss: 8.822e-01 Pos: 0.391 Neg: 0.491	Data time: 0.0079, Train time: 6.2287, Iter time: 6.2366
11/05 21:25:18 Train Epoch: 19 [280/477], Current Loss: 8.814e-01 Pos: 0.394 Neg: 0.487	Data time: 0.0089, Train time: 6.3054, Iter time: 6.3143
11/05 21:29:23 Train Epoch: 19 [320/477], Current Loss: 8.811e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0093, Train time: 6.1095, Iter time: 6.1188
11/05 21:33:33 Train Epoch: 19 [360/477], Current Loss: 8.815e-01 Pos: 0.395 Neg: 0.486	Data time: 0.0087, Train time: 6.2417, Iter time: 6.2504
11/05 21:38:16 Train Epoch: 19 [400/477], Current Loss: 8.814e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0146, Train time: 7.0631, Iter time: 7.0776
11/05 21:42:28 Train Epoch: 19 [440/477], Current Loss: 8.818e-01 Pos: 0.396 Neg: 0.486	Data time: 0.0094, Train time: 6.2943, Iter time: 6.3037
11/05 21:46:03 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 21:46:03 Resetting the data loader seed to 0
11/05 21:49:28 Validation iter 101 / 400 : Data Loading Time: 0.029, Feature Extraction Time: 0.894, Matching Time: 1.089, Loss: 0.986, RTE: 157.035, RRE: 0.656, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 21:52:45 Validation iter 201 / 400 : Data Loading Time: 0.009, Feature Extraction Time: 0.884, Matching Time: 1.084, Loss: 0.991, RTE: 169.585, RRE: 0.709, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 21:55:59 Validation iter 301 / 400 : Data Loading Time: 0.007, Feature Extraction Time: 0.879, Matching Time: 1.072, Loss: 0.991, RTE: 168.789, RRE: 0.699, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 21:59:10 Final Loss: 0.991, RTE: 171.897, RRE: 0.701, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 21:59:10 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/05 21:59:10  Epoch: 20, LR: [0.08261686238355867]
11/05 21:59:30 Train Epoch: 20 [0/477], Current Loss: 8.807e-01 Pos: 0.391 Neg: 0.490	Data time: 12.7646, Train time: 7.1392, Iter time: 19.9038
11/05 22:03:49 Train Epoch: 20 [40/477], Current Loss: 8.821e-01 Pos: 0.374 Neg: 0.508	Data time: 0.0290, Train time: 6.4363, Iter time: 6.4653
11/05 22:08:29 Train Epoch: 20 [80/477], Current Loss: 8.821e-01 Pos: 0.393 Neg: 0.489	Data time: 0.0106, Train time: 6.9926, Iter time: 7.0031
11/05 22:12:50 Train Epoch: 20 [120/477], Current Loss: 8.820e-01 Pos: 0.391 Neg: 0.491	Data time: 0.0080, Train time: 6.5280, Iter time: 6.5360
11/05 22:17:05 Train Epoch: 20 [160/477], Current Loss: 8.811e-01 Pos: 0.397 Neg: 0.485	Data time: 0.0082, Train time: 6.3514, Iter time: 6.3595
11/05 22:21:14 Train Epoch: 20 [200/477], Current Loss: 8.809e-01 Pos: 0.395 Neg: 0.485	Data time: 0.0074, Train time: 6.2189, Iter time: 6.2263
11/05 22:25:23 Train Epoch: 20 [240/477], Current Loss: 8.812e-01 Pos: 0.388 Neg: 0.493	Data time: 0.0079, Train time: 6.2254, Iter time: 6.2334
11/05 22:29:35 Train Epoch: 20 [280/477], Current Loss: 8.810e-01 Pos: 0.393 Neg: 0.488	Data time: 0.0083, Train time: 6.2787, Iter time: 6.2870
11/05 22:33:40 Train Epoch: 20 [320/477], Current Loss: 8.813e-01 Pos: 0.389 Neg: 0.492	Data time: 0.0089, Train time: 6.1134, Iter time: 6.1224
11/05 22:37:49 Train Epoch: 20 [360/477], Current Loss: 8.810e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0089, Train time: 6.2243, Iter time: 6.2332
11/05 22:42:28 Train Epoch: 20 [400/477], Current Loss: 8.809e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0125, Train time: 6.9739, Iter time: 6.9864
11/05 22:46:38 Train Epoch: 20 [440/477], Current Loss: 8.810e-01 Pos: 0.386 Neg: 0.495	Data time: 0.0106, Train time: 6.2172, Iter time: 6.2278
11/05 22:50:18 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 22:50:18 Resetting the data loader seed to 0
11/05 22:53:44 Validation iter 101 / 400 : Data Loading Time: 0.026, Feature Extraction Time: 0.897, Matching Time: 1.099, Loss: 0.989, RTE: 172.914, RRE: 0.722, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 22:56:59 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.886, Matching Time: 1.080, Loss: 0.992, RTE: 172.737, RRE: 0.736, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 23:00:18 Validation iter 301 / 400 : Data Loading Time: 0.007, Feature Extraction Time: 0.886, Matching Time: 1.079, Loss: 0.993, RTE: 174.549, RRE: 0.727, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 23:03:32 Final Loss: 0.993, RTE: 173.920, RRE: 0.710, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/05 23:03:32 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/05 23:03:32  Epoch: 21, LR: [0.08179069375972309]
11/05 23:03:53 Train Epoch: 21 [0/477], Current Loss: 8.807e-01 Pos: 0.390 Neg: 0.491	Data time: 12.9640, Train time: 7.2016, Iter time: 20.1656
11/05 23:08:09 Train Epoch: 21 [40/477], Current Loss: 8.810e-01 Pos: 0.388 Neg: 0.493	Data time: 0.0089, Train time: 6.3973, Iter time: 6.4062
11/05 23:12:20 Train Epoch: 21 [80/477], Current Loss: 8.808e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0072, Train time: 6.2752, Iter time: 6.2824
11/05 23:16:43 Train Epoch: 21 [120/477], Current Loss: 8.821e-01 Pos: 0.399 Neg: 0.483	Data time: 0.0093, Train time: 6.5591, Iter time: 6.5683
11/05 23:20:49 Train Epoch: 21 [160/477], Current Loss: 8.810e-01 Pos: 0.387 Neg: 0.495	Data time: 0.0068, Train time: 6.1541, Iter time: 6.1609
11/05 23:25:02 Train Epoch: 21 [200/477], Current Loss: 8.806e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0080, Train time: 6.3062, Iter time: 6.3142
11/05 23:29:09 Train Epoch: 21 [240/477], Current Loss: 8.806e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0076, Train time: 6.1617, Iter time: 6.1693
11/05 23:33:22 Train Epoch: 21 [280/477], Current Loss: 8.812e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0075, Train time: 6.3244, Iter time: 6.3319
11/05 23:37:29 Train Epoch: 21 [320/477], Current Loss: 8.809e-01 Pos: 0.386 Neg: 0.495	Data time: 0.0090, Train time: 6.1504, Iter time: 6.1594
11/05 23:41:38 Train Epoch: 21 [360/477], Current Loss: 8.812e-01 Pos: 0.389 Neg: 0.492	Data time: 0.0090, Train time: 6.2209, Iter time: 6.2299
11/05 23:46:14 Train Epoch: 21 [400/477], Current Loss: 8.811e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0123, Train time: 6.8822, Iter time: 6.8945
11/05 23:50:28 Train Epoch: 21 [440/477], Current Loss: 8.809e-01 Pos: 0.389 Neg: 0.492	Data time: 0.0092, Train time: 6.3401, Iter time: 6.3493
11/05 23:54:08 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/05 23:54:08 Resetting the data loader seed to 0
11/05 23:57:40 Validation iter 101 / 400 : Data Loading Time: 0.036, Feature Extraction Time: 0.891, Matching Time: 1.154, Loss: 0.988, RTE: 182.233, RRE: 0.728, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/06 00:00:58 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.896, Matching Time: 1.104, Loss: 0.989, RTE: 176.370, RRE: 0.713, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/06 00:04:17 Validation iter 301 / 400 : Data Loading Time: 0.009, Feature Extraction Time: 0.889, Matching Time: 1.099, Loss: 0.990, RTE: 176.065, RRE: 0.711, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/06 00:07:29 Final Loss: 0.990, RTE: 172.262, RRE: 0.701, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/06 00:07:30 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/06 00:07:30  Epoch: 22, LR: [0.08097278682212584]
11/06 00:07:51 Train Epoch: 22 [0/477], Current Loss: 8.807e-01 Pos: 0.395 Neg: 0.485	Data time: 13.6884, Train time: 6.9648, Iter time: 20.6532
11/06 00:11:56 Train Epoch: 22 [40/477], Current Loss: 8.807e-01 Pos: 0.393 Neg: 0.488	Data time: 0.0238, Train time: 6.1223, Iter time: 6.1462
11/06 00:16:04 Train Epoch: 22 [80/477], Current Loss: 8.809e-01 Pos: 0.393 Neg: 0.488	Data time: 0.0068, Train time: 6.1838, Iter time: 6.1906
11/06 00:20:39 Train Epoch: 22 [120/477], Current Loss: 8.812e-01 Pos: 0.387 Neg: 0.494	Data time: 0.0093, Train time: 6.8556, Iter time: 6.8649
11/06 00:24:43 Train Epoch: 22 [160/477], Current Loss: 8.804e-01 Pos: 0.392 Neg: 0.488	Data time: 0.0070, Train time: 6.0919, Iter time: 6.0990
11/06 00:28:52 Train Epoch: 22 [200/477], Current Loss: 8.812e-01 Pos: 0.385 Neg: 0.497	Data time: 0.0068, Train time: 6.2237, Iter time: 6.2305
11/06 00:33:07 Train Epoch: 22 [240/477], Current Loss: 8.810e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0086, Train time: 6.3664, Iter time: 6.3750
11/06 00:37:11 Train Epoch: 22 [280/477], Current Loss: 8.807e-01 Pos: 0.395 Neg: 0.486	Data time: 0.0079, Train time: 6.0843, Iter time: 6.0922
11/06 00:41:24 Train Epoch: 22 [320/477], Current Loss: 8.806e-01 Pos: 0.392 Neg: 0.488	Data time: 0.0086, Train time: 6.3354, Iter time: 6.3440
11/06 00:45:29 Train Epoch: 22 [360/477], Current Loss: 8.812e-01 Pos: 0.392 Neg: 0.490	Data time: 0.0086, Train time: 6.1161, Iter time: 6.1247
11/06 00:50:06 Train Epoch: 22 [400/477], Current Loss: 8.805e-01 Pos: 0.388 Neg: 0.492	Data time: 0.0123, Train time: 6.9074, Iter time: 6.9198
11/06 00:54:19 Train Epoch: 22 [440/477], Current Loss: 8.805e-01 Pos: 0.392 Neg: 0.488	Data time: 0.0098, Train time: 6.2948, Iter time: 6.3046
11/06 00:57:58 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
11/06 00:57:58 Resetting the data loader seed to 0
11/06 01:01:16 Validation iter 101 / 400 : Data Loading Time: 0.028, Feature Extraction Time: 0.863, Matching Time: 1.057, Loss: 0.994, RTE: 172.051, RRE: 0.671, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/06 01:04:33 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.873, Matching Time: 1.059, Loss: 0.991, RTE: 172.346, RRE: 0.695, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/06 01:07:48 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.875, Matching Time: 1.058, Loss: 0.989, RTE: 168.390, RRE: 0.696, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/06 01:10:57 Final Loss: 0.990, RTE: 173.591, RRE: 0.705, Hit Ratio: 0.001, Feat Match Ratio: 0.000
11/06 01:10:57 Current best val model with feat_match_ratio: 0.0 at epoch 1
11/06 01:10:57  Epoch: 23, LR: [0.08016305895390459]
11/06 01:11:19 Train Epoch: 23 [0/477], Current Loss: 8.804e-01 Pos: 0.393 Neg: 0.488	Data time: 14.3961, Train time: 7.7215, Iter time: 22.1176
11/06 01:15:48 Train Epoch: 23 [40/477], Current Loss: 8.808e-01 Pos: 0.383 Neg: 0.497	Data time: 0.0155, Train time: 6.6908, Iter time: 6.7063
11/06 01:20:00 Train Epoch: 23 [80/477], Current Loss: 8.806e-01 Pos: 0.394 Neg: 0.487	Data time: 0.0074, Train time: 6.3064, Iter time: 6.3138
11/06 01:24:44 Train Epoch: 23 [120/477], Current Loss: 8.808e-01 Pos: 0.389 Neg: 0.492	Data time: 0.0091, Train time: 7.0951, Iter time: 7.1042
11/06 01:28:52 Train Epoch: 23 [160/477], Current Loss: 8.809e-01 Pos: 0.396 Neg: 0.485	Data time: 0.0069, Train time: 6.1689, Iter time: 6.1759
11/06 01:33:17 Train Epoch: 23 [200/477], Current Loss: 8.809e-01 Pos: 0.394 Neg: 0.487	Data time: 0.0079, Train time: 6.6209, Iter time: 6.6289
11/06 01:37:29 Train Epoch: 23 [240/477], Current Loss: 8.803e-01 Pos: 0.390 Neg: 0.490	Data time: 0.0082, Train time: 6.2939, Iter time: 6.3021
11/06 01:41:51 Train Epoch: 23 [280/477], Current Loss: 8.806e-01 Pos: 0.388 Neg: 0.493	Data time: 0.0102, Train time: 6.5529, Iter time: 6.5631
11/06 01:46:15 Train Epoch: 23 [320/477], Current Loss: 8.804e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0097, Train time: 6.5701, Iter time: 6.5798
./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16--gtremoval2/2020-11-06_01-47-05
Host:  bb8
Conda  /home/allie/miniconda3/condabin/conda
/home/allie/code/benchmark/FCGF
Version:  5002ea8a5a10230c9c771aa8ac7991fcc03b0502
Git diff

diff --git a/config.py b/config.py
index 6c9fb68..9e1ccb9 100644
--- a/config.py
+++ b/config.py
@@ -90,7 +90,7 @@ opt_arg.add_argument(
 
 misc_arg = add_argument_group('Misc')
 misc_arg.add_argument('--use_gpu', type=str2bool, default=True)
-misc_arg.add_argument('--weights', type=str, default=None)
+misc_arg.add_argument('--weights', type=str, default="")
 misc_arg.add_argument('--weights_dir', type=str, default=None)
 misc_arg.add_argument('--resume', type=str, default=None)
 misc_arg.add_argument('--resume_dir', type=str, default=None)
diff --git a/lib/data_loaders.py b/lib/data_loaders.py
index e0e264d..fe07a78 100644
--- a/lib/data_loaders.py
+++ b/lib/data_loaders.py
@@ -692,7 +692,7 @@ class KITTIMapDataset(PairDataset):
         self.split = phase
         self.config = config
 
-        self.path_map_dict = os.path.join(root, "kitti_map_files_d3feat_%s.pkl" % self.split)
+        self.path_map_dict = os.path.join(root, "kitti_map_files_d3feat_%s_fcgf.pkl" % self.split)
         self.read_map_data()
         self.prepare_kitti_ply()#split=split)
        
@@ -712,10 +712,10 @@ class KITTIMapDataset(PairDataset):
         for id_log in subset_names:
             path_map = os.path.join(self.root, "kitti_maps_cmr_new", "map-%02d_0.05.ply" % (int(id_log)))
             print("Load map : ", path_map)
-            pcd = open3d.io.read_point_cloud(path_map)
-            pcd = pcd.voxel_down_sample(self.config.first_subsampling_dl)
-            pcd, ind = pcd.remove_radius_outlier(nb_points=7, radius=self.config.first_subsampling_dl*2)
-            self.dict_maps[id_log] = torch.Tensor(np.asarray(pcd.points))#.to(self.config.device)
+            pcd = o3d.io.read_point_cloud(path_map)
+            pcd = pcd.voxel_down_sample(self.config.voxel_size)
+            pcd, ind = pcd.remove_radius_outlier(nb_points=7, radius=self.config.voxel_size*2)
+            self.dict_maps[id_log] = np.asarray(pcd.points)#torch.Tensor(np.asarray(pcd.points))#.to(self.config.device)
 
 
         with open(self.path_map_dict, 'wb') as f: 
@@ -724,7 +724,7 @@ class KITTIMapDataset(PairDataset):
             print('Saved!')    
 
     def get_local_map(self,T_lidar, drive):#, force_select_points=False):
-        dist = torch.sqrt(((self.dict_maps[drive] - T_lidar[0:3,3])**2).sum(axis=1))
+        dist = np.sqrt(((self.dict_maps[drive] - T_lidar[0:3,3])**2).sum(axis=1))
         ind_valid_local = dist < self.config.depth_max
 
         return self.dict_maps[drive][ind_valid_local]
@@ -780,31 +780,47 @@ class KITTIMapDataset(PairDataset):
             xyz1 = scale * xyz1
 
         # Voxelization
-        xyz0_th = xyz0#torch.from_numpy(xyz0)
+        xyz0_th = torch.from_numpy(xyz0)#xyz0#torch.from_numpy(xyz0)
         xyz1_th = torch.from_numpy(xyz1)
     
         sel0 = ME.utils.sparse_quantize(xyz0_th / self.voxel_size, return_index=True)
         sel1 = ME.utils.sparse_quantize(xyz1_th / self.voxel_size, return_index=True)
     
         # Make point clouds using voxelized points
-        pcd0 = make_open3d_point_cloud(xyz0[sel0])
-        pcd1 = make_open3d_point_cloud(xyz1[sel1])
+        #pcd0 = make_open3d_point_cloud(xyz0[sel0])
+        #pcd1 = make_open3d_point_cloud(xyz1[sel1])
+
+        import copy
+        pcd0_trans = make_open3d_point_cloud(xyz0[sel0])
+        pcd0_trans.transform(trans)
+        xyz0_sel_trans = np.asarray(pcd0_trans.points)
+        h_ground = -1.5
+        ind_0 = xyz0_sel_trans[:,2] > h_ground
+        ind_1 = xyz1[sel1][:,2] > h_ground
+
+        pcd0 = make_open3d_point_cloud(xyz0[sel0][ind_0])
+        pcd1 = make_open3d_point_cloud(xyz1[sel1][ind_1])
+    
+        #xyz0_th = torch.from_numpy(xyz0)#xyz0#torch.from_numpy(xyz0)
+        #xyz1_th = torch.from_numpy(xyz1)
     
         # Get matches
         matches = get_matching_indices(pcd0, pcd1, trans, matching_search_voxel_size)
-        #if len(matches) < 1000:
-        #  raise ValueError(f"{drive}, {t0}, {t1}")
+        if len(matches) < 1000:
+            raise ValueError(f"{drive}, {idx}")
         #matches = np.array(matches)
 
 
         # Get features
-        npts0 = len(sel0)
-        npts1 = len(sel1)
-    
+
         feats_train0, feats_train1 = [], []
     
-        unique_xyz0_th = xyz0_th[sel0]
-        unique_xyz1_th = xyz1_th[sel1]
+        unique_xyz0_th = xyz0_th[sel0][ind_0]
+        unique_xyz1_th = xyz1_th[sel1][ind_1]
+        npts0 = unique_xyz0_th.shape[0]
+        npts1 = unique_xyz1_th.shape[0]
+    
+
     
         feats_train0.append(torch.ones((npts0, 1)))
         feats_train1.append(torch.ones((npts1, 1)))
@@ -818,8 +834,9 @@ class KITTIMapDataset(PairDataset):
         #print("single batch = ")
         #print(coords0.shape)
         #print(coords1.shape)
-        #print(len(matches) )        
+           
         if False:#len(matches) < 10:#coords0.shape[0] < 10 or coords1.shape[0] < 10:
+            print("num matches = ", len(matches) )     
             #print("matches shape = ", matches.shape)
 
             print(coords0)
@@ -850,7 +867,7 @@ class KITTIMapDataset(PairDataset):
             o3d.io.write_point_cloud("unique_xyz0_th_trans_%d.ply" % idx, pcd_target) 
 #    
 
-            #import pdb; pdb.set_trace()
+            import pdb; pdb.set_trace()
             #pcd_target = o3d.geometry.PointCloud()
             #pcd_target.points = o3d.utility.Vector3dVector(coords0)
             #o3d.io.write_point_cloud("coords0.ply" , pcd_target) 
diff --git a/lib/eval.py b/lib/eval.py
index 4afa0ef..7ef9b67 100644
--- a/lib/eval.py
+++ b/lib/eval.py
@@ -17,6 +17,7 @@ def find_nn_cpu(feat0, feat1, return_distance=False):
 
 def find_nn_gpu(F0, F1, nn_max_n=-1, return_distance=False, dist_type='SquareL2'):
   # Too much memory if F0 or F1 large. Divide the F0
+
   if nn_max_n > 1:
     N = len(F0)
     C = int(np.ceil(N / nn_max_n))
diff --git a/lib/trainer.py b/lib/trainer.py
index e6299f8..bd950bc 100644
--- a/lib/trainer.py
+++ b/lib/trainer.py
@@ -330,9 +330,62 @@ class ContrastiveLossTrainer(AlignmentTrainer):
       F1 = self.model(sinput1).F
       feat_timer.toc()
 
+      #import pdb; pdb.set_trace()
+      if False:
+
+          from sklearn.decomposition import PCA
+          import open3d as o3d
+          pc0 = o3d.geometry.PointCloud()
+          pc0.points = o3d.utility.Vector3dVector(xyz0.numpy())
+          pca = PCA(n_components=3)
+    
+          colors =   pca.fit_transform(torch.cat((F0, F1), axis=0).cpu().numpy())
+          colors -= colors.min()
+          colors /= colors.max()
+          pc0.colors = o3d.utility.Vector3dVector(colors[0:F0.shape[0]])
+    
+          o3d.io.write_point_cloud("pc0.ply" , pc0) 
+          pc0.transform(T_gt.numpy())
+          o3d.io.write_point_cloud("pc0_trans.ply" , pc0) 
+    
+          pc1 = o3d.geometry.PointCloud()
+          pc1.points = o3d.utility.Vector3dVector(xyz1.numpy())
+          pc1.colors = o3d.utility.Vector3dVector(colors[F0.shape[0]:])
+          o3d.io.write_point_cloud("pc1.ply" , pc1) 
+
+
+          ind_0 = input_dict['correspondences'][:,0].type(torch.long)
+          ind_1 = input_dict['correspondences'][:,1].type(torch.long)
+
+          pc1.points = o3d.utility.Vector3dVector(xyz1[ind_1].numpy())
+          pc1.colors = o3d.utility.Vector3dVector(colors[F0.shape[0]:][ind_1])
+          o3d.io.write_point_cloud("pc1_corr.ply" , pc1) 
+
+
+          pc0.points = o3d.utility.Vector3dVector(xyz0[ind_0].numpy())
+          pc0.colors = o3d.utility.Vector3dVector(colors[:F0.shape[0]][ind_0])
+          pc0.transform(T_gt.numpy())
+          o3d.io.write_point_cloud("pc0_trans_corr.ply" , pc0) 
+
+
+
+
       matching_timer.tic()
       xyz0, xyz1, T_gt = input_dict['pcd0'], input_dict['pcd1'], input_dict['T_gt']
       xyz0_corr, xyz1_corr = self.find_corr(xyz0, xyz1, F0, F1, subsample_size=5000)
+
+
+
+      #pc0.points = o3d.utility.Vector3dVector(xyz0_corr.numpy())
+      #pc0.transform(T_gt.numpy())
+      #o3d.io.write_point_cloud("xyz0_corr_trans.ply" , pc0) 
+#
+      #pc0.points = o3d.utility.Vector3dVector(xyz1_corr.numpy())
+      #o3d.io.write_point_cloud("xyz1_corr_trans.ply" , pc0) 
+
+
+
+
       T_est = te.est_quad_linear_robust(xyz0_corr, xyz1_corr)
 
       loss = corr_dist(T_est, T_gt, xyz0, xyz1, weight=None)
@@ -484,7 +537,6 @@ class HardestContrastiveLossTrainer(ContrastiveLossTrainer):
             coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
 
         F1 = self.model(sinput1).F
-
         pos_pairs = input_dict['correspondences']
         pos_loss, neg_loss = self.contrastive_hardest_negative_loss(
             F0,
diff --git a/nohup.out b/nohup.out
index 887d1c2..94dd3ea 100644
--- a/nohup.out
+++ b/nohup.out
@@ -1,573 +1,1717 @@
-./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b8i1-modelnout16/2020-11-02_17-08-48
+./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22
 Host:  bb8
-Conda  /home/allie/miniconda3/condabin/conda
+Conda  /home/allie/miniconda3/bin/conda
 /home/allie/code/benchmark/FCGF
-Version:  f0863a9ba4a29f677c0ddd2248cf4e56b9318add
+Version:  5002ea8a5a10230c9c771aa8ac7991fcc03b0502
 Git diff
 
-diff --git a/config.py b/config.py
-index 476402d..87abb73 100644
---- a/config.py
-+++ b/config.py
-@@ -112,14 +112,28 @@ data_arg.add_argument(
-     '--threed_match_dir', type=str, default="/home/chrischoy/datasets/FCGF/threedmatch")
- data_arg.add_argument(
-     '--kitti_root', type=str, default="/home/chrischoy/datasets/FCGF/kitti/")
-+
- data_arg.add_argument(
-     '--kitti_max_time_diff',
-     type=int,
-     default=3,
-     help='max time difference between pairs (non inclusive)')
-+
- data_arg.add_argument('--kitti_date', type=str, default='2011_09_26')
- 
- 
-+#arguments for KITTI map dataset
-+#for kitti ground truth poses (optimized by loop-closing SLAM)
-+data_arg.add_argument(
-+    '--path_cmrdata', type=str, default="/home/allie/dataset/cmr_original") 
-+data_arg.add_argument(
-+    '--depth_max', type=float, default=50) 
-+data_arg.add_argument(
-+    '--num_min_map_points', type=int, default=2e4) 
-+
-+
-+
-+
- def get_config():
-   args = parser.parse_args()
-   return args
 diff --git a/lib/data_loaders.py b/lib/data_loaders.py
-index 2bc475a..a45bee3 100644
+index e0e264d..e40a571 100644
 --- a/lib/data_loaders.py
 +++ b/lib/data_loaders.py
-@@ -18,10 +18,42 @@ import lib.transforms as t
- import MinkowskiEngine as ME
- 
- import open3d as o3d
-+import pickle
- 
- kitti_cache = {}
- kitti_icp_cache = {}
- 
-+eps = 1e-10
-+import csv
-+def read_csv_file(path_file):
-+    lines = []
-+    with open(path_file, "r") as f:
-+        reader = csv.reader(f, delimiter="\t")
-+        for i, line in enumerate(reader):
-+            if i >= 1:
-+                lines.append(np.asarray(line[0].split(',')[1:]).astype('float'))
-+    return lines
-+
-+
-+def pred_to_matrix_np(pred):
-+
-+    cam_T = np.tile(np.eye(4)[np.newaxis,:,:],[pred.shape[0], 1, 1])
-+    cam_T[:,0:3, 3] = pred[:, 0:3]
-+    s = np.tile(np.linalg.norm(pred[:,3:], axis=1)[:,np.newaxis],[1,4])
-+
-+    q = pred[:,3:] / (s+eps)
-+
-+    cam_T[:,0,0] = 1- 2*s[:,0]*(q[:,2]**2 + q[:,3]**2)
-+    cam_T[:,0,1] = 2   *s[:,0]*(q[:,1] * q[:,2] - q[:,3] * q[:,0])
-+    cam_T[:,0,2] = 2   *s[:,0]*(q[:,1] * q[:,3] + q[:,2] * q[:,0])
-+    cam_T[:,1,0] = 2   *s[:,0]*(q[:,1]*q[:,2] + q[:,3]*q[:,0])
-+    cam_T[:,1,1] = 1- 2*s[:,0]*(q[:,1]**2 + q[:,3]**2)
-+    cam_T[:,1,2] = 2   *s[:,0]*(q[:,2] * q[:,3] - q[:,1] * q[:,0])
-+    cam_T[:,2,0] = 2   *s[:,0]*(q[:,1] * q[:,3] - q[:,2] * q[:,0])
-+    cam_T[:,2,1] = 2   *s[:,0]*(q[:,2] * q[:,3] + q[:,1] * q[:,0])
-+    cam_T[:,2,2] = 1 -2*s[:,0]*(q[:,1]**2 + q[:,2]**2)
-+
-+    return cam_T
- 
- def collate_pair_fn(list_data):
-   xyz0, xyz1, coords0, coords1, feats0, feats1, matching_inds, trans = list(
-@@ -632,8 +664,278 @@ class ThreeDMatchPairDataset(IndoorPairDataset):
-       'test': './config/test_3dmatch.txt'
-   }
- 
-+class KITTIMapDataset(PairDataset):
-+    AUGMENT = None
-+    DATA_FILES = {
-+        'train': './config/train_kitti_map.txt', #log ids
-+        'val': './config/val_kitti_map.txt',
-+        'test': './config/test_kitti_map.txt'
-+    }
-+    TEST_RANDOM_ROTATION = False
-+    IS_ODOMETRY = True
-+    #MAX_TIME_DIFF = 3
-+
-+    def __init__(self,
-+               phase,
-+               transform=None,
-+               random_rotation=True,
-+               random_scale=True,
-+               manual_seed=False,
-+               config=None):
-+
-+
-+    #(self, root, split, config, input_threads=8, first_subsampling_dl=0.30):#, load_test=False):
-+        
-+        PairDataset.__init__(self, phase, transform, random_rotation, random_scale,
-+                         manual_seed, config)
-+
-+        self.root = root = os.path.join(config.kitti_root, 'dataset')
-+        self.split = phase
-+        self.config = config
-+
-+        self.path_map_dict = os.path.join(root, "kitti_map_files_d3feat_%s.pkl" % self.split)
-+        self.read_map_data()
-+        self.prepare_kitti_ply()#split=split)
-+       
-+
-+    def __len__(self):
-+        return self.num
-+
-+    def read_map_data(self):
-+        if os.path.exists(self.path_map_dict):
-+            with open(self.path_map_dict, 'rb') as f:
-+                self.dict_maps = pickle.load(f)
-+            return 
-+
-+
-+        subset_names = open(self.DATA_FILES[self.split]).read().split()
-+        self.dict_maps = {}
-+        for id_log in subset_names:
-+            path_map = os.path.join(self.root, "kitti_maps_cmr_new", "map-%02d_0.05.ply" % (int(id_log)))
-+            print("Load map : ", path_map)
-+            pcd = open3d.io.read_point_cloud(path_map)
-+            pcd = pcd.voxel_down_sample(self.config.first_subsampling_dl)
-+            pcd, ind = pcd.remove_radius_outlier(nb_points=7, radius=self.config.first_subsampling_dl*2)
-+            self.dict_maps[id_log] = torch.Tensor(np.asarray(pcd.points))#.to(self.config.device)
-+
-+
-+        with open(self.path_map_dict, 'wb') as f: 
-+            print('Saving map file to ', self.path_map_dict)
-+            pickle.dump(self.dict_maps, f)
-+            print('Saved!')    
-+
-+    def get_local_map(self,T_lidar, drive):#, force_select_points=False):
-+        dist = torch.sqrt(((self.dict_maps[drive] - T_lidar[0:3,3])**2).sum(axis=1))
-+        ind_valid_local = dist < self.config.depth_max
-+
-+        return self.dict_maps[drive][ind_valid_local]
-+
-+            
-+    def prepare_kitti_ply(self):#, split='train'):
-+        #max_time_diff = self.MAX_TIME_DIFF
-+        subset_names = open(self.DATA_FILES[self.split]).read().split()
-+        self.all_pos = []
-+        for dirname in subset_names:
-+            drive_id = int(dirname)
-+            fnames = glob.glob(self.root + '/sequences/%02d/velodyne/*.bin' % drive_id)
-+
-+            assert len(fnames) > 0, f"Make sure that the path {self.root} has data {dirname}"
-+            inames = sorted([int(os.path.split(fname)[-1][:-4]) for fname in fnames])
-+            path_poses = os.path.join(self.config.path_cmrdata, self.split, "kitti-%02d.csv" % drive_id)
-+            list_gt_poses = read_csv_file(path_poses)
-+
-+            for i in range(0,len(inames),2):# curr_time in inames:
-+                
-+
-+                T = pred_to_matrix_np(np.asarray(list_gt_poses[i][np.newaxis,[0,1,2,6,3,4,5]]))[0]
-+                xyz0 = self.get_local_map(T, dirname)
-+
-+                #use the local map as the source
-+                T = np.linalg.inv(T) 
-+                if xyz0.shape[0] < self.config.num_min_map_points:
-+                    continue
-+                
-+                self.files.append((drive_id, inames[i]))#, next_time))
-+                self.all_pos.append( torch.Tensor(T))#.to(self.config.device))
-+        self.num = len(self.files)
-+
-+    def __getitem__(self,idx):# split, idx):
-+        drive = self.files[idx][0]
-+        #t0, t1 = self.files[self.split][idx][1], self.files[self.split][idx][2]
-+
-+        #LiDAR is the target
-+        fname1 = self._get_velodyne_fn(drive,  self.files[idx][1])
-+        xyzr1 = np.fromfile(fname1, dtype=np.float32).reshape(-1, 4) 
-+        xyz1 = xyzr1[:, :3]
-+        
-+        #map is the source
-+        xyz0 = self.get_local_map( np.linalg.inv(self.all_pos[idx]), str(drive))
-+        trans = self.all_pos[idx]# M2
-+
-+        matching_search_voxel_size = self.matching_search_voxel_size
-+        if self.random_scale and random.random() < 0.95:
-+            scale = self.min_scale + \
-+                (self.max_scale - self.min_scale) * random.random()
-+            matching_search_voxel_size *= scale
-+            xyz0 = scale * xyz0
-+            xyz1 = scale * xyz1
-+
-+        # Voxelization
-+        xyz0_th = xyz0#torch.from_numpy(xyz0)
-+        xyz1_th = torch.from_numpy(xyz1)
-+    
-+        sel0 = ME.utils.sparse_quantize(xyz0_th / self.voxel_size, return_index=True)
-+        sel1 = ME.utils.sparse_quantize(xyz1_th / self.voxel_size, return_index=True)
-+    
-+        # Make point clouds using voxelized points
-+        pcd0 = make_open3d_point_cloud(xyz0[sel0])
-+        pcd1 = make_open3d_point_cloud(xyz1[sel1])
-+    
-+        # Get matches
-+        matches = get_matching_indices(pcd0, pcd1, trans, matching_search_voxel_size)
-+        #if len(matches) < 1000:
-+        #  raise ValueError(f"{drive}, {t0}, {t1}")
-+        matches = np.array(matches)
-+
-+
-+        # Get features
-+        npts0 = len(sel0)
-+        npts1 = len(sel1)
-+    
-+        feats_train0, feats_train1 = [], []
-+    
-+        unique_xyz0_th = xyz0_th[sel0]
-+        unique_xyz1_th = xyz1_th[sel1]
-+    
-+        feats_train0.append(torch.ones((npts0, 1)))
-+        feats_train1.append(torch.ones((npts1, 1)))
-+    
-+        feats0 = torch.cat(feats_train0, 1)
-+        feats1 = torch.cat(feats_train1, 1)
-+    
-+        coords0 = torch.floor(unique_xyz0_th / self.voxel_size)
-+        coords1 = torch.floor(unique_xyz1_th / self.voxel_size)
-+ 
-+        #print("matches shape = ", matches.shape)
-+        #print(coords0.shape)
-+        #print(coords1.shape)
-+        #print(coords0)
-+#
-+#
-+        #pcd_target = o3d.geometry.PointCloud()
-+        #pcd_target.points = o3d.utility.Vector3dVector(coords0)
-+        #o3d.io.write_point_cloud("coords0_before.ply" , pcd_target) 
-+#
-+        #pcd_target = o3d.geometry.PointCloud()
-+        #pcd_target.points = o3d.utility.Vector3dVector(coords1)
-+        #o3d.io.write_point_cloud("coords1_before.ply" , pcd_target) 
-+#
-+
-+        if self.transform:
-+          coords0, feats0 = self.transform(coords0, feats0)
-+          coords1, feats1 = self.transform(coords1, feats1)
-+    
-+        
-+        #pcd_target = o3d.geometry.PointCloud()
-+        #pcd_target.points = o3d.utility.Vector3dVector(coords0)
-+        #o3d.io.write_point_cloud("coords0.ply" , pcd_target) 
-+#
-+        #pcd_target = o3d.geometry.PointCloud()
-+        #pcd_target.points = o3d.utility.Vector3dVector(coords1)
-+        #o3d.io.write_point_cloud("coords1.ply" , pcd_target) 
-+#
-+#
-+
-+
-+        return (unique_xyz0_th.float(), unique_xyz1_th.float(), coords0.int(),
-+                coords1.int(), feats0.float(), feats1.float(), matches, trans)
-+    
-+            #return (anc_points, pos_points, unaligned_anc_points, unaligned_pos_points, matches, trans, True)
-+
-+    #def apply_transform(self, pts, trans):
-+    #    R = trans[:3, :3]
-+    #    T = trans[:3, 3]
-+    #    pts = pts @ R.T + T
-+    #    return pts
-+#
-+    #@property
-+    #def velo2cam(self):
-+    #    try:
-+    #        velo2cam = self._velo2cam
-+    #    except AttributeError:
-+    #        R = np.array([
-+    #            7.533745e-03, -9.999714e-01, -6.166020e-04, 1.480249e-02, 7.280733e-04,
-+    #            -9.998902e-01, 9.998621e-01, 7.523790e-03, 1.480755e-02
-+    #        ]).reshape(3, 3)
-+    #        T = np.array([-4.069766e-03, -7.631618e-02, -2.717806e-01]).reshape(3, 1)
-+    #        velo2cam = np.hstack([R, T])
-+    #        self._velo2cam = np.vstack((velo2cam, [0, 0, 0, 1])).T
-+    #    return self._velo2cam
-+#
-+    #def get_video_odometry(self, drive, indices=None, ext='.txt', return_all=False):
-+    #    if self.IS_ODOMETRY:
-+    #        data_path = self.root + '/poses/%02d.txt' % drive
-+    #        if data_path not in kitti_cache:
-+    #            kitti_cache[data_path] = np.genfromtxt(data_path)
-+    #        if return_all:
-+    #            return kitti_cache[data_path]
-+    #        else:
-+    #            return kitti_cache[data_path][indices]
-+    #    else:
-+    #        data_path = self.root + '/' + self.date + '_drive_%04d_sync/oxts/data' % drive
-+    #        odometry = []
-+    #        if indices is None:
-+    #            fnames = glob.glob(self.root + '/' + self.date +
-+    #                               '_drive_%04d_sync/velodyne_points/data/*.bin' % drive)
-+    #            indices = sorted([int(os.path.split(fname)[-1][:-4]) for fname in fnames])
-+#
-+    #        for index in indices:
-+    #            filename = os.path.join(data_path, '%010d%s' % (index, ext))
-+    #            if filename not in kitti_cache:
-+    #                kitti_cache[filename] = np.genfromtxt(filename)
-+    #                odometry.append(kitti_cache[filename])
-+#
-+    #        odometry = np.array(odometry)
-+    #        return odometry
-+#
-+    #def odometry_to_positions(self, odometry):
-+    #    if self.IS_ODOMETRY:
-+    #        T_w_cam0 = odometry.reshape(3, 4)
-+    #        T_w_cam0 = np.vstack((T_w_cam0, [0, 0, 0, 1]))
-+    #        return T_w_cam0
-+    #    else:
-+    #        lat, lon, alt, roll, pitch, yaw = odometry.T[:6]
-+#
-+    #        R = 6378137  # Earth's radius in metres
-+#
-+    #        # convert to metres
-+    #        lat, lon = np.deg2rad(lat), np.deg2rad(lon)
-+    #        mx = R * lon * np.cos(lat)
-+    #        my = R * lat
-+#
-+    #        times = odometry.T[-1]
-+    #        return np.vstack([mx, my, alt, roll, pitch, yaw, times]).T
-+#
-+    def _get_velodyne_fn(self, drive, t):
-+        if self.IS_ODOMETRY:
-+            fname = self.root + '/sequences/%02d/velodyne/%06d.bin' % (drive, t)
-+        else:
-+            fname = self.root + \
-+                    '/' + self.date + '_drive_%04d_sync/velodyne_points/data/%010d.bin' % (
-+                        drive, t)
-+        return fname
-+
-+    #def get_position_transform(self, pos0, pos1, invert=False):
-+    #    T0 = self.pos_transform(pos0)
-+    #    T1 = self.pos_transform(pos1)
-+    #    return (np.dot(T1, np.linalg.inv(T0)).T if not invert else np.dot(
-+    #        np.linalg.inv(T1), T0).T)
-+#
-+
-+
-+
- 
--ALL_DATASETS = [ThreeDMatchPairDataset, KITTIPairDataset, KITTINMPairDataset]
-+ALL_DATASETS = [ThreeDMatchPairDataset, KITTIPairDataset, KITTINMPairDataset, KITTIMapDataset]
- dataset_str_mapping = {d.__name__: d for d in ALL_DATASETS}
- 
- 
+@@ -692,7 +692,7 @@ class KITTIMapDataset(PairDataset):
+         self.split = phase
+         self.config = config
+ 
+-        self.path_map_dict = os.path.join(root, "kitti_map_files_d3feat_%s.pkl" % self.split)
++        self.path_map_dict = os.path.join(root, "kitti_map_files_d3feat_%s_fcgf.pkl" % self.split)
+         self.read_map_data()
+         self.prepare_kitti_ply()#split=split)
+        
+@@ -712,10 +712,10 @@ class KITTIMapDataset(PairDataset):
+         for id_log in subset_names:
+             path_map = os.path.join(self.root, "kitti_maps_cmr_new", "map-%02d_0.05.ply" % (int(id_log)))
+             print("Load map : ", path_map)
+-            pcd = open3d.io.read_point_cloud(path_map)
+-            pcd = pcd.voxel_down_sample(self.config.first_subsampling_dl)
+-            pcd, ind = pcd.remove_radius_outlier(nb_points=7, radius=self.config.first_subsampling_dl*2)
+-            self.dict_maps[id_log] = torch.Tensor(np.asarray(pcd.points))#.to(self.config.device)
++            pcd = o3d.io.read_point_cloud(path_map)
++            pcd = pcd.voxel_down_sample(self.config.voxel_size)
++            pcd, ind = pcd.remove_radius_outlier(nb_points=7, radius=self.config.voxel_size*2)
++            self.dict_maps[id_log] = np.asarray(pcd.points)#torch.Tensor(np.asarray(pcd.points))#.to(self.config.device)
+ 
+ 
+         with open(self.path_map_dict, 'wb') as f: 
+@@ -724,7 +724,7 @@ class KITTIMapDataset(PairDataset):
+             print('Saved!')    
+ 
+     def get_local_map(self,T_lidar, drive):#, force_select_points=False):
+-        dist = torch.sqrt(((self.dict_maps[drive] - T_lidar[0:3,3])**2).sum(axis=1))
++        dist = np.sqrt(((self.dict_maps[drive] - T_lidar[0:3,3])**2).sum(axis=1))
+         ind_valid_local = dist < self.config.depth_max
+ 
+         return self.dict_maps[drive][ind_valid_local]
+@@ -780,7 +780,7 @@ class KITTIMapDataset(PairDataset):
+             xyz1 = scale * xyz1
+ 
+         # Voxelization
+-        xyz0_th = xyz0#torch.from_numpy(xyz0)
++        xyz0_th = torch.from_numpy(xyz0)#xyz0#torch.from_numpy(xyz0)
+         xyz1_th = torch.from_numpy(xyz1)
+     
+         sel0 = ME.utils.sparse_quantize(xyz0_th / self.voxel_size, return_index=True)
+@@ -792,8 +792,8 @@ class KITTIMapDataset(PairDataset):
+     
+         # Get matches
+         matches = get_matching_indices(pcd0, pcd1, trans, matching_search_voxel_size)
+-        #if len(matches) < 1000:
+-        #  raise ValueError(f"{drive}, {t0}, {t1}")
++        if len(matches) < 1000:
++            raise ValueError(f"{drive}, {idx}")
+         #matches = np.array(matches)
+ 
+ 
+@@ -818,8 +818,9 @@ class KITTIMapDataset(PairDataset):
+         #print("single batch = ")
+         #print(coords0.shape)
+         #print(coords1.shape)
+-        #print(len(matches) )        
++           
+         if False:#len(matches) < 10:#coords0.shape[0] < 10 or coords1.shape[0] < 10:
++            print("num matches = ", len(matches) )     
+             #print("matches shape = ", matches.shape)
+ 
+             print(coords0)
+@@ -850,7 +851,7 @@ class KITTIMapDataset(PairDataset):
+             o3d.io.write_point_cloud("unique_xyz0_th_trans_%d.ply" % idx, pcd_target) 
+ #    
+ 
+-            #import pdb; pdb.set_trace()
++            import pdb; pdb.set_trace()
+             #pcd_target = o3d.geometry.PointCloud()
+             #pcd_target.points = o3d.utility.Vector3dVector(coords0)
+             #o3d.io.write_point_cloud("coords0.ply" , pcd_target) 
 diff --git a/lib/trainer.py b/lib/trainer.py
-index e4c230b..e6299f8 100644
+index e6299f8..fbb110f 100644
 --- a/lib/trainer.py
 +++ b/lib/trainer.py
-@@ -234,12 +234,12 @@ class ContrastiveLossTrainer(AlignmentTrainer):
-         # pairs consist of (xyz1 index, xyz0 index)
-         sinput0 = ME.SparseTensor(
-             input_dict['sinput0_F'].to(self.device),
--            coordinates=input_dict['sinput0_C'].to(self.device))
-+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
-         F0 = self.model(sinput0).F
- 
-         sinput1 = ME.SparseTensor(
-             input_dict['sinput1_F'].to(self.device),
--            coordinates=input_dict['sinput1_C'].to(self.device))
-+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
-         F1 = self.model(sinput1).F
+@@ -332,7 +332,7 @@ class ContrastiveLossTrainer(AlignmentTrainer):
  
-         N0, N1 = len(sinput0), len(sinput1)
-@@ -316,14 +316,17 @@ class ContrastiveLossTrainer(AlignmentTrainer):
- 
-       # pairs consist of (xyz1 index, xyz0 index)
-       feat_timer.tic()
-+      
-+      coords=input_dict['sinput0_C'].to(self.device)
-       sinput0 = ME.SparseTensor(
-           input_dict['sinput0_F'].to(self.device),
--          coordinates=input_dict['sinput0_C'].to(self.device))
-+          coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
-+
-       F0 = self.model(sinput0).F
- 
-       sinput1 = ME.SparseTensor(
-           input_dict['sinput1_F'].to(self.device),
--          coordinates=input_dict['sinput1_C'].to(self.device))
-+          coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
-       F1 = self.model(sinput1).F
-       feat_timer.toc()
- 
-@@ -473,12 +476,12 @@ class HardestContrastiveLossTrainer(ContrastiveLossTrainer):
- 
-         sinput0 = ME.SparseTensor(
-             input_dict['sinput0_F'].to(self.device),
--            coordinates=input_dict['sinput0_C'].to(self.device))
-+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
-         F0 = self.model(sinput0).F
- 
-         sinput1 = ME.SparseTensor(
-             input_dict['sinput1_F'].to(self.device),
--            coordinates=input_dict['sinput1_C'].to(self.device))
-+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
- 
-         F1 = self.model(sinput1).F
+       matching_timer.tic()
+       xyz0, xyz1, T_gt = input_dict['pcd0'], input_dict['pcd1'], input_dict['T_gt']
+-      xyz0_corr, xyz1_corr = self.find_corr(xyz0, xyz1, F0, F1, subsample_size=5000)
++      xyz0_corr, xyz1_corr = self.find_corr(xyz0, xyz1, F0, F1, subsample_size=10000)#5000)
+       T_est = te.est_quad_linear_robust(xyz0_corr, xyz1_corr)
  
-@@ -604,12 +607,12 @@ class TripletLossTrainer(ContrastiveLossTrainer):
-         # pairs consist of (xyz1 index, xyz0 index)
-         sinput0 = ME.SparseTensor(
-             input_dict['sinput0_F'].to(self.device),
--            coordinates=input_dict['sinput0_C'].to(self.device))
-+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
-         F0 = self.model(sinput0).F
+       loss = corr_dist(T_est, T_gt, xyz0, xyz1, weight=None)
+@@ -484,7 +484,6 @@ class HardestContrastiveLossTrainer(ContrastiveLossTrainer):
+             coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
  
-         sinput1 = ME.SparseTensor(
-             input_dict['sinput1_F'].to(self.device),
--            coordinates=input_dict['sinput1_C'].to(self.device))
-+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
          F1 = self.model(sinput1).F
- 
+-
          pos_pairs = input_dict['correspondences']
-diff --git a/model/residual_block.py b/model/residual_block.py
-index f06fc5a..759597f 100644
---- a/model/residual_block.py
-+++ b/model/residual_block.py
-@@ -29,7 +29,7 @@ class BasicBlockBase(nn.Module):
-         kernel_size=3,
-         stride=1,
-         dilation=dilation,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm2 = get_norm(self.NORM_TYPE, planes, bn_momentum=bn_momentum, D=D)
-     self.downsample = downsample
-diff --git a/model/resunet.py b/model/resunet.py
-index 6a0e2e1..eb9a4e2 100644
---- a/model/resunet.py
-+++ b/model/resunet.py
-@@ -34,7 +34,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=conv1_kernel_size,
-         stride=1,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm1 = get_norm(NORM_TYPE, CHANNELS[1], bn_momentum=bn_momentum, D=D)
- 
-@@ -47,7 +47,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm2 = get_norm(NORM_TYPE, CHANNELS[2], bn_momentum=bn_momentum, D=D)
- 
-@@ -60,7 +60,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm3 = get_norm(NORM_TYPE, CHANNELS[3], bn_momentum=bn_momentum, D=D)
- 
-@@ -73,7 +73,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm4 = get_norm(NORM_TYPE, CHANNELS[4], bn_momentum=bn_momentum, D=D)
- 
-@@ -86,7 +86,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm4_tr = get_norm(NORM_TYPE, TR_CHANNELS[4], bn_momentum=bn_momentum, D=D)
- 
-@@ -99,7 +99,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm3_tr = get_norm(NORM_TYPE, TR_CHANNELS[3], bn_momentum=bn_momentum, D=D)
- 
-@@ -112,7 +112,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm2_tr = get_norm(NORM_TYPE, TR_CHANNELS[2], bn_momentum=bn_momentum, D=D)
- 
-@@ -125,7 +125,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=1,
-         stride=1,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
- 
-     # self.block1_tr = BasicBlockBN(TR_CHANNELS[1], TR_CHANNELS[1], bn_momentum=bn_momentum, D=D)
-@@ -136,7 +136,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=1,
-         stride=1,
-         dilation=1,
--        bias=True,
-+        has_bias=True,
-         dimension=D)
- 
-   def forward(self, x):
-@@ -187,8 +187,8 @@ class ResUNet2(ME.MinkowskiNetwork):
-     if self.normalize_feature:
-       return ME.SparseTensor(
-           out.F / torch.norm(out.F, p=2, dim=1, keepdim=True),
--          coordinate_map_key=out.coordinate_map_key,
--          coordinate_manager=out.coordinate_manager)
-+          coords_key=out.coords_key,#out.coordinate_map_key,
-+          coords_manager=out.coords_man)#out.coordinate_manager)
-     else:
-       return out
- 
-@@ -244,3 +244,8 @@ class ResUNetIN2D(ResUNetBN2D):
- class ResUNetIN2E(ResUNetBN2E):
-   NORM_TYPE = 'BN'
-   BLOCK_NORM_TYPE = 'IN'
-+
-+class ResUNetBN2C(ResUNet2):
-+  NORM_TYPE = 'BN'
-+  CHANNELS = [None, 32, 64, 128, 256]
-+  TR_CHANNELS = [None, 64, 64, 64, 128]
+         pos_loss, neg_loss = self.contrastive_hardest_negative_loss(
+             F0,
+diff --git a/nohup.out b/nohup.out
+index 887d1c2..875f981 100644
+--- a/nohup.out
++++ b/nohup.out
+@@ -1,1504 +1,95 @@
+-./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b8i1-modelnout16/2020-11-02_17-08-48
++./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22
+ Host:  bb8
+-Conda  /home/allie/miniconda3/condabin/conda
++Conda  /home/allie/miniconda3/bin/conda
+ /home/allie/code/benchmark/FCGF
+-Version:  f0863a9ba4a29f677c0ddd2248cf4e56b9318add
++Version:  5002ea8a5a10230c9c771aa8ac7991fcc03b0502
+ Git diff
+ 
+-diff --git a/config.py b/config.py
+-index 476402d..87abb73 100644
+---- a/config.py
+-+++ b/config.py
+-@@ -112,14 +112,28 @@ data_arg.add_argument(
+-     '--threed_match_dir', type=str, default="/home/chrischoy/datasets/FCGF/threedmatch")
+- data_arg.add_argument(
+-     '--kitti_root', type=str, default="/home/chrischoy/datasets/FCGF/kitti/")
+-+
+- data_arg.add_argument(
+-     '--kitti_max_time_diff',
+-     type=int,
+-     default=3,
+-     help='max time difference between pairs (non inclusive)')
+-+
+- data_arg.add_argument('--kitti_date', type=str, default='2011_09_26')
+- 
+- 
+-+#arguments for KITTI map dataset
+-+#for kitti ground truth poses (optimized by loop-closing SLAM)
+-+data_arg.add_argument(
+-+    '--path_cmrdata', type=str, default="/home/allie/dataset/cmr_original") 
+-+data_arg.add_argument(
+-+    '--depth_max', type=float, default=50) 
+-+data_arg.add_argument(
+-+    '--num_min_map_points', type=int, default=2e4) 
+-+
+-+
+-+
+-+
+- def get_config():
+-   args = parser.parse_args()
+-   return args
+ diff --git a/lib/data_loaders.py b/lib/data_loaders.py
+-index 2bc475a..a45bee3 100644
++index e0e264d..e40a571 100644
+ --- a/lib/data_loaders.py
+ +++ b/lib/data_loaders.py
+-@@ -18,10 +18,42 @@ import lib.transforms as t
+- import MinkowskiEngine as ME
+- 
+- import open3d as o3d
+-+import pickle
+- 
+- kitti_cache = {}
+- kitti_icp_cache = {}
+- 
+-+eps = 1e-10
+-+import csv
+-+def read_csv_file(path_file):
+-+    lines = []
+-+    with open(path_file, "r") as f:
+-+        reader = csv.reader(f, delimiter="\t")
+-+        for i, line in enumerate(reader):
+-+            if i >= 1:
+-+                lines.append(np.asarray(line[0].split(',')[1:]).astype('float'))
+-+    return lines
+-+
+-+
+-+def pred_to_matrix_np(pred):
+-+
+-+    cam_T = np.tile(np.eye(4)[np.newaxis,:,:],[pred.shape[0], 1, 1])
+-+    cam_T[:,0:3, 3] = pred[:, 0:3]
+-+    s = np.tile(np.linalg.norm(pred[:,3:], axis=1)[:,np.newaxis],[1,4])
+-+
+-+    q = pred[:,3:] / (s+eps)
+-+
+-+    cam_T[:,0,0] = 1- 2*s[:,0]*(q[:,2]**2 + q[:,3]**2)
+-+    cam_T[:,0,1] = 2   *s[:,0]*(q[:,1] * q[:,2] - q[:,3] * q[:,0])
+-+    cam_T[:,0,2] = 2   *s[:,0]*(q[:,1] * q[:,3] + q[:,2] * q[:,0])
+-+    cam_T[:,1,0] = 2   *s[:,0]*(q[:,1]*q[:,2] + q[:,3]*q[:,0])
+-+    cam_T[:,1,1] = 1- 2*s[:,0]*(q[:,1]**2 + q[:,3]**2)
+-+    cam_T[:,1,2] = 2   *s[:,0]*(q[:,2] * q[:,3] - q[:,1] * q[:,0])
+-+    cam_T[:,2,0] = 2   *s[:,0]*(q[:,1] * q[:,3] - q[:,2] * q[:,0])
+-+    cam_T[:,2,1] = 2   *s[:,0]*(q[:,2] * q[:,3] + q[:,1] * q[:,0])
+-+    cam_T[:,2,2] = 1 -2*s[:,0]*(q[:,1]**2 + q[:,2]**2)
+-+
+-+    return cam_T
+- 
+- def collate_pair_fn(list_data):
+-   xyz0, xyz1, coords0, coords1, feats0, feats1, matching_inds, trans = list(
+-@@ -632,8 +664,278 @@ class ThreeDMatchPairDataset(IndoorPairDataset):
+-       'test': './config/test_3dmatch.txt'
+-   }
+- 
+-+class KITTIMapDataset(PairDataset):
+-+    AUGMENT = None
+-+    DATA_FILES = {
+-+        'train': './config/train_kitti_map.txt', #log ids
+-+        'val': './config/val_kitti_map.txt',
+-+        'test': './config/test_kitti_map.txt'
+-+    }
+-+    TEST_RANDOM_ROTATION = False
+-+    IS_ODOMETRY = True
+-+    #MAX_TIME_DIFF = 3
+-+
+-+    def __init__(self,
+-+               phase,
+-+               transform=None,
+-+               random_rotation=True,
+-+               random_scale=True,
+-+               manual_seed=False,
+-+               config=None):
+-+
+-+
+-+    #(self, root, split, config, input_threads=8, first_subsampling_dl=0.30):#, load_test=False):
+-+        
+-+        PairDataset.__init__(self, phase, transform, random_rotation, random_scale,
+-+                         manual_seed, config)
+-+
+-+        self.root = root = os.path.join(config.kitti_root, 'dataset')
+-+        self.split = phase
+-+        self.config = config
+-+
+-+        self.path_map_dict = os.path.join(root, "kitti_map_files_d3feat_%s.pkl" % self.split)
+-+        self.read_map_data()
+-+        self.prepare_kitti_ply()#split=split)
+-+       
+-+
+-+    def __len__(self):
+-+        return self.num
+-+
+-+    def read_map_data(self):
+-+        if os.path.exists(self.path_map_dict):
+-+            with open(self.path_map_dict, 'rb') as f:
+-+                self.dict_maps = pickle.load(f)
+-+            return 
+-+
+-+
+-+        subset_names = open(self.DATA_FILES[self.split]).read().split()
+-+        self.dict_maps = {}
+-+        for id_log in subset_names:
+-+            path_map = os.path.join(self.root, "kitti_maps_cmr_new", "map-%02d_0.05.ply" % (int(id_log)))
+-+            print("Load map : ", path_map)
+-+            pcd = open3d.io.read_point_cloud(path_map)
+-+            pcd = pcd.voxel_down_sample(self.config.first_subsampling_dl)
+-+            pcd, ind = pcd.remove_radius_outlier(nb_points=7, radius=self.config.first_subsampling_dl*2)
+-+            self.dict_maps[id_log] = torch.Tensor(np.asarray(pcd.points))#.to(self.config.device)
+-+
+-+
+-+        with open(self.path_map_dict, 'wb') as f: 
+-+            print('Saving map file to ', self.path_map_dict)
+-+            pickle.dump(self.dict_maps, f)
+-+            print('Saved!')    
+-+
+-+    def get_local_map(self,T_lidar, drive):#, force_select_points=False):
+-+        dist = torch.sqrt(((self.dict_maps[drive] - T_lidar[0:3,3])**2).sum(axis=1))
+-+        ind_valid_local = dist < self.config.depth_max
+-+
+-+        return self.dict_maps[drive][ind_valid_local]
+-+
+-+            
+-+    def prepare_kitti_ply(self):#, split='train'):
+-+        #max_time_diff = self.MAX_TIME_DIFF
+-+        subset_names = open(self.DATA_FILES[self.split]).read().split()
+-+        self.all_pos = []
+-+        for dirname in subset_names:
+-+            drive_id = int(dirname)
+-+            fnames = glob.glob(self.root + '/sequences/%02d/velodyne/*.bin' % drive_id)
+-+
+-+            assert len(fnames) > 0, f"Make sure that the path {self.root} has data {dirname}"
+-+            inames = sorted([int(os.path.split(fname)[-1][:-4]) for fname in fnames])
+-+            path_poses = os.path.join(self.config.path_cmrdata, self.split, "kitti-%02d.csv" % drive_id)
+-+            list_gt_poses = read_csv_file(path_poses)
+-+
+-+            for i in range(0,len(inames),2):# curr_time in inames:
+-+                
+-+
+-+                T = pred_to_matrix_np(np.asarray(list_gt_poses[i][np.newaxis,[0,1,2,6,3,4,5]]))[0]
+-+                xyz0 = self.get_local_map(T, dirname)
+-+
+-+                #use the local map as the source
+-+                T = np.linalg.inv(T) 
+-+                if xyz0.shape[0] < self.config.num_min_map_points:
+-+                    continue
+-+                
+-+                self.files.append((drive_id, inames[i]))#, next_time))
+-+                self.all_pos.append( torch.Tensor(T))#.to(self.config.device))
+-+        self.num = len(self.files)
+-+
+-+    def __getitem__(self,idx):# split, idx):
+-+        drive = self.files[idx][0]
+-+        #t0, t1 = self.files[self.split][idx][1], self.files[self.split][idx][2]
+-+
+-+        #LiDAR is the target
+-+        fname1 = self._get_velodyne_fn(drive,  self.files[idx][1])
+-+        xyzr1 = np.fromfile(fname1, dtype=np.float32).reshape(-1, 4) 
+-+        xyz1 = xyzr1[:, :3]
+-+        
+-+        #map is the source
+-+        xyz0 = self.get_local_map( np.linalg.inv(self.all_pos[idx]), str(drive))
+-+        trans = self.all_pos[idx]# M2
+-+
+-+        matching_search_voxel_size = self.matching_search_voxel_size
+-+        if self.random_scale and random.random() < 0.95:
+-+            scale = self.min_scale + \
+-+                (self.max_scale - self.min_scale) * random.random()
+-+            matching_search_voxel_size *= scale
+-+            xyz0 = scale * xyz0
+-+            xyz1 = scale * xyz1
+-+
+-+        # Voxelization
+-+        xyz0_th = xyz0#torch.from_numpy(xyz0)
+-+        xyz1_th = torch.from_numpy(xyz1)
+-+    
+-+        sel0 = ME.utils.sparse_quantize(xyz0_th / self.voxel_size, return_index=True)
+-+        sel1 = ME.utils.sparse_quantize(xyz1_th / self.voxel_size, return_index=True)
+-+    
+-+        # Make point clouds using voxelized points
+-+        pcd0 = make_open3d_point_cloud(xyz0[sel0])
+-+        pcd1 = make_open3d_point_cloud(xyz1[sel1])
+-+    
+-+        # Get matches
+-+        matches = get_matching_indices(pcd0, pcd1, trans, matching_search_voxel_size)
+-+        #if len(matches) < 1000:
+-+        #  raise ValueError(f"{drive}, {t0}, {t1}")
+-+        matches = np.array(matches)
+-+
+-+
+-+        # Get features
+-+        npts0 = len(sel0)
+-+        npts1 = len(sel1)
+-+    
+-+        feats_train0, feats_train1 = [], []
+-+    
+-+        unique_xyz0_th = xyz0_th[sel0]
+-+        unique_xyz1_th = xyz1_th[sel1]
+-+    
+-+        feats_train0.append(torch.ones((npts0, 1)))
+-+        feats_train1.append(torch.ones((npts1, 1)))
+-+    
+-+        feats0 = torch.cat(feats_train0, 1)
+-+        feats1 = torch.cat(feats_train1, 1)
+-+    
+-+        coords0 = torch.floor(unique_xyz0_th / self.voxel_size)
+-+        coords1 = torch.floor(unique_xyz1_th / self.voxel_size)
+-+ 
+-+        #print("matches shape = ", matches.shape)
+-+        #print(coords0.shape)
+-+        #print(coords1.shape)
+-+        #print(coords0)
+-+#
+-+#
+-+        #pcd_target = o3d.geometry.PointCloud()
+-+        #pcd_target.points = o3d.utility.Vector3dVector(coords0)
+-+        #o3d.io.write_point_cloud("coords0_before.ply" , pcd_target) 
+-+#
+-+        #pcd_target = o3d.geometry.PointCloud()
+-+        #pcd_target.points = o3d.utility.Vector3dVector(coords1)
+-+        #o3d.io.write_point_cloud("coords1_before.ply" , pcd_target) 
+-+#
+-+
+-+        if self.transform:
+-+          coords0, feats0 = self.transform(coords0, feats0)
+-+          coords1, feats1 = self.transform(coords1, feats1)
+-+    
+-+        
+-+        #pcd_target = o3d.geometry.PointCloud()
+-+        #pcd_target.points = o3d.utility.Vector3dVector(coords0)
+-+        #o3d.io.write_point_cloud("coords0.ply" , pcd_target) 
+-+#
+-+        #pcd_target = o3d.geometry.PointCloud()
+-+        #pcd_target.points = o3d.utility.Vector3dVector(coords1)
+-+        #o3d.io.write_point_cloud("coords1.ply" , pcd_target) 
+-+#
+-+#
+-+
+-+
+-+        return (unique_xyz0_th.float(), unique_xyz1_th.float(), coords0.int(),
+-+                coords1.int(), feats0.float(), feats1.float(), matches, trans)
+-+    
+-+            #return (anc_points, pos_points, unaligned_anc_points, unaligned_pos_points, matches, trans, True)
+-+
+-+    #def apply_transform(self, pts, trans):
+-+    #    R = trans[:3, :3]
+-+    #    T = trans[:3, 3]
+-+    #    pts = pts @ R.T + T
+-+    #    return pts
+-+#
+-+    #@property
+-+    #def velo2cam(self):
+-+    #    try:
+-+    #        velo2cam = self._velo2cam
+-+    #    except AttributeError:
+-+    #        R = np.array([
+-+    #            7.533745e-03, -9.999714e-01, -6.166020e-04, 1.480249e-02, 7.280733e-04,
+-+    #            -9.998902e-01, 9.998621e-01, 7.523790e-03, 1.480755e-02
+-+    #        ]).reshape(3, 3)
+-+    #        T = np.array([-4.069766e-03, -7.631618e-02, -2.717806e-01]).reshape(3, 1)
+-+    #        velo2cam = np.hstack([R, T])
+-+    #        self._velo2cam = np.vstack((velo2cam, [0, 0, 0, 1])).T
+-+    #    return self._velo2cam
+-+#
+-+    #def get_video_odometry(self, drive, indices=None, ext='.txt', return_all=False):
+-+    #    if self.IS_ODOMETRY:
+-+    #        data_path = self.root + '/poses/%02d.txt' % drive
+-+    #        if data_path not in kitti_cache:
+-+    #            kitti_cache[data_path] = np.genfromtxt(data_path)
+-+    #        if return_all:
+-+    #            return kitti_cache[data_path]
+-+    #        else:
+-+    #            return kitti_cache[data_path][indices]
+-+    #    else:
+-+    #        data_path = self.root + '/' + self.date + '_drive_%04d_sync/oxts/data' % drive
+-+    #        odometry = []
+-+    #        if indices is None:
+-+    #            fnames = glob.glob(self.root + '/' + self.date +
+-+    #                               '_drive_%04d_sync/velodyne_points/data/*.bin' % drive)
+-+    #            indices = sorted([int(os.path.split(fname)[-1][:-4]) for fname in fnames])
+-+#
+-+    #        for index in indices:
+-+    #            filename = os.path.join(data_path, '%010d%s' % (index, ext))
+-+    #            if filename not in kitti_cache:
+-+    #                kitti_cache[filename] = np.genfromtxt(filename)
+-+    #                odometry.append(kitti_cache[filename])
+-+#
+-+    #        odometry = np.array(odometry)
+-+    #        return odometry
+-+#
+-+    #def odometry_to_positions(self, odometry):
+-+    #    if self.IS_ODOMETRY:
+-+    #        T_w_cam0 = odometry.reshape(3, 4)
+-+    #        T_w_cam0 = np.vstack((T_w_cam0, [0, 0, 0, 1]))
+-+    #        return T_w_cam0
+-+    #    else:
+-+    #        lat, lon, alt, roll, pitch, yaw = odometry.T[:6]
+-+#
+-+    #        R = 6378137  # Earth's radius in metres
+-+#
+-+    #        # convert to metres
+-+    #        lat, lon = np.deg2rad(lat), np.deg2rad(lon)
+-+    #        mx = R * lon * np.cos(lat)
+-+    #        my = R * lat
+-+#
+-+    #        times = odometry.T[-1]
+-+    #        return np.vstack([mx, my, alt, roll, pitch, yaw, times]).T
+-+#
+-+    def _get_velodyne_fn(self, drive, t):
+-+        if self.IS_ODOMETRY:
+-+            fname = self.root + '/sequences/%02d/velodyne/%06d.bin' % (drive, t)
+-+        else:
+-+            fname = self.root + \
+-+                    '/' + self.date + '_drive_%04d_sync/velodyne_points/data/%010d.bin' % (
+-+                        drive, t)
+-+        return fname
+-+
+-+    #def get_position_transform(self, pos0, pos1, invert=False):
+-+    #    T0 = self.pos_transform(pos0)
+-+    #    T1 = self.pos_transform(pos1)
+-+    #    return (np.dot(T1, np.linalg.inv(T0)).T if not invert else np.dot(
+-+    #        np.linalg.inv(T1), T0).T)
+-+#
+-+
+-+
+-+
+- 
+--ALL_DATASETS = [ThreeDMatchPairDataset, KITTIPairDataset, KITTINMPairDataset]
+-+ALL_DATASETS = [ThreeDMatchPairDataset, KITTIPairDataset, KITTINMPairDataset, KITTIMapDataset]
+- dataset_str_mapping = {d.__name__: d for d in ALL_DATASETS}
+- 
+- 
++@@ -692,7 +692,7 @@ class KITTIMapDataset(PairDataset):
++         self.split = phase
++         self.config = config
++ 
++-        self.path_map_dict = os.path.join(root, "kitti_map_files_d3feat_%s.pkl" % self.split)
+++        self.path_map_dict = os.path.join(root, "kitti_map_files_d3feat_%s_fcgf.pkl" % self.split)
++         self.read_map_data()
++         self.prepare_kitti_ply()#split=split)
++        
++@@ -712,10 +712,10 @@ class KITTIMapDataset(PairDataset):
++         for id_log in subset_names:
++             path_map = os.path.join(self.root, "kitti_maps_cmr_new", "map-%02d_0.05.ply" % (int(id_log)))
++             print("Load map : ", path_map)
++-            pcd = open3d.io.read_point_cloud(path_map)
++-            pcd = pcd.voxel_down_sample(self.config.first_subsampling_dl)
++-            pcd, ind = pcd.remove_radius_outlier(nb_points=7, radius=self.config.first_subsampling_dl*2)
++-            self.dict_maps[id_log] = torch.Tensor(np.asarray(pcd.points))#.to(self.config.device)
+++            pcd = o3d.io.read_point_cloud(path_map)
+++            pcd = pcd.voxel_down_sample(self.config.voxel_size)
+++            pcd, ind = pcd.remove_radius_outlier(nb_points=7, radius=self.config.voxel_size*2)
+++            self.dict_maps[id_log] = np.asarray(pcd.points)#torch.Tensor(np.asarray(pcd.points))#.to(self.config.device)
++ 
++ 
++         with open(self.path_map_dict, 'wb') as f: 
++@@ -724,7 +724,7 @@ class KITTIMapDataset(PairDataset):
++             print('Saved!')    
++ 
++     def get_local_map(self,T_lidar, drive):#, force_select_points=False):
++-        dist = torch.sqrt(((self.dict_maps[drive] - T_lidar[0:3,3])**2).sum(axis=1))
+++        dist = np.sqrt(((self.dict_maps[drive] - T_lidar[0:3,3])**2).sum(axis=1))
++         ind_valid_local = dist < self.config.depth_max
++ 
++         return self.dict_maps[drive][ind_valid_local]
++@@ -780,7 +780,7 @@ class KITTIMapDataset(PairDataset):
++             xyz1 = scale * xyz1
++ 
++         # Voxelization
++-        xyz0_th = xyz0#torch.from_numpy(xyz0)
+++        xyz0_th = torch.from_numpy(xyz0)#xyz0#torch.from_numpy(xyz0)
++         xyz1_th = torch.from_numpy(xyz1)
++     
++         sel0 = ME.utils.sparse_quantize(xyz0_th / self.voxel_size, return_index=True)
++@@ -792,8 +792,8 @@ class KITTIMapDataset(PairDataset):
++     
++         # Get matches
++         matches = get_matching_indices(pcd0, pcd1, trans, matching_search_voxel_size)
++-        #if len(matches) < 1000:
++-        #  raise ValueError(f"{drive}, {t0}, {t1}")
+++        if len(matches) < 1000:
+++            raise ValueError(f"{drive}, {idx}")
++         #matches = np.array(matches)
++ 
++ 
++@@ -818,8 +818,9 @@ class KITTIMapDataset(PairDataset):
++         #print("single batch = ")
++         #print(coords0.shape)
++         #print(coords1.shape)
++-        #print(len(matches) )        
+++           
++         if False:#len(matches) < 10:#coords0.shape[0] < 10 or coords1.shape[0] < 10:
+++            print("num matches = ", len(matches) )     
++             #print("matches shape = ", matches.shape)
++ 
++             print(coords0)
++@@ -850,7 +851,7 @@ class KITTIMapDataset(PairDataset):
++             o3d.io.write_point_cloud("unique_xyz0_th_trans_%d.ply" % idx, pcd_target) 
++ #    
++ 
++-            #import pdb; pdb.set_trace()
+++            import pdb; pdb.set_trace()
++             #pcd_target = o3d.geometry.PointCloud()
++             #pcd_target.points = o3d.utility.Vector3dVector(coords0)
++             #o3d.io.write_point_cloud("coords0.ply" , pcd_target) 
+ diff --git a/lib/trainer.py b/lib/trainer.py
+-index e4c230b..e6299f8 100644
++index e6299f8..fbb110f 100644
+ --- a/lib/trainer.py
+ +++ b/lib/trainer.py
+-@@ -234,12 +234,12 @@ class ContrastiveLossTrainer(AlignmentTrainer):
+-         # pairs consist of (xyz1 index, xyz0 index)
+-         sinput0 = ME.SparseTensor(
+-             input_dict['sinput0_F'].to(self.device),
+--            coordinates=input_dict['sinput0_C'].to(self.device))
+-+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
+-         F0 = self.model(sinput0).F
+- 
+-         sinput1 = ME.SparseTensor(
+-             input_dict['sinput1_F'].to(self.device),
+--            coordinates=input_dict['sinput1_C'].to(self.device))
+-+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
+-         F1 = self.model(sinput1).F
+- 
+-         N0, N1 = len(sinput0), len(sinput1)
+-@@ -316,14 +316,17 @@ class ContrastiveLossTrainer(AlignmentTrainer):
+- 
+-       # pairs consist of (xyz1 index, xyz0 index)
+-       feat_timer.tic()
+-+      
+-+      coords=input_dict['sinput0_C'].to(self.device)
+-       sinput0 = ME.SparseTensor(
+-           input_dict['sinput0_F'].to(self.device),
+--          coordinates=input_dict['sinput0_C'].to(self.device))
+-+          coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
+-+
+-       F0 = self.model(sinput0).F
+- 
+-       sinput1 = ME.SparseTensor(
+-           input_dict['sinput1_F'].to(self.device),
+--          coordinates=input_dict['sinput1_C'].to(self.device))
+-+          coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
+-       F1 = self.model(sinput1).F
+-       feat_timer.toc()
+- 
+-@@ -473,12 +476,12 @@ class HardestContrastiveLossTrainer(ContrastiveLossTrainer):
+- 
+-         sinput0 = ME.SparseTensor(
+-             input_dict['sinput0_F'].to(self.device),
+--            coordinates=input_dict['sinput0_C'].to(self.device))
+-+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
+-         F0 = self.model(sinput0).F
+- 
+-         sinput1 = ME.SparseTensor(
+-             input_dict['sinput1_F'].to(self.device),
+--            coordinates=input_dict['sinput1_C'].to(self.device))
+-+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
+- 
+-         F1 = self.model(sinput1).F
+- 
+-@@ -604,12 +607,12 @@ class TripletLossTrainer(ContrastiveLossTrainer):
+-         # pairs consist of (xyz1 index, xyz0 index)
+-         sinput0 = ME.SparseTensor(
+-             input_dict['sinput0_F'].to(self.device),
+--            coordinates=input_dict['sinput0_C'].to(self.device))
+-+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
+-         F0 = self.model(sinput0).F
+- 
+-         sinput1 = ME.SparseTensor(
+-             input_dict['sinput1_F'].to(self.device),
+--            coordinates=input_dict['sinput1_C'].to(self.device))
+-+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
+-         F1 = self.model(sinput1).F
+- 
+-         pos_pairs = input_dict['correspondences']
+-diff --git a/model/residual_block.py b/model/residual_block.py
+-index f06fc5a..759597f 100644
+---- a/model/residual_block.py
+-+++ b/model/residual_block.py
+-@@ -29,7 +29,7 @@ class BasicBlockBase(nn.Module):
+-         kernel_size=3,
+-         stride=1,
+-         dilation=dilation,
+--        bias=False,
+-+        has_bias=False,
+-         dimension=D)
+-     self.norm2 = get_norm(self.NORM_TYPE, planes, bn_momentum=bn_momentum, D=D)
+-     self.downsample = downsample
+-diff --git a/model/resunet.py b/model/resunet.py
+-index 6a0e2e1..eb9a4e2 100644
+---- a/model/resunet.py
+-+++ b/model/resunet.py
+-@@ -34,7 +34,7 @@ class ResUNet2(ME.MinkowskiNetwork):
+-         kernel_size=conv1_kernel_size,
+-         stride=1,
+-         dilation=1,
+--        bias=False,
+-+        has_bias=False,
+-         dimension=D)
+-     self.norm1 = get_norm(NORM_TYPE, CHANNELS[1], bn_momentum=bn_momentum, D=D)
+- 
+-@@ -47,7 +47,7 @@ class ResUNet2(ME.MinkowskiNetwork):
+-         kernel_size=3,
+-         stride=2,
+-         dilation=1,
+--        bias=False,
+-+        has_bias=False,
+-         dimension=D)
+-     self.norm2 = get_norm(NORM_TYPE, CHANNELS[2], bn_momentum=bn_momentum, D=D)
+- 
+-@@ -60,7 +60,7 @@ class ResUNet2(ME.MinkowskiNetwork):
+-         kernel_size=3,
+-         stride=2,
+-         dilation=1,
+--        bias=False,
+-+        has_bias=False,
+-         dimension=D)
+-     self.norm3 = get_norm(NORM_TYPE, CHANNELS[3], bn_momentum=bn_momentum, D=D)
+- 
+-@@ -73,7 +73,7 @@ class ResUNet2(ME.MinkowskiNetwork):
+-         kernel_size=3,
+-         stride=2,
+-         dilation=1,
+--        bias=False,
+-+        has_bias=False,
+-         dimension=D)
+-     self.norm4 = get_norm(NORM_TYPE, CHANNELS[4], bn_momentum=bn_momentum, D=D)
+- 
+-@@ -86,7 +86,7 @@ class ResUNet2(ME.MinkowskiNetwork):
+-         kernel_size=3,
+-         stride=2,
+-         dilation=1,
+--        bias=False,
+-+        has_bias=False,
+-         dimension=D)
+-     self.norm4_tr = get_norm(NORM_TYPE, TR_CHANNELS[4], bn_momentum=bn_momentum, D=D)
+- 
+-@@ -99,7 +99,7 @@ class ResUNet2(ME.MinkowskiNetwork):
+-         kernel_size=3,
+-         stride=2,
+-         dilation=1,
+--        bias=False,
+-+        has_bias=False,
+-         dimension=D)
+-     self.norm3_tr = get_norm(NORM_TYPE, TR_CHANNELS[3], bn_momentum=bn_momentum, D=D)
+- 
+-@@ -112,7 +112,7 @@ class ResUNet2(ME.MinkowskiNetwork):
+-         kernel_size=3,
+-         stride=2,
+-         dilation=1,
+--        bias=False,
+-+        has_bias=False,
+-         dimension=D)
+-     self.norm2_tr = get_norm(NORM_TYPE, TR_CHANNELS[2], bn_momentum=bn_momentum, D=D)
+- 
+-@@ -125,7 +125,7 @@ class ResUNet2(ME.MinkowskiNetwork):
+-         kernel_size=1,
+-         stride=1,
+-         dilation=1,
+--        bias=False,
+-+        has_bias=False,
+-         dimension=D)
+- 
+-     # self.block1_tr = BasicBlockBN(TR_CHANNELS[1], TR_CHANNELS[1], bn_momentum=bn_momentum, D=D)
+-@@ -136,7 +136,7 @@ class ResUNet2(ME.MinkowskiNetwork):
+-         kernel_size=1,
+-         stride=1,
+-         dilation=1,
+--        bias=True,
+-+        has_bias=True,
+-         dimension=D)
+- 
+-   def forward(self, x):
+-@@ -187,8 +187,8 @@ class ResUNet2(ME.MinkowskiNetwork):
+-     if self.normalize_feature:
+-       return ME.SparseTensor(
+-           out.F / torch.norm(out.F, p=2, dim=1, keepdim=True),
+--          coordinate_map_key=out.coordinate_map_key,
+--          coordinate_manager=out.coordinate_manager)
+-+          coords_key=out.coords_key,#out.coordinate_map_key,
+-+          coords_manager=out.coords_man)#out.coordinate_manager)
+-     else:
+-       return out
+- 
+-@@ -244,3 +244,8 @@ class ResUNetIN2D(ResUNetBN2D):
+- class ResUNetIN2E(ResUNetBN2E):
+-   NORM_TYPE = 'BN'
+-   BLOCK_NORM_TYPE = 'IN'
+-+
+-+class ResUNetBN2C(ResUNet2):
+-+  NORM_TYPE = 'BN'
+-+  CHANNELS = [None, 32, 64, 128, 256]
+-+  TR_CHANNELS = [None, 64, 64, 64, 128]
+-\ No newline at end of file
+-diff --git a/scripts/train_fcgf_kitti.sh b/scripts/train_fcgf_kitti.sh
+-index de073fd..ed12044 100755
+---- a/scripts/train_fcgf_kitti.sh
+-+++ b/scripts/train_fcgf_kitti.sh
+-@@ -3,7 +3,7 @@ export PATH_POSTFIX=$1
+- export MISC_ARGS=$2
+- 
+- export DATA_ROOT="./outputs/Experiments"
+--export DATASET=${DATASET:-KITTINMPairDataset}
+-+export DATASET=${DATASET:-KITTIMapDataset} #KITTINMPairDataset}
+- export TRAINER=${TRAINER:-HardestContrastiveLossTrainer}
+- export MODEL=${MODEL:-ResUNetBN2C}
+- export MODEL_N_OUT=${MODEL_N_OUT:-16}
+-
+-Mon Nov  2 17:08:49 2020       
+-+-----------------------------------------------------------------------------+
+-| NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |
+-|-------------------------------+----------------------+----------------------+
+-| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
+-| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
+-|===============================+======================+======================|
+-|   0  GeForce GTX TIT...  On   | 00000000:05:00.0 Off |                  N/A |
+-| 50%   83C    P2   117W / 250W |  12207MiB / 12211MiB |    100%      Default |
+-+-------------------------------+----------------------+----------------------+
+-|   1  GeForce GTX TIT...  On   | 00000000:06:00.0 Off |                  N/A |
+-| 24%   63C    P8    17W / 250W |     11MiB / 12212MiB |      0%      Default |
+-+-------------------------------+----------------------+----------------------+
+-|   2  GeForce GTX TIT...  On   | 00000000:09:00.0 Off |                  N/A |
+-| 53%   83C    P2   110W / 250W |   9515MiB / 12212MiB |     97%      Default |
+-+-------------------------------+----------------------+----------------------+
+-|   3  GeForce GTX TIT...  On   | 00000000:0A:00.0 Off |                  N/A |
+-| 36%   70C    P8    21W / 250W |     11MiB / 12212MiB |      0%      Default |
+-+-------------------------------+----------------------+----------------------+
+-                                                                               
+-+-----------------------------------------------------------------------------+
+-| Processes:                                                       GPU Memory |
+-|  GPU       PID   Type   Process name                             Usage      |
+-|=============================================================================|
+-|    0      4990      C   python3                                    12196MiB |
+-|    2     14147      C   python3                                     9504MiB |
+-+-----------------------------------------------------------------------------+
+-11/02 17:08:50 ===> Configurations
+-11/02 17:08:50     out_dir: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b8i1-modelnout16/2020-11-02_17-08-48
+-11/02 17:08:50     trainer: HardestContrastiveLossTrainer
+-11/02 17:08:50     save_freq_epoch: 1
+-11/02 17:08:50     batch_size: 8
+-11/02 17:08:50     val_batch_size: 1
+-11/02 17:08:50     use_hard_negative: True
+-11/02 17:08:50     hard_negative_sample_ratio: 0.05
+-11/02 17:08:50     hard_negative_max_num: 3000
+-11/02 17:08:50     num_pos_per_batch: 1024
+-11/02 17:08:50     num_hn_samples_per_batch: 256
+-11/02 17:08:50     neg_thresh: 1.4
+-11/02 17:08:50     pos_thresh: 0.1
+-11/02 17:08:50     neg_weight: 1
+-11/02 17:08:50     use_random_scale: True
+-11/02 17:08:50     min_scale: 0.8
+-11/02 17:08:50     max_scale: 1.2
+-11/02 17:08:50     use_random_rotation: True
+-11/02 17:08:50     rotation_range: 360
+-11/02 17:08:50     train_phase: train
+-11/02 17:08:50     val_phase: val
+-11/02 17:08:50     test_phase: test
+-11/02 17:08:50     stat_freq: 40
+-11/02 17:08:50     test_valid: True
+-11/02 17:08:50     val_max_iter: 400
+-11/02 17:08:50     val_epoch_freq: 1
+-11/02 17:08:50     positive_pair_search_voxel_size_multiplier: 1.5
+-11/02 17:08:50     hit_ratio_thresh: 0.3
+-11/02 17:08:50     triplet_num_pos: 256
+-11/02 17:08:50     triplet_num_hn: 512
+-11/02 17:08:50     triplet_num_rand: 1024
+-11/02 17:08:50     model: ResUNetBN2C
+-11/02 17:08:50     model_n_out: 16
+-11/02 17:08:50     conv1_kernel_size: 5
+-11/02 17:08:50     normalize_feature: True
+-11/02 17:08:50     dist_type: L2
+-11/02 17:08:50     best_val_metric: feat_match_ratio
+-11/02 17:08:50     optimizer: SGD
+-11/02 17:08:50     max_epoch: 200
+-11/02 17:08:50     lr: 0.1
+-11/02 17:08:50     momentum: 0.8
+-11/02 17:08:50     sgd_momentum: 0.9
+-11/02 17:08:50     sgd_dampening: 0.1
+-11/02 17:08:50     adam_beta1: 0.9
+-11/02 17:08:50     adam_beta2: 0.999
+-11/02 17:08:50     weight_decay: 0.0001
+-11/02 17:08:50     iter_size: 1
+-11/02 17:08:50     bn_momentum: 0.05
+-11/02 17:08:50     exp_gamma: 0.99
+-11/02 17:08:50     scheduler: ExpLR
+-11/02 17:08:50     icp_cache_path: /home/chrischoy/datasets/FCGF/kitti/icp/
+-11/02 17:08:50     use_gpu: True
+-11/02 17:08:50     weights: None
+-11/02 17:08:50     weights_dir: None
+-11/02 17:08:50     resume: None
+-11/02 17:08:50     resume_dir: None
+-11/02 17:08:50     train_num_thread: 2
+-11/02 17:08:50     val_num_thread: 1
+-11/02 17:08:50     test_num_thread: 2
+-11/02 17:08:50     fast_validation: False
+-11/02 17:08:50     nn_max_n: 500
+-11/02 17:08:50     dataset: KITTIMapDataset
+-11/02 17:08:50     voxel_size: 0.3
+-11/02 17:08:50     threed_match_dir: /home/chrischoy/datasets/FCGF/threedmatch
+-11/02 17:08:50     kitti_root: /home/allie/dataset/kitti_odometry/
+-11/02 17:08:50     kitti_max_time_diff: 3
+-11/02 17:08:50     kitti_date: 2011_09_26
+-11/02 17:08:50     path_cmrdata: /home/allie/dataset/cmr_original
+-11/02 17:08:50     depth_max: 50
+-11/02 17:08:50     num_min_map_points: 20000.0
+-11/02 17:11:43 ResUNetBN2C(
+-  (conv1): MinkowskiConvolution(in=1, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
+-  (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  (block1): BasicBlockBN(
+-    (conv1): MinkowskiConvolution(in=32, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-    (conv2): MinkowskiConvolution(in=32, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  )
+-  (conv2): MinkowskiConvolution(in=32, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
+-  (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  (block2): BasicBlockBN(
+-    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  )
+-  (conv3): MinkowskiConvolution(in=64, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
+-  (norm3): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  (block3): BasicBlockBN(
+-    (conv1): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-    (conv2): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  )
+-  (conv4): MinkowskiConvolution(in=128, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
+-  (norm4): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  (block4): BasicBlockBN(
+-    (conv1): MinkowskiConvolution(in=256, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm1): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-    (conv2): MinkowskiConvolution(in=256, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm2): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  )
+-  (conv4_tr): MinkowskiConvolutionTranspose(in=256, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
+-  (norm4_tr): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  (block4_tr): BasicBlockBN(
+-    (conv1): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-    (conv2): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  )
+-  (conv3_tr): MinkowskiConvolutionTranspose(in=256, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
+-  (norm3_tr): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  (block3_tr): BasicBlockBN(
+-    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  )
+-  (conv2_tr): MinkowskiConvolutionTranspose(in=128, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
+-  (norm2_tr): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  (block2_tr): BasicBlockBN(
+-    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  )
+-  (conv1_tr): MinkowskiConvolution(in=96, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
+-  (final): MinkowskiConvolution(in=64, out=16, region_type=RegionType.HYPERCUBE, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
+-)
+-11/02 17:11:45 Resetting the data loader seed to 0
+-/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/MinkowskiEngine/SparseTensor.py:260: UserWarning: Coords implicitly converted to torch.IntTensor. To remove this warning, use `.int()` to convert the coords into an torch.IntTensor
+-  'To remove this warning, use `.int()` to convert the ' +
+-/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/MinkowskiEngine/SparseTensor.py:267: UserWarning: Coords implicitly converted to CPU type. To remove this warning, use `.cpu()` to convert the coords into a CPU type
+-  'To remove this warning, use `.cpu()` to convert the ' +
+-11/02 17:18:03 Validation iter 101 / 400 : Data Loading Time: 2.147, Feature Extraction Time: 0.954, Matching Time: 0.619, Loss: 0.995, RTE: 257.727, RRE: 0.892, Hit Ratio: 0.000, Feat Match Ratio: 0.000
+-11/02 17:24:23 Validation iter 201 / 400 : Data Loading Time: 2.181, Feature Extraction Time: 0.954, Matching Time: 0.631, Loss: 0.990, RTE: 228.406, RRE: 0.844, Hit Ratio: 0.000, Feat Match Ratio: 0.000
+-11/02 17:31:11 Validation iter 301 / 400 : Data Loading Time: 2.429, Feature Extraction Time: 0.960, Matching Time: 0.641, Loss: 0.991, RTE: 222.431, RRE: 0.841, Hit Ratio: 0.000, Feat Match Ratio: 0.000
+-11/02 17:37:29 Final Loss: 0.992, RTE: 228.734, RRE: 0.859, Hit Ratio: 0.000, Feat Match Ratio: 0.000
+-/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:449: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
+-  "please use `get_last_lr()`.", UserWarning)
+-11/02 17:37:30  Epoch: 1, LR: [0.1]
+-Traceback (most recent call last):
+-  File "train.py", line 84, in <module>
+-    main(config)
+-  File "train.py", line 63, in main
+-    trainer.train()
+-  File "/home/allie/code/benchmark/FCGF/lib/trainer.py", line 132, in train
+-    self._train_epoch(epoch)
+-  File "/home/allie/code/benchmark/FCGF/lib/trainer.py", line 474, in _train_epoch
+-    input_dict = data_loader_iter.next()
+-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 435, in __next__
+-    data = self._next_data()
+-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1085, in _next_data
+-    return self._process_data(data)
+-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1111, in _process_data
+-    data.reraise()
+-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/_utils.py", line 428, in reraise
+-    raise self.exc_type(msg)
+-ValueError: Caught ValueError in DataLoader worker process 0.
+-Original Traceback (most recent call last):
+-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 198, in _worker_loop
+-    data = fetcher.fetch(index)
+-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 47, in fetch
+-    return self.collate_fn(data)
+-  File "/home/allie/code/benchmark/FCGF/lib/data_loaders.py", line 85, in collate_pair_fn
+-    torch.from_numpy(np.array(matching_inds[batch_id]) + curr_start_inds))
+-ValueError: operands could not be broadcast together with shapes (0,) (1,2) 
+-
+-Traceback (most recent call last):
+-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/runpy.py", line 193, in _run_module_as_main
+-    "__main__", mod_spec)
+-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/runpy.py", line 85, in _run_code
+-    exec(code, run_globals)
+-  File "/home/allie/code/benchmark/FCGF/scripts/test_kitti.py", line 144, in <module>
+-    main(config)
+-  File "/home/allie/code/benchmark/FCGF/scripts/test_kitti.py", line 27, in main
+-    config, config.test_phase, 1, num_threads=config.test_num_workers, shuffle=True)
+-AttributeError: 'EasyDict' object has no attribute 'test_num_workers'
+-./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-03_01-04-07
+-Host:  bb8
+-Conda  /home/allie/miniconda3/condabin/conda
+-/home/allie/code/benchmark/FCGF
+-Version:  f0863a9ba4a29f677c0ddd2248cf4e56b9318add
+-Git diff
+-
+-diff --git a/config.py b/config.py
+-index 476402d..6c9fb68 100644
+---- a/config.py
+-+++ b/config.py
+-@@ -94,9 +94,9 @@ misc_arg.add_argument('--weights', type=str, default=None)
+- misc_arg.add_argument('--weights_dir', type=str, default=None)
+- misc_arg.add_argument('--resume', type=str, default=None)
+- misc_arg.add_argument('--resume_dir', type=str, default=None)
+--misc_arg.add_argument('--train_num_thread', type=int, default=2)
+--misc_arg.add_argument('--val_num_thread', type=int, default=1)
+--misc_arg.add_argument('--test_num_thread', type=int, default=2)
+-+misc_arg.add_argument('--train_num_thread', type=int, default=8)#2)
+-+misc_arg.add_argument('--val_num_thread', type=int, default=8)
+-+misc_arg.add_argument('--test_num_thread', type=int, default=8)#2)
+- misc_arg.add_argument('--fast_validation', type=str2bool, default=False)
+- misc_arg.add_argument(
+-     '--nn_max_n',
+-@@ -112,14 +112,28 @@ data_arg.add_argument(
+-     '--threed_match_dir', type=str, default="/home/chrischoy/datasets/FCGF/threedmatch")
+- data_arg.add_argument(
+-     '--kitti_root', type=str, default="/home/chrischoy/datasets/FCGF/kitti/")
+-+
+- data_arg.add_argument(
+-     '--kitti_max_time_diff',
+-     type=int,
+-     default=3,
+-     help='max time difference between pairs (non inclusive)')
+-+
+- data_arg.add_argument('--kitti_date', type=str, default='2011_09_26')
+- 
++@@ -332,7 +332,7 @@ class ContrastiveLossTrainer(AlignmentTrainer):
+  
+-+#arguments for KITTI map dataset
+-+#for kitti ground truth poses (optimized by loop-closing SLAM)
+-+data_arg.add_argument(
+-+    '--path_cmrdata', type=str, default="/home/allie/dataset/cmr_original") 
+-+data_arg.add_argument(
+-+    '--depth_max', type=float, default=50) 
+-+data_arg.add_argument(
+-+    '--num_min_map_points', type=int, default=2e4) 
+-+
+-+
+-+
+-+
+- def get_config():
+-   args = parser.parse_args()
+-   return args
+-diff --git a/lib/data_loaders.py b/lib/data_loaders.py
+-index 2bc475a..e0e264d 100644
+---- a/lib/data_loaders.py
+-+++ b/lib/data_loaders.py
+-@@ -18,10 +18,42 @@ import lib.transforms as t
+- import MinkowskiEngine as ME
+- 
+- import open3d as o3d
+-+import pickle
+- 
+- kitti_cache = {}
+- kitti_icp_cache = {}
+- 
+-+eps = 1e-10
+-+import csv
+-+def read_csv_file(path_file):
+-+    lines = []
+-+    with open(path_file, "r") as f:
+-+        reader = csv.reader(f, delimiter="\t")
+-+        for i, line in enumerate(reader):
+-+            if i >= 1:
+-+                lines.append(np.asarray(line[0].split(',')[1:]).astype('float'))
+-+    return lines
+-+
+-+
+-+def pred_to_matrix_np(pred):
+-+
+-+    cam_T = np.tile(np.eye(4)[np.newaxis,:,:],[pred.shape[0], 1, 1])
+-+    cam_T[:,0:3, 3] = pred[:, 0:3]
+-+    s = np.tile(np.linalg.norm(pred[:,3:], axis=1)[:,np.newaxis],[1,4])
+-+
+-+    q = pred[:,3:] / (s+eps)
+-+
+-+    cam_T[:,0,0] = 1- 2*s[:,0]*(q[:,2]**2 + q[:,3]**2)
+-+    cam_T[:,0,1] = 2   *s[:,0]*(q[:,1] * q[:,2] - q[:,3] * q[:,0])
+-+    cam_T[:,0,2] = 2   *s[:,0]*(q[:,1] * q[:,3] + q[:,2] * q[:,0])
+-+    cam_T[:,1,0] = 2   *s[:,0]*(q[:,1]*q[:,2] + q[:,3]*q[:,0])
+-+    cam_T[:,1,1] = 1- 2*s[:,0]*(q[:,1]**2 + q[:,3]**2)
+-+    cam_T[:,1,2] = 2   *s[:,0]*(q[:,2] * q[:,3] - q[:,1] * q[:,0])
+-+    cam_T[:,2,0] = 2   *s[:,0]*(q[:,1] * q[:,3] - q[:,2] * q[:,0])
+-+    cam_T[:,2,1] = 2   *s[:,0]*(q[:,2] * q[:,3] + q[:,1] * q[:,0])
+-+    cam_T[:,2,2] = 1 -2*s[:,0]*(q[:,1]**2 + q[:,2]**2)
+-+
+-+    return cam_T
+- 
+- def collate_pair_fn(list_data):
+-   xyz0, xyz1, coords0, coords1, feats0, feats1, matching_inds, trans = list(
+-@@ -48,7 +80,6 @@ def collate_pair_fn(list_data):
+-     xyz_batch1.append(to_tensor(xyz1[batch_id]))
+- 
+-     trans_batch.append(to_tensor(trans[batch_id]))
+--
+-     matching_inds_batch.append(
+-         torch.from_numpy(np.array(matching_inds[batch_id]) + curr_start_inds))
+-     len_batch.append([N0, N1])
+-@@ -632,8 +663,231 @@ class ThreeDMatchPairDataset(IndoorPairDataset):
+-       'test': './config/test_3dmatch.txt'
+-   }
+- 
+-+class KITTIMapDataset(PairDataset):
+-+    AUGMENT = None
+-+    DATA_FILES = {
+-+        'train': './config/train_kitti_map.txt', #log ids
+-+        'val': './config/val_kitti_map.txt',
+-+        'test': './config/test_kitti_map.txt'
+-+    }
+-+    TEST_RANDOM_ROTATION = False
+-+    IS_ODOMETRY = True
+-+    #MAX_TIME_DIFF = 3
+-+
+-+    def __init__(self,
+-+               phase,
+-+               transform=None,
+-+               random_rotation=True,
+-+               random_scale=True,
+-+               manual_seed=False,
+-+               config=None):
+-+
+-+
+-+    #(self, root, split, config, input_threads=8, first_subsampling_dl=0.30):#, load_test=False):
+-+        
+-+        PairDataset.__init__(self, phase, transform, random_rotation, random_scale,
+-+                         manual_seed, config)
+-+
+-+        self.root = root = os.path.join(config.kitti_root, 'dataset')
+-+        self.split = phase
+-+        self.config = config
+-+
+-+        self.path_map_dict = os.path.join(root, "kitti_map_files_d3feat_%s.pkl" % self.split)
+-+        self.read_map_data()
+-+        self.prepare_kitti_ply()#split=split)
+-+       
+-+
+-+    def __len__(self):
+-+        return self.num
+-+
+-+    def read_map_data(self):
+-+        if os.path.exists(self.path_map_dict):
+-+            with open(self.path_map_dict, 'rb') as f:
+-+                self.dict_maps = pickle.load(f)
+-+            return 
+-+
+-+
+-+        subset_names = open(self.DATA_FILES[self.split]).read().split()
+-+        self.dict_maps = {}
+-+        for id_log in subset_names:
+-+            path_map = os.path.join(self.root, "kitti_maps_cmr_new", "map-%02d_0.05.ply" % (int(id_log)))
+-+            print("Load map : ", path_map)
+-+            pcd = open3d.io.read_point_cloud(path_map)
+-+            pcd = pcd.voxel_down_sample(self.config.first_subsampling_dl)
+-+            pcd, ind = pcd.remove_radius_outlier(nb_points=7, radius=self.config.first_subsampling_dl*2)
+-+            self.dict_maps[id_log] = torch.Tensor(np.asarray(pcd.points))#.to(self.config.device)
+-+
+-+
+-+        with open(self.path_map_dict, 'wb') as f: 
+-+            print('Saving map file to ', self.path_map_dict)
+-+            pickle.dump(self.dict_maps, f)
+-+            print('Saved!')    
+-+
+-+    def get_local_map(self,T_lidar, drive):#, force_select_points=False):
+-+        dist = torch.sqrt(((self.dict_maps[drive] - T_lidar[0:3,3])**2).sum(axis=1))
+-+        ind_valid_local = dist < self.config.depth_max
+-+
+-+        return self.dict_maps[drive][ind_valid_local]
+-+
+-+            
+-+    def prepare_kitti_ply(self):#, split='train'):
+-+        #max_time_diff = self.MAX_TIME_DIFF
+-+        subset_names = open(self.DATA_FILES[self.split]).read().split()
+-+        self.all_pos = []
+-+        for dirname in subset_names:
+-+            drive_id = int(dirname)
+-+            fnames = glob.glob(self.root + '/sequences/%02d/velodyne/*.bin' % drive_id)
+-+
+-+            assert len(fnames) > 0, f"Make sure that the path {self.root} has data {dirname}"
+-+            inames = sorted([int(os.path.split(fname)[-1][:-4]) for fname in fnames])
+-+            path_poses = os.path.join(self.config.path_cmrdata, self.split, "kitti-%02d.csv" % drive_id)
+-+            list_gt_poses = read_csv_file(path_poses)
+-+
+-+            for i in range(0,len(inames),2):# curr_time in inames:
+-+                
+-+
+-+                T = pred_to_matrix_np(np.asarray(list_gt_poses[i][np.newaxis,[0,1,2,6,3,4,5]]))[0]
+-+                xyz0 = self.get_local_map(T, dirname)
+-+
+-+                #use the local map as the source
+-+                T = np.linalg.inv(T) 
+-+                if xyz0.shape[0] < self.config.num_min_map_points:
+-+                    continue
+-+                
+-+                self.files.append((drive_id, inames[i]))#, next_time))
+-+                self.all_pos.append( torch.Tensor(T))#.to(self.config.device))
+-+        self.num = len(self.files)
+-+
+-+    def __getitem__(self,idx):# split, idx):
+-+        drive = self.files[idx][0]
+-+        #t0, t1 = self.files[self.split][idx][1], self.files[self.split][idx][2]
+-+
+-+        #LiDAR is the target
+-+        fname1 = self._get_velodyne_fn(drive,  self.files[idx][1])
+-+        xyzr1 = np.fromfile(fname1, dtype=np.float32).reshape(-1, 4) 
+-+        xyz1 = xyzr1[:, :3]
+-+        
+-+        #map is the source
+-+        xyz0 = self.get_local_map( np.linalg.inv(self.all_pos[idx]), str(drive))
+-+        trans = self.all_pos[idx]# M2
+-+
+-+        matching_search_voxel_size = self.matching_search_voxel_size
+-+        if self.random_scale and random.random() < 0.95:
+-+            scale = self.min_scale + \
+-+                (self.max_scale - self.min_scale) * random.random()
+-+            matching_search_voxel_size *= scale
+-+            xyz0 = scale * xyz0
+-+            xyz1 = scale * xyz1
+-+
+-+        # Voxelization
+-+        xyz0_th = xyz0#torch.from_numpy(xyz0)
+-+        xyz1_th = torch.from_numpy(xyz1)
+-+    
+-+        sel0 = ME.utils.sparse_quantize(xyz0_th / self.voxel_size, return_index=True)
+-+        sel1 = ME.utils.sparse_quantize(xyz1_th / self.voxel_size, return_index=True)
+-+    
+-+        # Make point clouds using voxelized points
+-+        pcd0 = make_open3d_point_cloud(xyz0[sel0])
+-+        pcd1 = make_open3d_point_cloud(xyz1[sel1])
+-+    
+-+        # Get matches
+-+        matches = get_matching_indices(pcd0, pcd1, trans, matching_search_voxel_size)
+-+        #if len(matches) < 1000:
+-+        #  raise ValueError(f"{drive}, {t0}, {t1}")
+-+        #matches = np.array(matches)
+-+
+-+
+-+        # Get features
+-+        npts0 = len(sel0)
+-+        npts1 = len(sel1)
+-+    
+-+        feats_train0, feats_train1 = [], []
+-+    
+-+        unique_xyz0_th = xyz0_th[sel0]
+-+        unique_xyz1_th = xyz1_th[sel1]
+-+    
+-+        feats_train0.append(torch.ones((npts0, 1)))
+-+        feats_train1.append(torch.ones((npts1, 1)))
+-+    
+-+        feats0 = torch.cat(feats_train0, 1)
+-+        feats1 = torch.cat(feats_train1, 1)
+-+    
+-+        coords0 = torch.floor(unique_xyz0_th / self.voxel_size)
+-+        coords1 = torch.floor(unique_xyz1_th / self.voxel_size)
+-+
+-+        #print("single batch = ")
+-+        #print(coords0.shape)
+-+        #print(coords1.shape)
+-+        #print(len(matches) )        
+-+        if False:#len(matches) < 10:#coords0.shape[0] < 10 or coords1.shape[0] < 10:
+-+            #print("matches shape = ", matches.shape)
+-+
+-+            print(coords0)
+-+#    
+-+#    
+-+            pcd_target = o3d.geometry.PointCloud()
+-+            pcd_target.points = o3d.utility.Vector3dVector(coords0)
+-+            o3d.io.write_point_cloud("coords0_before_%d.ply" % idx , pcd_target) 
+-+#    
+-+            pcd_target = o3d.geometry.PointCloud()
+-+            pcd_target.points = o3d.utility.Vector3dVector(coords1)
+-+            o3d.io.write_point_cloud("coords1_before_%d.ply" % idx, pcd_target) 
+-+#    
+-+    
+-+            pcd_target = o3d.geometry.PointCloud()
+-+            pcd_target.points = o3d.utility.Vector3dVector(unique_xyz1_th)
+-+            o3d.io.write_point_cloud("unique_xyz1_th_%d.ply"% idx , pcd_target) 
+-+#    
+-+    
+-+            pcd_target = o3d.geometry.PointCloud()
+-+            pcd_target.points = o3d.utility.Vector3dVector(unique_xyz0_th)
+-+            o3d.io.write_point_cloud("unique_xyz0_th_%d.ply"% idx , pcd_target)         
+-+#    
+-+            pcd_target = o3d.geometry.PointCloud()
+-+            pcd_target.points = o3d.utility.Vector3dVector(unique_xyz0_th)
+-+            pcd_target.transform(trans)
+-+    
+-+            o3d.io.write_point_cloud("unique_xyz0_th_trans_%d.ply" % idx, pcd_target) 
+-+#    
+-+
+-+            #import pdb; pdb.set_trace()
+-+            #pcd_target = o3d.geometry.PointCloud()
+-+            #pcd_target.points = o3d.utility.Vector3dVector(coords0)
+-+            #o3d.io.write_point_cloud("coords0.ply" , pcd_target) 
+-+#    
+-+            #pcd_target = o3d.geometry.PointCloud()
+-+            #pcd_target.points = o3d.utility.Vector3dVector(coords1)
+-+            #o3d.io.write_point_cloud("coords1.ply" , pcd_target) 
+-+
+-+
+-+        if self.transform: #add noises to the point clouds
+-+          coords0, feats0 = self.transform(coords0, feats0)
+-+          coords1, feats1 = self.transform(coords1, feats1)
+-+        
+-+
+-+        return (unique_xyz0_th.float(), unique_xyz1_th.float(), coords0.int(),
+-+                coords1.int(), feats0.float(), feats1.float(), matches, trans)
+-+
+-+    def _get_velodyne_fn(self, drive, t):
+-+        if self.IS_ODOMETRY:
+-+            fname = self.root + '/sequences/%02d/velodyne/%06d.bin' % (drive, t)
+-+        else:
+-+            fname = self.root + \
+-+                    '/' + self.date + '_drive_%04d_sync/velodyne_points/data/%010d.bin' % (
+-+                        drive, t)
+-+        return fname
+-+
+-+    #def get_position_transform(self, pos0, pos1, invert=False):
+-+    #    T0 = self.pos_transform(pos0)
+-+    #    T1 = self.pos_transform(pos1)
+-+    #    return (np.dot(T1, np.linalg.inv(T0)).T if not invert else np.dot(
+-+    #        np.linalg.inv(T1), T0).T)
+-+#
+-+
+-+
+-+
+- 
+--ALL_DATASETS = [ThreeDMatchPairDataset, KITTIPairDataset, KITTINMPairDataset]
+-+ALL_DATASETS = [ThreeDMatchPairDataset, KITTIPairDataset, KITTINMPairDataset, KITTIMapDataset]
+- dataset_str_mapping = {d.__name__: d for d in ALL_DATASETS}
+- 
+- 
+-diff --git a/lib/trainer.py b/lib/trainer.py
+-index e4c230b..e6299f8 100644
+---- a/lib/trainer.py
+-+++ b/lib/trainer.py
+-@@ -234,12 +234,12 @@ class ContrastiveLossTrainer(AlignmentTrainer):
+-         # pairs consist of (xyz1 index, xyz0 index)
+-         sinput0 = ME.SparseTensor(
+-             input_dict['sinput0_F'].to(self.device),
+--            coordinates=input_dict['sinput0_C'].to(self.device))
+-+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
+-         F0 = self.model(sinput0).F
+- 
+-         sinput1 = ME.SparseTensor(
+-             input_dict['sinput1_F'].to(self.device),
+--            coordinates=input_dict['sinput1_C'].to(self.device))
+-+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
+-         F1 = self.model(sinput1).F
+- 
+-         N0, N1 = len(sinput0), len(sinput1)
+-@@ -316,14 +316,17 @@ class ContrastiveLossTrainer(AlignmentTrainer):
+- 
+-       # pairs consist of (xyz1 index, xyz0 index)
+-       feat_timer.tic()
+-+      
+-+      coords=input_dict['sinput0_C'].to(self.device)
+-       sinput0 = ME.SparseTensor(
+-           input_dict['sinput0_F'].to(self.device),
+--          coordinates=input_dict['sinput0_C'].to(self.device))
+-+          coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
+-+
+-       F0 = self.model(sinput0).F
+- 
+-       sinput1 = ME.SparseTensor(
+-           input_dict['sinput1_F'].to(self.device),
+--          coordinates=input_dict['sinput1_C'].to(self.device))
+-+          coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
+-       F1 = self.model(sinput1).F
+-       feat_timer.toc()
+- 
+-@@ -473,12 +476,12 @@ class HardestContrastiveLossTrainer(ContrastiveLossTrainer):
+- 
+-         sinput0 = ME.SparseTensor(
+-             input_dict['sinput0_F'].to(self.device),
+--            coordinates=input_dict['sinput0_C'].to(self.device))
+-+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
+-         F0 = self.model(sinput0).F
+- 
+-         sinput1 = ME.SparseTensor(
+-             input_dict['sinput1_F'].to(self.device),
+--            coordinates=input_dict['sinput1_C'].to(self.device))
+-+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
+- 
+-         F1 = self.model(sinput1).F
+- 
+-@@ -604,12 +607,12 @@ class TripletLossTrainer(ContrastiveLossTrainer):
+-         # pairs consist of (xyz1 index, xyz0 index)
+-         sinput0 = ME.SparseTensor(
+-             input_dict['sinput0_F'].to(self.device),
+--            coordinates=input_dict['sinput0_C'].to(self.device))
+-+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
+-         F0 = self.model(sinput0).F
+- 
+-         sinput1 = ME.SparseTensor(
+-             input_dict['sinput1_F'].to(self.device),
+--            coordinates=input_dict['sinput1_C'].to(self.device))
+-+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
+-         F1 = self.model(sinput1).F
+- 
+-         pos_pairs = input_dict['correspondences']
+-diff --git a/model/residual_block.py b/model/residual_block.py
+-index f06fc5a..759597f 100644
+---- a/model/residual_block.py
+-+++ b/model/residual_block.py
+-@@ -29,7 +29,7 @@ class BasicBlockBase(nn.Module):
+-         kernel_size=3,
+-         stride=1,
+-         dilation=dilation,
+--        bias=False,
+-+        has_bias=False,
+-         dimension=D)
+-     self.norm2 = get_norm(self.NORM_TYPE, planes, bn_momentum=bn_momentum, D=D)
+-     self.downsample = downsample
+-diff --git a/model/resunet.py b/model/resunet.py
+-index 6a0e2e1..eb9a4e2 100644
+---- a/model/resunet.py
+-+++ b/model/resunet.py
+-@@ -34,7 +34,7 @@ class ResUNet2(ME.MinkowskiNetwork):
+-         kernel_size=conv1_kernel_size,
+-         stride=1,
+-         dilation=1,
+--        bias=False,
+-+        has_bias=False,
+-         dimension=D)
+-     self.norm1 = get_norm(NORM_TYPE, CHANNELS[1], bn_momentum=bn_momentum, D=D)
+- 
+-@@ -47,7 +47,7 @@ class ResUNet2(ME.MinkowskiNetwork):
+-         kernel_size=3,
+-         stride=2,
+-         dilation=1,
+--        bias=False,
+-+        has_bias=False,
+-         dimension=D)
+-     self.norm2 = get_norm(NORM_TYPE, CHANNELS[2], bn_momentum=bn_momentum, D=D)
+- 
+-@@ -60,7 +60,7 @@ class ResUNet2(ME.MinkowskiNetwork):
+-         kernel_size=3,
+-         stride=2,
+-         dilation=1,
+--        bias=False,
+-+        has_bias=False,
+-         dimension=D)
+-     self.norm3 = get_norm(NORM_TYPE, CHANNELS[3], bn_momentum=bn_momentum, D=D)
+- 
+-@@ -73,7 +73,7 @@ class ResUNet2(ME.MinkowskiNetwork):
+-         kernel_size=3,
+-         stride=2,
+-         dilation=1,
+--        bias=False,
+-+        has_bias=False,
+-         dimension=D)
+-     self.norm4 = get_norm(NORM_TYPE, CHANNELS[4], bn_momentum=bn_momentum, D=D)
+- 
+-@@ -86,7 +86,7 @@ class ResUNet2(ME.MinkowskiNetwork):
+-         kernel_size=3,
+-         stride=2,
+-         dilation=1,
+--        bias=False,
+-+        has_bias=False,
+-         dimension=D)
+-     self.norm4_tr = get_norm(NORM_TYPE, TR_CHANNELS[4], bn_momentum=bn_momentum, D=D)
+- 
+-@@ -99,7 +99,7 @@ class ResUNet2(ME.MinkowskiNetwork):
+-         kernel_size=3,
+-         stride=2,
+-         dilation=1,
+--        bias=False,
+-+        has_bias=False,
+-         dimension=D)
+-     self.norm3_tr = get_norm(NORM_TYPE, TR_CHANNELS[3], bn_momentum=bn_momentum, D=D)
+- 
+-@@ -112,7 +112,7 @@ class ResUNet2(ME.MinkowskiNetwork):
+-         kernel_size=3,
+-         stride=2,
+-         dilation=1,
+--        bias=False,
+-+        has_bias=False,
+-         dimension=D)
+-     self.norm2_tr = get_norm(NORM_TYPE, TR_CHANNELS[2], bn_momentum=bn_momentum, D=D)
+- 
+-@@ -125,7 +125,7 @@ class ResUNet2(ME.MinkowskiNetwork):
+-         kernel_size=1,
+-         stride=1,
+-         dilation=1,
+--        bias=False,
+-+        has_bias=False,
+-         dimension=D)
+- 
+-     # self.block1_tr = BasicBlockBN(TR_CHANNELS[1], TR_CHANNELS[1], bn_momentum=bn_momentum, D=D)
+-@@ -136,7 +136,7 @@ class ResUNet2(ME.MinkowskiNetwork):
+-         kernel_size=1,
+-         stride=1,
+-         dilation=1,
+--        bias=True,
+-+        has_bias=True,
+-         dimension=D)
+- 
+-   def forward(self, x):
+-@@ -187,8 +187,8 @@ class ResUNet2(ME.MinkowskiNetwork):
+-     if self.normalize_feature:
+-       return ME.SparseTensor(
+-           out.F / torch.norm(out.F, p=2, dim=1, keepdim=True),
+--          coordinate_map_key=out.coordinate_map_key,
+--          coordinate_manager=out.coordinate_manager)
+-+          coords_key=out.coords_key,#out.coordinate_map_key,
+-+          coords_manager=out.coords_man)#out.coordinate_manager)
+-     else:
+-       return out
+- 
+-@@ -244,3 +244,8 @@ class ResUNetIN2D(ResUNetBN2D):
+- class ResUNetIN2E(ResUNetBN2E):
+-   NORM_TYPE = 'BN'
+-   BLOCK_NORM_TYPE = 'IN'
+-+
+-+class ResUNetBN2C(ResUNet2):
+-+  NORM_TYPE = 'BN'
+-+  CHANNELS = [None, 32, 64, 128, 256]
+-+  TR_CHANNELS = [None, 64, 64, 64, 128]
+-\ No newline at end of file
+-diff --git a/scripts/train_fcgf_kitti.sh b/scripts/train_fcgf_kitti.sh
+-index de073fd..64a0e8e 100755
+---- a/scripts/train_fcgf_kitti.sh
+-+++ b/scripts/train_fcgf_kitti.sh
+-@@ -3,20 +3,20 @@ export PATH_POSTFIX=$1
+- export MISC_ARGS=$2
+- 
+- export DATA_ROOT="./outputs/Experiments"
+--export DATASET=${DATASET:-KITTINMPairDataset}
+-+export DATASET=${DATASET:-KITTIMapDataset} #KITTINMPairDataset}
+- export TRAINER=${TRAINER:-HardestContrastiveLossTrainer}
+- export MODEL=${MODEL:-ResUNetBN2C}
+- export MODEL_N_OUT=${MODEL_N_OUT:-16}
+- export OPTIMIZER=${OPTIMIZER:-SGD}
+- export LR=${LR:-1e-1}
+- export MAX_EPOCH=${MAX_EPOCH:-200}
+--export BATCH_SIZE=${BATCH_SIZE:-8}
+-+export BATCH_SIZE=${BATCH_SIZE:-6}
+- export ITER_SIZE=${ITER_SIZE:-1}
+- export VOXEL_SIZE=${VOXEL_SIZE:-0.3}
+- export POSITIVE_PAIR_SEARCH_VOXEL_SIZE_MULTIPLIER=${POSITIVE_PAIR_SEARCH_VOXEL_SIZE_MULTIPLIER:-1.5}
+- export CONV1_KERNEL_SIZE=${CONV1_KERNEL_SIZE:-5}
+- export EXP_GAMMA=${EXP_GAMMA:-0.99}
+--export RANDOM_SCALE=${RANDOM_SCALE:-True}
+-+export RANDOM_SCALE=${RANDOM_SCALE:-False} #scale doesn't work for the local map
+- export TIME=$(date +"%Y-%m-%d_%H-%M-%S")
+- export KITTI_PATH=${KITTI_PATH:-/home/chrischoy/datasets/KITTI_FCGF}
+- export VERSION=$(git rev-parse HEAD)
+-
+-Tue Nov  3 01:04:07 2020       
+-+-----------------------------------------------------------------------------+
+-| NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |
+-|-------------------------------+----------------------+----------------------+
+-| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
+-| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
+-|===============================+======================+======================|
+-|   0  GeForce GTX TIT...  On   | 00000000:05:00.0 Off |                  N/A |
+-| 50%   83C    P2   139W / 250W |  12207MiB / 12211MiB |     93%      Default |
+-+-------------------------------+----------------------+----------------------+
+-|   1  GeForce GTX TIT...  On   | 00000000:06:00.0 Off |                  N/A |
+-| 27%   65C    P8    17W / 250W |     11MiB / 12212MiB |      0%      Default |
+-+-------------------------------+----------------------+----------------------+
+-|   2  GeForce GTX TIT...  On   | 00000000:09:00.0 Off |                  N/A |
+-| 52%   83C    P2   102W / 250W |   9539MiB / 12212MiB |      0%      Default |
+-+-------------------------------+----------------------+----------------------+
+-|   3  GeForce GTX TIT...  On   | 00000000:0A:00.0 Off |                  N/A |
+-| 40%   77C    P5    25W / 250W |     11MiB / 12212MiB |      0%      Default |
+-+-------------------------------+----------------------+----------------------+
+-                                                                               
+-+-----------------------------------------------------------------------------+
+-| Processes:                                                       GPU Memory |
+-|  GPU       PID   Type   Process name                             Usage      |
+-|=============================================================================|
+-|    0      4990      C   python3                                    12196MiB |
+-|    2     14147      C   python3                                     9528MiB |
+-+-----------------------------------------------------------------------------+
+-11/03 01:04:09 ===> Configurations
+-11/03 01:04:09     out_dir: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-03_01-04-07
+-11/03 01:04:09     trainer: HardestContrastiveLossTrainer
+-11/03 01:04:09     save_freq_epoch: 1
+-11/03 01:04:09     batch_size: 6
+-11/03 01:04:09     val_batch_size: 1
+-11/03 01:04:09     use_hard_negative: True
+-11/03 01:04:09     hard_negative_sample_ratio: 0.05
+-11/03 01:04:09     hard_negative_max_num: 3000
+-11/03 01:04:09     num_pos_per_batch: 1024
+-11/03 01:04:09     num_hn_samples_per_batch: 256
+-11/03 01:04:09     neg_thresh: 1.4
+-11/03 01:04:09     pos_thresh: 0.1
+-11/03 01:04:09     neg_weight: 1
+-11/03 01:04:09     use_random_scale: False
+-11/03 01:04:09     min_scale: 0.8
+-11/03 01:04:09     max_scale: 1.2
+-11/03 01:04:09     use_random_rotation: True
+-11/03 01:04:09     rotation_range: 360
+-11/03 01:04:09     train_phase: train
+-11/03 01:04:09     val_phase: val
+-11/03 01:04:09     test_phase: test
+-11/03 01:04:09     stat_freq: 40
+-11/03 01:04:09     test_valid: True
+-11/03 01:04:09     val_max_iter: 400
+-11/03 01:04:09     val_epoch_freq: 1
+-11/03 01:04:09     positive_pair_search_voxel_size_multiplier: 1.5
+-11/03 01:04:09     hit_ratio_thresh: 0.3
+-11/03 01:04:09     triplet_num_pos: 256
+-11/03 01:04:09     triplet_num_hn: 512
+-11/03 01:04:09     triplet_num_rand: 1024
+-11/03 01:04:09     model: ResUNetBN2C
+-11/03 01:04:09     model_n_out: 16
+-11/03 01:04:09     conv1_kernel_size: 5
+-11/03 01:04:09     normalize_feature: True
+-11/03 01:04:09     dist_type: L2
+-11/03 01:04:09     best_val_metric: feat_match_ratio
+-11/03 01:04:09     optimizer: SGD
+-11/03 01:04:09     max_epoch: 200
+-11/03 01:04:09     lr: 0.1
+-11/03 01:04:09     momentum: 0.8
+-11/03 01:04:09     sgd_momentum: 0.9
+-11/03 01:04:09     sgd_dampening: 0.1
+-11/03 01:04:09     adam_beta1: 0.9
+-11/03 01:04:09     adam_beta2: 0.999
+-11/03 01:04:09     weight_decay: 0.0001
+-11/03 01:04:09     iter_size: 1
+-11/03 01:04:09     bn_momentum: 0.05
+-11/03 01:04:09     exp_gamma: 0.99
+-11/03 01:04:09     scheduler: ExpLR
+-11/03 01:04:09     icp_cache_path: /home/chrischoy/datasets/FCGF/kitti/icp/
+-11/03 01:04:09     use_gpu: True
+-11/03 01:04:09     weights: None
+-11/03 01:04:09     weights_dir: None
+-11/03 01:04:09     resume: None
+-11/03 01:04:09     resume_dir: None
+-11/03 01:04:09     train_num_thread: 8
+-11/03 01:04:09     val_num_thread: 8
+-11/03 01:04:09     test_num_thread: 8
+-11/03 01:04:09     fast_validation: False
+-11/03 01:04:09     nn_max_n: 500
+-11/03 01:04:09     dataset: KITTIMapDataset
+-11/03 01:04:09     voxel_size: 0.3
+-11/03 01:04:09     threed_match_dir: /home/chrischoy/datasets/FCGF/threedmatch
+-11/03 01:04:09     kitti_root: /home/allie/dataset/kitti_odometry/
+-11/03 01:04:09     kitti_max_time_diff: 3
+-11/03 01:04:09     kitti_date: 2011_09_26
+-11/03 01:04:09     path_cmrdata: /home/allie/dataset/cmr_original
+-11/03 01:04:09     depth_max: 50
+-11/03 01:04:09     num_min_map_points: 20000.0
+-11/03 01:06:57 ResUNetBN2C(
+-  (conv1): MinkowskiConvolution(in=1, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
+-  (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  (block1): BasicBlockBN(
+-    (conv1): MinkowskiConvolution(in=32, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-    (conv2): MinkowskiConvolution(in=32, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  )
+-  (conv2): MinkowskiConvolution(in=32, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
+-  (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  (block2): BasicBlockBN(
+-    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  )
+-  (conv3): MinkowskiConvolution(in=64, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
+-  (norm3): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  (block3): BasicBlockBN(
+-    (conv1): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-    (conv2): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  )
+-  (conv4): MinkowskiConvolution(in=128, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
+-  (norm4): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  (block4): BasicBlockBN(
+-    (conv1): MinkowskiConvolution(in=256, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm1): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-    (conv2): MinkowskiConvolution(in=256, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm2): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  )
+-  (conv4_tr): MinkowskiConvolutionTranspose(in=256, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
+-  (norm4_tr): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  (block4_tr): BasicBlockBN(
+-    (conv1): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-    (conv2): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  )
+-  (conv3_tr): MinkowskiConvolutionTranspose(in=256, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
+-  (norm3_tr): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  (block3_tr): BasicBlockBN(
+-    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  )
+-  (conv2_tr): MinkowskiConvolutionTranspose(in=128, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
+-  (norm2_tr): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  (block2_tr): BasicBlockBN(
+-    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
+-    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
+-  )
+-  (conv1_tr): MinkowskiConvolution(in=96, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
+-  (final): MinkowskiConvolution(in=64, out=16, region_type=RegionType.HYPERCUBE, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
+-)
+-11/03 01:07:00 Resetting the data loader seed to 0
+-/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/MinkowskiEngine/SparseTensor.py:260: UserWarning: Coords implicitly converted to torch.IntTensor. To remove this warning, use `.int()` to convert the coords into an torch.IntTensor
+-  'To remove this warning, use `.int()` to convert the ' +
+-/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/MinkowskiEngine/SparseTensor.py:267: UserWarning: Coords implicitly converted to CPU type. To remove this warning, use `.cpu()` to convert the coords into a CPU type
+-  'To remove this warning, use `.cpu()` to convert the ' +
+-11/03 01:10:36 Validation iter 101 / 400 : Data Loading Time: 0.062, Feature Extraction Time: 1.172, Matching Time: 0.883, Loss: 0.999, RTE: 250.249, RRE: 0.855, Hit Ratio: 0.000, Feat Match Ratio: 0.000
+-11/03 01:14:04 Validation iter 201 / 400 : Data Loading Time: 0.014, Feature Extraction Time: 1.170, Matching Time: 0.879, Loss: 0.998, RTE: 222.577, RRE: 0.821, Hit Ratio: 0.000, Feat Match Ratio: 0.000
+-11/03 01:17:31 Validation iter 301 / 400 : Data Loading Time: 0.017, Feature Extraction Time: 1.159, Matching Time: 0.880, Loss: 0.995, RTE: 217.632, RRE: 0.824, Hit Ratio: 0.000, Feat Match Ratio: 0.000
+-11/03 01:20:47 Final Loss: 0.995, RTE: 224.363, RRE: 0.844, Hit Ratio: 0.000, Feat Match Ratio: 0.000
+-/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:449: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
+-  "please use `get_last_lr()`.", UserWarning)
+-11/03 01:20:47  Epoch: 1, LR: [0.1]
+-11/03 01:21:22 Train Epoch: 1 [0/477], Current Loss: 1.704e+00 Pos: 0.724 Neg: 0.980	Data time: 26.4148, Train time: 8.3080, Iter time: 34.7228
+-11/03 01:26:58 Train Epoch: 1 [40/477], Current Loss: 1.344e+00 Pos: 0.288 Neg: 1.057	Data time: 0.1094, Train time: 8.2677, Iter time: 8.3771
++       matching_timer.tic()
++       xyz0, xyz1, T_gt = input_dict['pcd0'], input_dict['pcd1'], input_dict['T_gt']
++-      xyz0_corr, xyz1_corr = self.find_corr(xyz0, xyz1, F0, F1, subsample_size=5000)
+++      xyz0_corr, xyz1_corr = self.find_corr(xyz0, xyz1, F0, F1, subsample_size=10000)#5000)
++       T_est = te.est_quad_linear_robust(xyz0_corr,
 \ No newline at end of file
 diff --git a/scripts/train_fcgf_kitti.sh b/scripts/train_fcgf_kitti.sh
-index de073fd..ed12044 100755
+index 64a0e8e..09e4c81 100755
 --- a/scripts/train_fcgf_kitti.sh
 +++ b/scripts/train_fcgf_kitti.sh
-@@ -3,7 +3,7 @@ export PATH_POSTFIX=$1
- export MISC_ARGS=$2
- 
- export DATA_ROOT="./outputs/Experiments"
--export DATASET=${DATASET:-KITTINMPairDataset}
-+export DATASET=${DATASET:-KITTIMapDataset} #KITTINMPairDataset}
- export TRAINER=${TRAINER:-HardestContrastiveLossTrainer}
- export MODEL=${MODEL:-ResUNetBN2C}
- export MODEL_N_OUT=${MODEL_N_OUT:-16}
+@@ -13,7 +13,7 @@ export MAX_EPOCH=${MAX_EPOCH:-200}
+ export BATCH_SIZE=${BATCH_SIZE:-6}
+ export ITER_SIZE=${ITER_SIZE:-1}
+ export VOXEL_SIZE=${VOXEL_SIZE:-0.3}
+-export POSITIVE_PAIR_SEARCH_VOXEL_SIZE_MULTIPLIER=${POSITIVE_PAIR_SEARCH_VOXEL_SIZE_MULTIPLIER:-1.5}
++export POSITIVE_PAIR_SEARCH_VOXEL_SIZE_MULTIPLIER=${POSITIVE_PAIR_SEARCH_VOXEL_SIZE_MULTIPLIER:-0.5} #1,5 -> 0.5 otherwise it might generate too many pairs from the dense map
+ export CONV1_KERNEL_SIZE=${CONV1_KERNEL_SIZE:-5}
+ export EXP_GAMMA=${EXP_GAMMA:-0.99}
+ export RANDOM_SCALE=${RANDOM_SCALE:-False} #scale doesn't work for the local map
 
-Mon Nov  2 17:08:49 2020       
+Thu Nov  5 01:31:22 2020       
 +-----------------------------------------------------------------------------+
 | NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |
 |-------------------------------+----------------------+----------------------+
@@ -575,96 +1719,95 @@ Mon Nov  2 17:08:49 2020
 | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
 |===============================+======================+======================|
 |   0  GeForce GTX TIT...  On   | 00000000:05:00.0 Off |                  N/A |
-| 50%   83C    P2   117W / 250W |  12207MiB / 12211MiB |    100%      Default |
+| 23%   61C    P8    32W / 250W |      0MiB / 12211MiB |      0%      Default |
 +-------------------------------+----------------------+----------------------+
 |   1  GeForce GTX TIT...  On   | 00000000:06:00.0 Off |                  N/A |
-| 24%   63C    P8    17W / 250W |     11MiB / 12212MiB |      0%      Default |
+| 23%   62C    P8    17W / 250W |      0MiB / 12212MiB |      0%      Default |
 +-------------------------------+----------------------+----------------------+
 |   2  GeForce GTX TIT...  On   | 00000000:09:00.0 Off |                  N/A |
-| 53%   83C    P2   110W / 250W |   9515MiB / 12212MiB |     97%      Default |
+| 53%   84C    P2   137W / 250W |  11247MiB / 12212MiB |    100%      Default |
 +-------------------------------+----------------------+----------------------+
 |   3  GeForce GTX TIT...  On   | 00000000:0A:00.0 Off |                  N/A |
-| 36%   70C    P8    21W / 250W |     11MiB / 12212MiB |      0%      Default |
+| 22%   45C    P8    16W / 250W |      0MiB / 12212MiB |      0%      Default |
 +-------------------------------+----------------------+----------------------+
                                                                                
 +-----------------------------------------------------------------------------+
 | Processes:                                                       GPU Memory |
 |  GPU       PID   Type   Process name                             Usage      |
 |=============================================================================|
-|    0      4990      C   python3                                    12196MiB |
-|    2     14147      C   python3                                     9504MiB |
+|    2      6811      C   python3                                    11236MiB |
 +-----------------------------------------------------------------------------+
-11/02 17:08:50 ===> Configurations
-11/02 17:08:50     out_dir: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b8i1-modelnout16/2020-11-02_17-08-48
-11/02 17:08:50     trainer: HardestContrastiveLossTrainer
-11/02 17:08:50     save_freq_epoch: 1
-11/02 17:08:50     batch_size: 8
-11/02 17:08:50     val_batch_size: 1
-11/02 17:08:50     use_hard_negative: True
-11/02 17:08:50     hard_negative_sample_ratio: 0.05
-11/02 17:08:50     hard_negative_max_num: 3000
-11/02 17:08:50     num_pos_per_batch: 1024
-11/02 17:08:50     num_hn_samples_per_batch: 256
-11/02 17:08:50     neg_thresh: 1.4
-11/02 17:08:50     pos_thresh: 0.1
-11/02 17:08:50     neg_weight: 1
-11/02 17:08:50     use_random_scale: True
-11/02 17:08:50     min_scale: 0.8
-11/02 17:08:50     max_scale: 1.2
-11/02 17:08:50     use_random_rotation: True
-11/02 17:08:50     rotation_range: 360
-11/02 17:08:50     train_phase: train
-11/02 17:08:50     val_phase: val
-11/02 17:08:50     test_phase: test
-11/02 17:08:50     stat_freq: 40
-11/02 17:08:50     test_valid: True
-11/02 17:08:50     val_max_iter: 400
-11/02 17:08:50     val_epoch_freq: 1
-11/02 17:08:50     positive_pair_search_voxel_size_multiplier: 1.5
-11/02 17:08:50     hit_ratio_thresh: 0.3
-11/02 17:08:50     triplet_num_pos: 256
-11/02 17:08:50     triplet_num_hn: 512
-11/02 17:08:50     triplet_num_rand: 1024
-11/02 17:08:50     model: ResUNetBN2C
-11/02 17:08:50     model_n_out: 16
-11/02 17:08:50     conv1_kernel_size: 5
-11/02 17:08:50     normalize_feature: True
-11/02 17:08:50     dist_type: L2
-11/02 17:08:50     best_val_metric: feat_match_ratio
-11/02 17:08:50     optimizer: SGD
-11/02 17:08:50     max_epoch: 200
-11/02 17:08:50     lr: 0.1
-11/02 17:08:50     momentum: 0.8
-11/02 17:08:50     sgd_momentum: 0.9
-11/02 17:08:50     sgd_dampening: 0.1
-11/02 17:08:50     adam_beta1: 0.9
-11/02 17:08:50     adam_beta2: 0.999
-11/02 17:08:50     weight_decay: 0.0001
-11/02 17:08:50     iter_size: 1
-11/02 17:08:50     bn_momentum: 0.05
-11/02 17:08:50     exp_gamma: 0.99
-11/02 17:08:50     scheduler: ExpLR
-11/02 17:08:50     icp_cache_path: /home/chrischoy/datasets/FCGF/kitti/icp/
-11/02 17:08:50     use_gpu: True
-11/02 17:08:50     weights: None
-11/02 17:08:50     weights_dir: None
-11/02 17:08:50     resume: None
-11/02 17:08:50     resume_dir: None
-11/02 17:08:50     train_num_thread: 2
-11/02 17:08:50     val_num_thread: 1
-11/02 17:08:50     test_num_thread: 2
-11/02 17:08:50     fast_validation: False
-11/02 17:08:50     nn_max_n: 500
-11/02 17:08:50     dataset: KITTIMapDataset
-11/02 17:08:50     voxel_size: 0.3
-11/02 17:08:50     threed_match_dir: /home/chrischoy/datasets/FCGF/threedmatch
-11/02 17:08:50     kitti_root: /home/allie/dataset/kitti_odometry/
-11/02 17:08:50     kitti_max_time_diff: 3
-11/02 17:08:50     kitti_date: 2011_09_26
-11/02 17:08:50     path_cmrdata: /home/allie/dataset/cmr_original
-11/02 17:08:50     depth_max: 50
-11/02 17:08:50     num_min_map_points: 20000.0
-11/02 17:11:43 ResUNetBN2C(
+11/05 01:31:24 ===> Configurations
+11/05 01:31:24     out_dir: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22
+11/05 01:31:24     trainer: HardestContrastiveLossTrainer
+11/05 01:31:24     save_freq_epoch: 1
+11/05 01:31:24     batch_size: 6
+11/05 01:31:24     val_batch_size: 1
+11/05 01:31:24     use_hard_negative: True
+11/05 01:31:24     hard_negative_sample_ratio: 0.05
+11/05 01:31:24     hard_negative_max_num: 3000
+11/05 01:31:24     num_pos_per_batch: 1024
+11/05 01:31:24     num_hn_samples_per_batch: 256
+11/05 01:31:24     neg_thresh: 1.4
+11/05 01:31:24     pos_thresh: 0.1
+11/05 01:31:24     neg_weight: 1
+11/05 01:31:24     use_random_scale: False
+11/05 01:31:24     min_scale: 0.8
+11/05 01:31:24     max_scale: 1.2
+11/05 01:31:24     use_random_rotation: True
+11/05 01:31:24     rotation_range: 360
+11/05 01:31:24     train_phase: train
+11/05 01:31:24     val_phase: val
+11/05 01:31:24     test_phase: test
+11/05 01:31:24     stat_freq: 40
+11/05 01:31:24     test_valid: True
+11/05 01:31:24     val_max_iter: 400
+11/05 01:31:24     val_epoch_freq: 1
+11/05 01:31:24     positive_pair_search_voxel_size_multiplier: 0.5
+11/05 01:31:24     hit_ratio_thresh: 0.3
+11/05 01:31:24     triplet_num_pos: 256
+11/05 01:31:24     triplet_num_hn: 512
+11/05 01:31:24     triplet_num_rand: 1024
+11/05 01:31:24     model: ResUNetBN2C
+11/05 01:31:24     model_n_out: 16
+11/05 01:31:24     conv1_kernel_size: 5
+11/05 01:31:24     normalize_feature: True
+11/05 01:31:24     dist_type: L2
+11/05 01:31:24     best_val_metric: feat_match_ratio
+11/05 01:31:24     optimizer: SGD
+11/05 01:31:24     max_epoch: 200
+11/05 01:31:24     lr: 0.1
+11/05 01:31:24     momentum: 0.8
+11/05 01:31:24     sgd_momentum: 0.9
+11/05 01:31:24     sgd_dampening: 0.1
+11/05 01:31:24     adam_beta1: 0.9
+11/05 01:31:24     adam_beta2: 0.999
+11/05 01:31:24     weight_decay: 0.0001
+11/05 01:31:24     iter_size: 1
+11/05 01:31:24     bn_momentum: 0.05
+11/05 01:31:24     exp_gamma: 0.99
+11/05 01:31:24     scheduler: ExpLR
+11/05 01:31:24     icp_cache_path: /home/chrischoy/datasets/FCGF/kitti/icp/
+11/05 01:31:24     use_gpu: True
+11/05 01:31:24     weights: None
+11/05 01:31:24     weights_dir: None
+11/05 01:31:24     resume: None
+11/05 01:31:24     resume_dir: None
+11/05 01:31:24     train_num_thread: 8
+11/05 01:31:24     val_num_thread: 8
+11/05 01:31:24     test_num_thread: 8
+11/05 01:31:24     fast_validation: False
+11/05 01:31:24     nn_max_n: 500
+11/05 01:31:24     dataset: KITTIMapDataset
+11/05 01:31:24     voxel_size: 0.3
+11/05 01:31:24     threed_match_dir: /home/chrischoy/datasets/FCGF/threedmatch
+11/05 01:31:24     kitti_root: /home/allie/dataset/kitti_odometry/
+11/05 01:31:24     kitti_max_time_diff: 3
+11/05 01:31:24     kitti_date: 2011_09_26
+11/05 01:31:24     path_cmrdata: /home/allie/dataset/cmr_original
+11/05 01:31:24     depth_max: 50
+11/05 01:31:24     num_min_map_points: 20000.0
+11/05 01:33:30 ResUNetBN2C(
   (conv1): MinkowskiConvolution(in=1, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
   (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
   (block1): BasicBlockBN(
@@ -724,781 +1867,675 @@ Mon Nov  2 17:08:49 2020
   (conv1_tr): MinkowskiConvolution(in=96, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
   (final): MinkowskiConvolution(in=64, out=16, region_type=RegionType.HYPERCUBE, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
 )
-11/02 17:11:45 Resetting the data loader seed to 0
-/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/MinkowskiEngine/SparseTensor.py:260: UserWarning: Coords implicitly converted to torch.IntTensor. To remove this warning, use `.int()` to convert the coords into an torch.IntTensor
+11/05 01:33:31 Resetting the data loader seed to 0
+/home/allie/miniconda3/lib/python3.7/site-packages/MinkowskiEngine-0.4.2-py3.7-linux-x86_64.egg/MinkowskiEngine/SparseTensor.py:229: UserWarning: Coords implicitly converted to torch.IntTensor. To remove this warning, use `.int()` to convert the coords into an torch.IntTensor
   'To remove this warning, use `.int()` to convert the ' +
-/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/MinkowskiEngine/SparseTensor.py:267: UserWarning: Coords implicitly converted to CPU type. To remove this warning, use `.cpu()` to convert the coords into a CPU type
+/home/allie/miniconda3/lib/python3.7/site-packages/MinkowskiEngine-0.4.2-py3.7-linux-x86_64.egg/MinkowskiEngine/SparseTensor.py:236: UserWarning: Coords implicitly converted to CPU type. To remove this warning, use `.cpu()` to convert the coords into a CPU type
   'To remove this warning, use `.cpu()` to convert the ' +
-11/02 17:18:03 Validation iter 101 / 400 : Data Loading Time: 2.147, Feature Extraction Time: 0.954, Matching Time: 0.619, Loss: 0.995, RTE: 257.727, RRE: 0.892, Hit Ratio: 0.000, Feat Match Ratio: 0.000
-11/02 17:24:23 Validation iter 201 / 400 : Data Loading Time: 2.181, Feature Extraction Time: 0.954, Matching Time: 0.631, Loss: 0.990, RTE: 228.406, RRE: 0.844, Hit Ratio: 0.000, Feat Match Ratio: 0.000
-11/02 17:31:11 Validation iter 301 / 400 : Data Loading Time: 2.429, Feature Extraction Time: 0.960, Matching Time: 0.641, Loss: 0.991, RTE: 222.431, RRE: 0.841, Hit Ratio: 0.000, Feat Match Ratio: 0.000
-11/02 17:37:29 Final Loss: 0.992, RTE: 228.734, RRE: 0.859, Hit Ratio: 0.000, Feat Match Ratio: 0.000
-/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:449: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
-  "please use `get_last_lr()`.", UserWarning)
-11/02 17:37:30  Epoch: 1, LR: [0.1]
-Traceback (most recent call last):
-  File "train.py", line 84, in <module>
-    main(config)
-  File "train.py", line 63, in main
-    trainer.train()
-  File "/home/allie/code/benchmark/FCGF/lib/trainer.py", line 132, in train
-    self._train_epoch(epoch)
-  File "/home/allie/code/benchmark/FCGF/lib/trainer.py", line 474, in _train_epoch
-    input_dict = data_loader_iter.next()
-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 435, in __next__
-    data = self._next_data()
-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1085, in _next_data
-    return self._process_data(data)
-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1111, in _process_data
-    data.reraise()
-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/_utils.py", line 428, in reraise
-    raise self.exc_type(msg)
-ValueError: Caught ValueError in DataLoader worker process 0.
-Original Traceback (most recent call last):
-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 198, in _worker_loop
-    data = fetcher.fetch(index)
-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 47, in fetch
-    return self.collate_fn(data)
-  File "/home/allie/code/benchmark/FCGF/lib/data_loaders.py", line 85, in collate_pair_fn
-    torch.from_numpy(np.array(matching_inds[batch_id]) + curr_start_inds))
-ValueError: operands could not be broadcast together with shapes (0,) (1,2) 
-
-Traceback (most recent call last):
-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/runpy.py", line 193, in _run_module_as_main
-    "__main__", mod_spec)
-  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/runpy.py", line 85, in _run_code
-    exec(code, run_globals)
-  File "/home/allie/code/benchmark/FCGF/scripts/test_kitti.py", line 144, in <module>
-    main(config)
-  File "/home/allie/code/benchmark/FCGF/scripts/test_kitti.py", line 27, in main
-    config, config.test_phase, 1, num_threads=config.test_num_workers, shuffle=True)
-AttributeError: 'EasyDict' object has no attribute 'test_num_workers'
-./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-03_01-04-07
+11/05 01:36:51 Validation iter 101 / 400 : Data Loading Time: 0.030, Feature Extraction Time: 0.839, Matching Time: 1.087, Loss: 0.995, RTE: 232.597, RRE: 0.810, Hit Ratio: 0.000, Feat Match Ratio: 0.000
+11/05 01:40:07 Validation iter 201 / 400 : Data Loading Time: 0.007, Feature Extraction Time: 0.843, Matching Time: 1.084, Loss: 0.995, RTE: 229.636, RRE: 0.849, Hit Ratio: 0.000, Feat Match Ratio: 0.000
+11/05 01:44:00 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.864, Matching Time: 1.184, Loss: 0.993, RTE: 220.317, RRE: 0.829, Hit Ratio: 0.000, Feat Match Ratio: 0.000
+11/05 01:47:07 Final Loss: 0.993, RTE: 223.164, RRE: 0.841, Hit Ratio: 0.000, Feat Match Ratio: 0.000
+11/05 01:47:07  Epoch: 1, LR: [0.1]
+11/05 01:47:28 Train Epoch: 1 [0/477], Current Loss: 1.658e+00 Pos: 0.642 Neg: 1.016	Data time: 13.5048, Train time: 7.0318, Iter time: 20.5366
+11/05 01:51:45 Train Epoch: 1 [40/477], Current Loss: 1.283e+00 Pos: 0.297 Neg: 0.986	Data time: 0.0193, Train time: 6.4053, Iter time: 6.4246
+11/05 01:55:51 Train Epoch: 1 [80/477], Current Loss: 1.049e+00 Pos: 0.391 Neg: 0.658	Data time: 0.0066, Train time: 6.1362, Iter time: 6.1427
+11/05 01:59:56 Train Epoch: 1 [120/477], Current Loss: 1.096e+00 Pos: 0.432 Neg: 0.664	Data time: 0.0067, Train time: 6.1250, Iter time: 6.1317
+11/05 02:04:02 Train Epoch: 1 [160/477], Current Loss: 1.013e+00 Pos: 0.369 Neg: 0.644	Data time: 0.0071, Train time: 6.1442, Iter time: 6.1513
+11/05 02:08:07 Train Epoch: 1 [200/477], Current Loss: 1.013e+00 Pos: 0.329 Neg: 0.685	Data time: 0.0075, Train time: 6.1021, Iter time: 6.1096
+11/05 02:12:17 Train Epoch: 1 [240/477], Current Loss: 9.379e-01 Pos: 0.435 Neg: 0.503	Data time: 0.0082, Train time: 6.2534, Iter time: 6.2616
+11/05 02:16:58 Train Epoch: 1 [280/477], Current Loss: 9.943e-01 Pos: 0.347 Neg: 0.647	Data time: 0.0122, Train time: 6.9964, Iter time: 7.0085
+11/05 02:21:03 Train Epoch: 1 [320/477], Current Loss: 9.331e-01 Pos: 0.398 Neg: 0.535	Data time: 0.0094, Train time: 6.1144, Iter time: 6.1238
+11/05 02:25:18 Train Epoch: 1 [360/477], Current Loss: 8.968e-01 Pos: 0.392 Neg: 0.505	Data time: 0.0102, Train time: 6.3711, Iter time: 6.3813
+11/05 02:29:20 Train Epoch: 1 [400/477], Current Loss: 8.934e-01 Pos: 0.401 Neg: 0.492	Data time: 0.0095, Train time: 6.0487, Iter time: 6.0582
+11/05 02:33:31 Train Epoch: 1 [440/477], Current Loss: 9.321e-01 Pos: 0.453 Neg: 0.479	Data time: 0.0099, Train time: 6.2574, Iter time: 6.2672
+11/05 02:37:06 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 02:37:06 Resetting the data loader seed to 0
+11/05 02:40:33 Validation iter 101 / 400 : Data Loading Time: 0.030, Feature Extraction Time: 0.895, Matching Time: 1.103, Loss: 0.990, RTE: 181.130, RRE: 0.702, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 02:43:54 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.892, Matching Time: 1.102, Loss: 0.991, RTE: 178.359, RRE: 0.715, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 02:47:37 Validation iter 301 / 400 : Data Loading Time: 0.009, Feature Extraction Time: 0.898, Matching Time: 1.169, Loss: 0.986, RTE: 175.156, RRE: 0.669, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 02:51:10 Final Loss: 0.985, RTE: 172.728, RRE: 0.673, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 02:51:10 Saving the best val model with feat_match_ratio: 0.0
+11/05 02:51:10 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/best_val_checkpoint.pth ...
+11/05 02:51:10  Epoch: 2, LR: [0.099]
+11/05 02:51:32 Train Epoch: 2 [0/477], Current Loss: 9.129e-01 Pos: 0.366 Neg: 0.547	Data time: 13.0873, Train time: 7.9353, Iter time: 21.0226
+11/05 02:55:42 Train Epoch: 2 [40/477], Current Loss: 9.004e-01 Pos: 0.395 Neg: 0.505	Data time: 0.0094, Train time: 6.2390, Iter time: 6.2484
+11/05 02:59:46 Train Epoch: 2 [80/477], Current Loss: 8.900e-01 Pos: 0.395 Neg: 0.495	Data time: 0.0071, Train time: 6.1057, Iter time: 6.1128
+11/05 03:03:57 Train Epoch: 2 [120/477], Current Loss: 8.868e-01 Pos: 0.397 Neg: 0.490	Data time: 0.0074, Train time: 6.2503, Iter time: 6.2577
+11/05 03:08:04 Train Epoch: 2 [160/477], Current Loss: 9.504e-01 Pos: 0.412 Neg: 0.538	Data time: 0.0076, Train time: 6.1656, Iter time: 6.1731
+11/05 03:12:09 Train Epoch: 2 [200/477], Current Loss: 8.910e-01 Pos: 0.378 Neg: 0.513	Data time: 0.0082, Train time: 6.1207, Iter time: 6.1289
+11/05 03:16:14 Train Epoch: 2 [240/477], Current Loss: 8.879e-01 Pos: 0.393 Neg: 0.495	Data time: 0.0083, Train time: 6.1114, Iter time: 6.1197
+11/05 03:20:51 Train Epoch: 2 [280/477], Current Loss: 8.848e-01 Pos: 0.394 Neg: 0.491	Data time: 0.0113, Train time: 6.9163, Iter time: 6.9276
+11/05 03:25:04 Train Epoch: 2 [320/477], Current Loss: 8.850e-01 Pos: 0.397 Neg: 0.488	Data time: 0.0090, Train time: 6.3269, Iter time: 6.3358
+11/05 03:29:10 Train Epoch: 2 [360/477], Current Loss: 8.833e-01 Pos: 0.395 Neg: 0.488	Data time: 0.0092, Train time: 6.1391, Iter time: 6.1483
+11/05 03:33:14 Train Epoch: 2 [400/477], Current Loss: 8.828e-01 Pos: 0.394 Neg: 0.488	Data time: 0.0097, Train time: 6.0900, Iter time: 6.0997
+11/05 03:37:22 Train Epoch: 2 [440/477], Current Loss: 8.828e-01 Pos: 0.393 Neg: 0.489	Data time: 0.0097, Train time: 6.1900, Iter time: 6.1997
+11/05 03:41:04 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 03:41:04 Resetting the data loader seed to 0
+11/05 03:44:31 Validation iter 101 / 400 : Data Loading Time: 0.024, Feature Extraction Time: 0.883, Matching Time: 1.124, Loss: 0.991, RTE: 174.481, RRE: 0.671, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 03:47:48 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.880, Matching Time: 1.098, Loss: 0.990, RTE: 172.524, RRE: 0.681, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 03:51:15 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.882, Matching Time: 1.122, Loss: 0.987, RTE: 176.372, RRE: 0.699, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 03:55:07 Final Loss: 0.988, RTE: 173.064, RRE: 0.687, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 03:55:07 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/05 03:55:07  Epoch: 3, LR: [0.09801]
+11/05 03:55:24 Train Epoch: 3 [0/477], Current Loss: 8.843e-01 Pos: 0.398 Neg: 0.487	Data time: 10.9499, Train time: 5.9981, Iter time: 16.9480
+11/05 03:59:31 Train Epoch: 3 [40/477], Current Loss: 8.823e-01 Pos: 0.392 Neg: 0.491	Data time: 0.0115, Train time: 6.1442, Iter time: 6.1558
+11/05 04:03:41 Train Epoch: 3 [80/477], Current Loss: 8.838e-01 Pos: 0.389 Neg: 0.495	Data time: 0.0067, Train time: 6.2617, Iter time: 6.2684
+11/05 04:07:49 Train Epoch: 3 [120/477], Current Loss: 1.133e+00 Pos: 0.405 Neg: 0.729	Data time: 0.0067, Train time: 6.1930, Iter time: 6.1997
+11/05 04:11:58 Train Epoch: 3 [160/477], Current Loss: 9.197e-01 Pos: 0.392 Neg: 0.528	Data time: 0.0069, Train time: 6.1965, Iter time: 6.2034
+11/05 04:16:06 Train Epoch: 3 [200/477], Current Loss: 8.974e-01 Pos: 0.382 Neg: 0.515	Data time: 0.0073, Train time: 6.1923, Iter time: 6.1995
+11/05 04:20:12 Train Epoch: 3 [240/477], Current Loss: 8.916e-01 Pos: 0.405 Neg: 0.486	Data time: 0.0081, Train time: 6.1546, Iter time: 6.1627
+11/05 04:24:39 Train Epoch: 3 [280/477], Current Loss: 8.950e-01 Pos: 0.396 Neg: 0.499	Data time: 0.0118, Train time: 6.6580, Iter time: 6.6698
+11/05 04:28:56 Train Epoch: 3 [320/477], Current Loss: 8.868e-01 Pos: 0.395 Neg: 0.492	Data time: 0.0103, Train time: 6.4156, Iter time: 6.4259
+11/05 04:33:03 Train Epoch: 3 [360/477], Current Loss: 8.852e-01 Pos: 0.394 Neg: 0.491	Data time: 0.0093, Train time: 6.1682, Iter time: 6.1774
+11/05 04:37:10 Train Epoch: 3 [400/477], Current Loss: 9.325e-01 Pos: 0.375 Neg: 0.557	Data time: 0.0091, Train time: 6.1511, Iter time: 6.1602
+11/05 04:41:20 Train Epoch: 3 [440/477], Current Loss: 8.919e-01 Pos: 0.394 Neg: 0.498	Data time: 0.0091, Train time: 6.2471, Iter time: 6.2562
+11/05 04:45:00 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 04:45:00 Resetting the data loader seed to 0
+11/05 04:48:30 Validation iter 101 / 400 : Data Loading Time: 0.036, Feature Extraction Time: 0.905, Matching Time: 1.119, Loss: 0.983, RTE: 162.542, RRE: 0.750, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 04:51:55 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.904, Matching Time: 1.123, Loss: 0.985, RTE: 177.505, RRE: 0.743, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 04:55:04 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.888, Matching Time: 1.084, Loss: 0.987, RTE: 176.445, RRE: 0.714, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 04:59:06 Final Loss: 0.983, RTE: 174.797, RRE: 0.688, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 04:59:06 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/05 04:59:06  Epoch: 4, LR: [0.0970299]
+11/05 04:59:31 Train Epoch: 4 [0/477], Current Loss: 8.895e-01 Pos: 0.398 Neg: 0.492	Data time: 16.7389, Train time: 7.9743, Iter time: 24.7132
+11/05 05:03:40 Train Epoch: 4 [40/477], Current Loss: 8.881e-01 Pos: 0.386 Neg: 0.503	Data time: 0.0077, Train time: 6.2148, Iter time: 6.2225
+11/05 05:07:44 Train Epoch: 4 [80/477], Current Loss: 8.971e-01 Pos: 0.396 Neg: 0.501	Data time: 0.0065, Train time: 6.0957, Iter time: 6.1022
+11/05 05:11:50 Train Epoch: 4 [120/477], Current Loss: 8.873e-01 Pos: 0.390 Neg: 0.497	Data time: 0.0068, Train time: 6.1598, Iter time: 6.1667
+11/05 05:15:54 Train Epoch: 4 [160/477], Current Loss: 8.878e-01 Pos: 0.398 Neg: 0.490	Data time: 0.0069, Train time: 6.0722, Iter time: 6.0790
+11/05 05:20:01 Train Epoch: 4 [200/477], Current Loss: 8.852e-01 Pos: 0.400 Neg: 0.486	Data time: 0.0067, Train time: 6.1718, Iter time: 6.1786
+11/05 05:24:08 Train Epoch: 4 [240/477], Current Loss: 9.090e-01 Pos: 0.436 Neg: 0.473	Data time: 0.0073, Train time: 6.1785, Iter time: 6.1858
+11/05 05:28:33 Train Epoch: 4 [280/477], Current Loss: 9.067e-01 Pos: 0.376 Neg: 0.530	Data time: 0.0104, Train time: 6.6072, Iter time: 6.6176
+11/05 05:33:02 Train Epoch: 4 [320/477], Current Loss: 8.999e-01 Pos: 0.407 Neg: 0.493	Data time: 0.0104, Train time: 6.7089, Iter time: 6.7193
+11/05 05:37:13 Train Epoch: 4 [360/477], Current Loss: 8.866e-01 Pos: 0.395 Neg: 0.491	Data time: 0.0089, Train time: 6.2747, Iter time: 6.2836
+11/05 05:41:21 Train Epoch: 4 [400/477], Current Loss: 9.009e-01 Pos: 0.408 Neg: 0.493	Data time: 0.0097, Train time: 6.1819, Iter time: 6.1916
+11/05 05:45:33 Train Epoch: 4 [440/477], Current Loss: 8.922e-01 Pos: 0.397 Neg: 0.495	Data time: 0.0090, Train time: 6.2813, Iter time: 6.2903
+11/05 05:49:12 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 05:49:12 Resetting the data loader seed to 0
+11/05 05:52:32 Validation iter 101 / 400 : Data Loading Time: 0.035, Feature Extraction Time: 0.884, Matching Time: 1.048, Loss: 0.989, RTE: 167.465, RRE: 0.732, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 05:55:52 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.886, Matching Time: 1.069, Loss: 0.988, RTE: 174.527, RRE: 0.711, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 05:59:08 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.884, Matching Time: 1.065, Loss: 0.992, RTE: 174.237, RRE: 0.711, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 06:03:09 Final Loss: 0.988, RTE: 170.873, RRE: 0.685, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 06:03:09 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/05 06:03:09  Epoch: 5, LR: [0.096059601]
+11/05 06:03:28 Train Epoch: 5 [0/477], Current Loss: 8.869e-01 Pos: 0.410 Neg: 0.477	Data time: 11.4992, Train time: 7.2910, Iter time: 18.7902
+11/05 06:07:42 Train Epoch: 5 [40/477], Current Loss: 8.842e-01 Pos: 0.391 Neg: 0.493	Data time: 0.0303, Train time: 6.3039, Iter time: 6.3342
+11/05 06:11:50 Train Epoch: 5 [80/477], Current Loss: 8.835e-01 Pos: 0.395 Neg: 0.488	Data time: 0.0063, Train time: 6.1970, Iter time: 6.2033
+11/05 06:16:01 Train Epoch: 5 [120/477], Current Loss: 8.840e-01 Pos: 0.388 Neg: 0.496	Data time: 0.0069, Train time: 6.2830, Iter time: 6.2899
+11/05 06:20:13 Train Epoch: 5 [160/477], Current Loss: 8.838e-01 Pos: 0.398 Neg: 0.486	Data time: 0.0064, Train time: 6.2881, Iter time: 6.2945
+11/05 06:24:21 Train Epoch: 5 [200/477], Current Loss: 8.830e-01 Pos: 0.392 Neg: 0.491	Data time: 0.0075, Train time: 6.1966, Iter time: 6.2041
+11/05 06:28:31 Train Epoch: 5 [240/477], Current Loss: 8.823e-01 Pos: 0.392 Neg: 0.490	Data time: 0.0081, Train time: 6.2357, Iter time: 6.2438
+11/05 06:32:49 Train Epoch: 5 [280/477], Current Loss: 8.834e-01 Pos: 0.390 Neg: 0.494	Data time: 0.0101, Train time: 6.4473, Iter time: 6.4574
+11/05 06:37:18 Train Epoch: 5 [320/477], Current Loss: 8.891e-01 Pos: 0.390 Neg: 0.499	Data time: 0.0104, Train time: 6.7055, Iter time: 6.7159
+11/05 06:41:22 Train Epoch: 5 [360/477], Current Loss: 8.841e-01 Pos: 0.393 Neg: 0.491	Data time: 0.0087, Train time: 6.0856, Iter time: 6.0942
+11/05 06:45:33 Train Epoch: 5 [400/477], Current Loss: 8.849e-01 Pos: 0.400 Neg: 0.485	Data time: 0.0100, Train time: 6.2590, Iter time: 6.2690
+11/05 06:49:40 Train Epoch: 5 [440/477], Current Loss: 8.847e-01 Pos: 0.387 Neg: 0.498	Data time: 0.0094, Train time: 6.1638, Iter time: 6.1732
+11/05 06:53:14 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 06:53:14 Resetting the data loader seed to 0
+11/05 06:56:38 Validation iter 101 / 400 : Data Loading Time: 0.033, Feature Extraction Time: 0.910, Matching Time: 1.067, Loss: 0.984, RTE: 172.231, RRE: 0.722, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 06:59:58 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.892, Matching Time: 1.083, Loss: 0.983, RTE: 175.236, RRE: 0.740, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 07:03:09 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.885, Matching Time: 1.063, Loss: 0.984, RTE: 174.518, RRE: 0.711, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 07:07:04 Final Loss: 0.985, RTE: 173.632, RRE: 0.695, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 07:07:05 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/05 07:07:05  Epoch: 6, LR: [0.09509900499]
+11/05 07:07:23 Train Epoch: 6 [0/477], Current Loss: 8.841e-01 Pos: 0.401 Neg: 0.483	Data time: 10.4744, Train time: 6.8869, Iter time: 17.3613
+11/05 07:11:32 Train Epoch: 6 [40/477], Current Loss: 8.841e-01 Pos: 0.386 Neg: 0.498	Data time: 0.0104, Train time: 6.2199, Iter time: 6.2303
+11/05 07:15:45 Train Epoch: 6 [80/477], Current Loss: 8.834e-01 Pos: 0.394 Neg: 0.489	Data time: 0.0070, Train time: 6.3155, Iter time: 6.3226
+11/05 07:19:51 Train Epoch: 6 [120/477], Current Loss: 8.828e-01 Pos: 0.397 Neg: 0.485	Data time: 0.0063, Train time: 6.1492, Iter time: 6.1555
+11/05 07:24:02 Train Epoch: 6 [160/477], Current Loss: 8.835e-01 Pos: 0.389 Neg: 0.495	Data time: 0.0065, Train time: 6.2786, Iter time: 6.2851
+11/05 07:28:08 Train Epoch: 6 [200/477], Current Loss: 8.822e-01 Pos: 0.390 Neg: 0.492	Data time: 0.0069, Train time: 6.1362, Iter time: 6.1431
+11/05 07:32:16 Train Epoch: 6 [240/477], Current Loss: 8.824e-01 Pos: 0.390 Neg: 0.492	Data time: 0.0086, Train time: 6.1787, Iter time: 6.1872
+11/05 07:36:19 Train Epoch: 6 [280/477], Current Loss: 8.822e-01 Pos: 0.389 Neg: 0.493	Data time: 0.0085, Train time: 6.0679, Iter time: 6.0764
+11/05 07:41:06 Train Epoch: 6 [320/477], Current Loss: 8.828e-01 Pos: 0.394 Neg: 0.489	Data time: 0.0118, Train time: 7.1636, Iter time: 7.1755
+11/05 07:45:13 Train Epoch: 6 [360/477], Current Loss: 8.815e-01 Pos: 0.394 Neg: 0.488	Data time: 0.0085, Train time: 6.1835, Iter time: 6.1921
+11/05 07:49:18 Train Epoch: 6 [400/477], Current Loss: 8.818e-01 Pos: 0.394 Neg: 0.488	Data time: 0.0094, Train time: 6.1027, Iter time: 6.1121
+11/05 07:53:30 Train Epoch: 6 [440/477], Current Loss: 8.823e-01 Pos: 0.395 Neg: 0.488	Data time: 0.0093, Train time: 6.2863, Iter time: 6.2956
+11/05 07:57:08 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 07:57:08 Resetting the data loader seed to 0
+11/05 08:00:32 Validation iter 101 / 400 : Data Loading Time: 0.030, Feature Extraction Time: 0.887, Matching Time: 1.082, Loss: 0.986, RTE: 163.001, RRE: 0.748, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 08:03:55 Validation iter 201 / 400 : Data Loading Time: 0.009, Feature Extraction Time: 0.884, Matching Time: 1.105, Loss: 0.983, RTE: 168.516, RRE: 0.698, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 08:07:16 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.882, Matching Time: 1.106, Loss: 0.979, RTE: 172.493, RRE: 0.673, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 08:11:03 Final Loss: 0.982, RTE: 174.936, RRE: 0.697, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 08:11:03 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/05 08:11:03  Epoch: 7, LR: [0.0941480149401]
+11/05 08:11:30 Train Epoch: 7 [0/477], Current Loss: 8.817e-01 Pos: 0.393 Neg: 0.489	Data time: 18.9043, Train time: 7.5805, Iter time: 26.4848
+11/05 08:15:39 Train Epoch: 7 [40/477], Current Loss: 8.858e-01 Pos: 0.405 Neg: 0.481	Data time: 0.0213, Train time: 6.1867, Iter time: 6.2080
+11/05 08:19:46 Train Epoch: 7 [80/477], Current Loss: 8.817e-01 Pos: 0.395 Neg: 0.487	Data time: 0.0068, Train time: 6.1713, Iter time: 6.1781
+11/05 08:23:53 Train Epoch: 7 [120/477], Current Loss: 8.816e-01 Pos: 0.390 Neg: 0.492	Data time: 0.0064, Train time: 6.1722, Iter time: 6.1786
+11/05 08:28:04 Train Epoch: 7 [160/477], Current Loss: 8.825e-01 Pos: 0.391 Neg: 0.491	Data time: 0.0079, Train time: 6.2705, Iter time: 6.2784
+11/05 08:32:10 Train Epoch: 7 [200/477], Current Loss: 8.854e-01 Pos: 0.390 Neg: 0.496	Data time: 0.0067, Train time: 6.1348, Iter time: 6.1415
+11/05 08:36:19 Train Epoch: 7 [240/477], Current Loss: 8.860e-01 Pos: 0.370 Neg: 0.516	Data time: 0.0087, Train time: 6.2290, Iter time: 6.2378
+11/05 08:40:26 Train Epoch: 7 [280/477], Current Loss: 8.881e-01 Pos: 0.394 Neg: 0.494	Data time: 0.0081, Train time: 6.1514, Iter time: 6.1595
+11/05 08:45:04 Train Epoch: 7 [320/477], Current Loss: 8.845e-01 Pos: 0.397 Neg: 0.487	Data time: 0.0137, Train time: 6.9357, Iter time: 6.9494
+11/05 08:49:13 Train Epoch: 7 [360/477], Current Loss: 8.830e-01 Pos: 0.394 Neg: 0.489	Data time: 0.0090, Train time: 6.2344, Iter time: 6.2434
+11/05 08:53:20 Train Epoch: 7 [400/477], Current Loss: 8.826e-01 Pos: 0.390 Neg: 0.493	Data time: 0.0090, Train time: 6.1488, Iter time: 6.1578
+11/05 08:57:29 Train Epoch: 7 [440/477], Current Loss: 8.821e-01 Pos: 0.387 Neg: 0.495	Data time: 0.0095, Train time: 6.2234, Iter time: 6.2329
+11/05 09:01:09 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 09:01:09 Resetting the data loader seed to 0
+11/05 09:04:31 Validation iter 101 / 400 : Data Loading Time: 0.033, Feature Extraction Time: 0.887, Matching Time: 1.055, Loss: 0.981, RTE: 171.682, RRE: 0.655, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 09:07:52 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.884, Matching Time: 1.080, Loss: 0.986, RTE: 169.820, RRE: 0.668, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 09:11:10 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.887, Matching Time: 1.079, Loss: 0.985, RTE: 172.221, RRE: 0.689, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 09:14:31 Final Loss: 0.983, RTE: 173.452, RRE: 0.698, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 09:14:32 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/05 09:14:32  Epoch: 8, LR: [0.093206534790699]
+11/05 09:15:00 Train Epoch: 8 [0/477], Current Loss: 8.816e-01 Pos: 0.392 Neg: 0.490	Data time: 19.9401, Train time: 8.0155, Iter time: 27.9556
+11/05 09:19:22 Train Epoch: 8 [40/477], Current Loss: 8.817e-01 Pos: 0.393 Neg: 0.489	Data time: 0.0083, Train time: 6.5392, Iter time: 6.5475
+11/05 09:23:30 Train Epoch: 8 [80/477], Current Loss: 8.814e-01 Pos: 0.391 Neg: 0.491	Data time: 0.0069, Train time: 6.1831, Iter time: 6.1900
+11/05 09:27:36 Train Epoch: 8 [120/477], Current Loss: 8.818e-01 Pos: 0.384 Neg: 0.497	Data time: 0.0063, Train time: 6.1443, Iter time: 6.1506
+11/05 09:31:45 Train Epoch: 8 [160/477], Current Loss: 8.816e-01 Pos: 0.387 Neg: 0.494	Data time: 0.0066, Train time: 6.2186, Iter time: 6.2252
+11/05 09:35:56 Train Epoch: 8 [200/477], Current Loss: 8.813e-01 Pos: 0.395 Neg: 0.487	Data time: 0.0072, Train time: 6.2685, Iter time: 6.2757
+11/05 09:40:04 Train Epoch: 8 [240/477], Current Loss: 8.813e-01 Pos: 0.392 Neg: 0.490	Data time: 0.0080, Train time: 6.2110, Iter time: 6.2190
+11/05 09:44:13 Train Epoch: 8 [280/477], Current Loss: 8.856e-01 Pos: 0.359 Neg: 0.526	Data time: 0.0089, Train time: 6.2157, Iter time: 6.2246
+11/05 09:48:57 Train Epoch: 8 [320/477], Current Loss: 8.849e-01 Pos: 0.374 Neg: 0.511	Data time: 0.0131, Train time: 7.0746, Iter time: 7.0877
+11/05 09:53:08 Train Epoch: 8 [360/477], Current Loss: 8.824e-01 Pos: 0.395 Neg: 0.488	Data time: 0.0098, Train time: 6.2716, Iter time: 6.2814
+11/05 09:57:18 Train Epoch: 8 [400/477], Current Loss: 8.817e-01 Pos: 0.394 Neg: 0.487	Data time: 0.0093, Train time: 6.2346, Iter time: 6.2439
+11/05 10:01:25 Train Epoch: 8 [440/477], Current Loss: 8.817e-01 Pos: 0.393 Neg: 0.489	Data time: 0.0095, Train time: 6.1720, Iter time: 6.1814
+11/05 10:05:04 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 10:05:04 Resetting the data loader seed to 0
+11/05 10:08:31 Validation iter 101 / 400 : Data Loading Time: 0.032, Feature Extraction Time: 0.896, Matching Time: 1.104, Loss: 0.981, RTE: 173.654, RRE: 0.674, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 10:11:47 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.880, Matching Time: 1.089, Loss: 0.987, RTE: 181.810, RRE: 0.698, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 10:15:02 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.878, Matching Time: 1.077, Loss: 0.987, RTE: 173.696, RRE: 0.693, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 10:18:23 Final Loss: 0.984, RTE: 169.041, RRE: 0.683, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 10:18:24 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/05 10:18:24  Epoch: 9, LR: [0.09227446944279201]
+11/05 10:18:50 Train Epoch: 9 [0/477], Current Loss: 8.846e-01 Pos: 0.390 Neg: 0.495	Data time: 18.6116, Train time: 7.6090, Iter time: 26.2206
+11/05 10:23:22 Train Epoch: 9 [40/477], Current Loss: 8.818e-01 Pos: 0.392 Neg: 0.490	Data time: 0.0174, Train time: 6.7776, Iter time: 6.7950
+11/05 10:27:28 Train Epoch: 9 [80/477], Current Loss: 8.812e-01 Pos: 0.393 Neg: 0.488	Data time: 0.0066, Train time: 6.1452, Iter time: 6.1518
+11/05 10:31:35 Train Epoch: 9 [120/477], Current Loss: 8.819e-01 Pos: 0.390 Neg: 0.492	Data time: 0.0070, Train time: 6.1451, Iter time: 6.1521
+11/05 10:35:46 Train Epoch: 9 [160/477], Current Loss: 8.811e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0077, Train time: 6.2890, Iter time: 6.2967
+11/05 10:39:51 Train Epoch: 9 [200/477], Current Loss: 8.814e-01 Pos: 0.392 Neg: 0.490	Data time: 0.0066, Train time: 6.1037, Iter time: 6.1103
+11/05 10:43:59 Train Epoch: 9 [240/477], Current Loss: 8.817e-01 Pos: 0.393 Neg: 0.489	Data time: 0.0086, Train time: 6.2046, Iter time: 6.2132
+11/05 10:48:03 Train Epoch: 9 [280/477], Current Loss: 8.814e-01 Pos: 0.394 Neg: 0.487	Data time: 0.0087, Train time: 6.0788, Iter time: 6.0875
+11/05 10:52:36 Train Epoch: 9 [320/477], Current Loss: 8.813e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0115, Train time: 6.8088, Iter time: 6.8203
+11/05 10:56:46 Train Epoch: 9 [360/477], Current Loss: 8.813e-01 Pos: 0.390 Neg: 0.492	Data time: 0.0090, Train time: 6.2412, Iter time: 6.2501
+11/05 11:00:55 Train Epoch: 9 [400/477], Current Loss: 8.817e-01 Pos: 0.381 Neg: 0.501	Data time: 0.0091, Train time: 6.2181, Iter time: 6.2272
+11/05 11:05:04 Train Epoch: 9 [440/477], Current Loss: 8.813e-01 Pos: 0.392 Neg: 0.490	Data time: 0.0095, Train time: 6.2047, Iter time: 6.2142
+11/05 11:08:42 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 11:08:42 Resetting the data loader seed to 0
+11/05 11:12:09 Validation iter 101 / 400 : Data Loading Time: 0.027, Feature Extraction Time: 0.891, Matching Time: 1.110, Loss: 0.983, RTE: 167.406, RRE: 0.707, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 11:15:33 Validation iter 201 / 400 : Data Loading Time: 0.009, Feature Extraction Time: 0.892, Matching Time: 1.121, Loss: 0.978, RTE: 161.768, RRE: 0.661, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 11:18:52 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.889, Matching Time: 1.106, Loss: 0.984, RTE: 165.801, RRE: 0.678, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 11:21:58 Final Loss: 0.984, RTE: 171.113, RRE: 0.689, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 11:21:58 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/05 11:21:58  Epoch: 10, LR: [0.09135172474836409]
+11/05 11:22:12 Train Epoch: 10 [0/477], Current Loss: 8.811e-01 Pos: 0.394 Neg: 0.487	Data time: 7.7318, Train time: 5.8223, Iter time: 13.5542
+11/05 11:26:58 Train Epoch: 10 [40/477], Current Loss: 8.809e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0096, Train time: 7.1528, Iter time: 7.1623
+11/05 11:31:09 Train Epoch: 10 [80/477], Current Loss: 8.808e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0064, Train time: 6.2452, Iter time: 6.2516
+11/05 11:35:21 Train Epoch: 10 [120/477], Current Loss: 8.862e-01 Pos: 0.403 Neg: 0.483	Data time: 0.0066, Train time: 6.3108, Iter time: 6.3174
+11/05 11:39:29 Train Epoch: 10 [160/477], Current Loss: 8.820e-01 Pos: 0.393 Neg: 0.489	Data time: 0.0068, Train time: 6.1860, Iter time: 6.1928
+11/05 11:43:36 Train Epoch: 10 [200/477], Current Loss: 8.822e-01 Pos: 0.398 Neg: 0.484	Data time: 0.0074, Train time: 6.1725, Iter time: 6.1799
+11/05 11:47:44 Train Epoch: 10 [240/477], Current Loss: 8.809e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0076, Train time: 6.1745, Iter time: 6.1821
+11/05 11:51:46 Train Epoch: 10 [280/477], Current Loss: 8.815e-01 Pos: 0.393 Neg: 0.489	Data time: 0.0079, Train time: 6.0452, Iter time: 6.0531
+11/05 11:56:25 Train Epoch: 10 [320/477], Current Loss: 8.811e-01 Pos: 0.387 Neg: 0.494	Data time: 0.0120, Train time: 6.9700, Iter time: 6.9820
+11/05 12:00:36 Train Epoch: 10 [360/477], Current Loss: 8.810e-01 Pos: 0.394 Neg: 0.487	Data time: 0.0104, Train time: 6.2579, Iter time: 6.2683
+11/05 12:04:45 Train Epoch: 10 [400/477], Current Loss: 8.820e-01 Pos: 0.398 Neg: 0.484	Data time: 0.0103, Train time: 6.2288, Iter time: 6.2392
+11/05 12:08:49 Train Epoch: 10 [440/477], Current Loss: 8.809e-01 Pos: 0.394 Neg: 0.487	Data time: 0.0099, Train time: 6.0718, Iter time: 6.0818
+11/05 12:12:25 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 12:12:25 Resetting the data loader seed to 0
+11/05 12:15:47 Validation iter 101 / 400 : Data Loading Time: 0.024, Feature Extraction Time: 0.882, Matching Time: 1.075, Loss: 0.995, RTE: 183.224, RRE: 0.699, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 12:19:12 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.884, Matching Time: 1.108, Loss: 0.992, RTE: 177.374, RRE: 0.692, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 12:22:24 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.884, Matching Time: 1.078, Loss: 0.992, RTE: 176.745, RRE: 0.700, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 12:25:41 Final Loss: 0.991, RTE: 172.876, RRE: 0.689, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 12:25:42 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/05 12:25:42  Epoch: 11, LR: [0.09043820750088044]
+11/05 12:26:06 Train Epoch: 11 [0/477], Current Loss: 8.809e-01 Pos: 0.391 Neg: 0.490	Data time: 16.0422, Train time: 8.1352, Iter time: 24.1773
+11/05 12:30:44 Train Epoch: 11 [40/477], Current Loss: 8.808e-01 Pos: 0.393 Neg: 0.487	Data time: 0.0087, Train time: 6.9256, Iter time: 6.9343
+11/05 12:34:54 Train Epoch: 11 [80/477], Current Loss: 8.810e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0063, Train time: 6.2544, Iter time: 6.2607
+11/05 12:38:58 Train Epoch: 11 [120/477], Current Loss: 8.810e-01 Pos: 0.386 Neg: 0.495	Data time: 0.0074, Train time: 6.0774, Iter time: 6.0847
+11/05 12:43:06 Train Epoch: 11 [160/477], Current Loss: 8.807e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0071, Train time: 6.1931, Iter time: 6.2002
+11/05 12:47:12 Train Epoch: 11 [200/477], Current Loss: 8.810e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0074, Train time: 6.1612, Iter time: 6.1686
+11/05 12:51:20 Train Epoch: 11 [240/477], Current Loss: 8.808e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0081, Train time: 6.1875, Iter time: 6.1956
+11/05 12:55:32 Train Epoch: 11 [280/477], Current Loss: 8.807e-01 Pos: 0.394 Neg: 0.487	Data time: 0.0084, Train time: 6.2810, Iter time: 6.2893
+11/05 13:00:06 Train Epoch: 11 [320/477], Current Loss: 8.807e-01 Pos: 0.388 Neg: 0.493	Data time: 0.0133, Train time: 6.8385, Iter time: 6.8518
+11/05 13:04:23 Train Epoch: 11 [360/477], Current Loss: 8.808e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0095, Train time: 6.4221, Iter time: 6.4316
+11/05 13:08:30 Train Epoch: 11 [400/477], Current Loss: 8.807e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0089, Train time: 6.1615, Iter time: 6.1704
+11/05 13:12:37 Train Epoch: 11 [440/477], Current Loss: 8.808e-01 Pos: 0.389 Neg: 0.492	Data time: 0.0095, Train time: 6.1634, Iter time: 6.1729
+11/05 13:16:13 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 13:16:13 Resetting the data loader seed to 0
+11/05 13:19:40 Validation iter 101 / 400 : Data Loading Time: 0.030, Feature Extraction Time: 0.890, Matching Time: 1.113, Loss: 0.988, RTE: 167.626, RRE: 0.676, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 13:23:04 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.891, Matching Time: 1.118, Loss: 0.986, RTE: 176.729, RRE: 0.684, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 13:26:19 Validation iter 301 / 400 : Data Loading Time: 0.009, Feature Extraction Time: 0.893, Matching Time: 1.089, Loss: 0.987, RTE: 176.615, RRE: 0.678, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 13:29:36 Final Loss: 0.988, RTE: 172.702, RRE: 0.688, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 13:29:37 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/05 13:29:37  Epoch: 12, LR: [0.08953382542587164]
+11/05 13:29:57 Train Epoch: 12 [0/477], Current Loss: 8.810e-01 Pos: 0.392 Neg: 0.489	Data time: 12.7240, Train time: 7.0835, Iter time: 19.8074
+11/05 13:34:32 Train Epoch: 12 [40/477], Current Loss: 8.808e-01 Pos: 0.393 Neg: 0.488	Data time: 0.0120, Train time: 6.8637, Iter time: 6.8756
+11/05 13:38:40 Train Epoch: 12 [80/477], Current Loss: 8.807e-01 Pos: 0.387 Neg: 0.493	Data time: 0.0060, Train time: 6.1956, Iter time: 6.2016
+11/05 13:42:48 Train Epoch: 12 [120/477], Current Loss: 8.808e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0066, Train time: 6.1870, Iter time: 6.1936
+11/05 13:46:54 Train Epoch: 12 [160/477], Current Loss: 8.808e-01 Pos: 0.394 Neg: 0.486	Data time: 0.0070, Train time: 6.1572, Iter time: 6.1642
+11/05 13:51:07 Train Epoch: 12 [200/477], Current Loss: 8.806e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0077, Train time: 6.3077, Iter time: 6.3154
+11/05 13:55:16 Train Epoch: 12 [240/477], Current Loss: 8.882e-01 Pos: 0.410 Neg: 0.478	Data time: 0.0085, Train time: 6.2139, Iter time: 6.2224
+11/05 13:59:27 Train Epoch: 12 [280/477], Current Loss: 8.819e-01 Pos: 0.395 Neg: 0.486	Data time: 0.0099, Train time: 6.2597, Iter time: 6.2696
+11/05 14:03:43 Train Epoch: 12 [320/477], Current Loss: 8.814e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0107, Train time: 6.3853, Iter time: 6.3961
+11/05 14:08:11 Train Epoch: 12 [360/477], Current Loss: 8.809e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0112, Train time: 6.6861, Iter time: 6.6973
+11/05 14:12:19 Train Epoch: 12 [400/477], Current Loss: 8.813e-01 Pos: 0.393 Neg: 0.488	Data time: 0.0095, Train time: 6.1948, Iter time: 6.2043
+11/05 14:16:27 Train Epoch: 12 [440/477], Current Loss: 8.808e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0102, Train time: 6.2056, Iter time: 6.2158
+11/05 14:20:06 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 14:20:07 Resetting the data loader seed to 0
+11/05 14:23:26 Validation iter 101 / 400 : Data Loading Time: 0.028, Feature Extraction Time: 0.881, Matching Time: 1.049, Loss: 0.988, RTE: 158.605, RRE: 0.669, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 14:26:40 Validation iter 201 / 400 : Data Loading Time: 0.007, Feature Extraction Time: 0.882, Matching Time: 1.042, Loss: 0.988, RTE: 164.840, RRE: 0.672, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 14:29:58 Validation iter 301 / 400 : Data Loading Time: 0.007, Feature Extraction Time: 0.877, Matching Time: 1.058, Loss: 0.984, RTE: 167.664, RRE: 0.678, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 14:33:08 Final Loss: 0.987, RTE: 173.034, RRE: 0.696, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 14:33:08 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/05 14:33:08  Epoch: 13, LR: [0.08863848717161293]
+11/05 14:33:30 Train Epoch: 13 [0/477], Current Loss: 8.809e-01 Pos: 0.390 Neg: 0.491	Data time: 14.4156, Train time: 7.0073, Iter time: 21.4229
+11/05 14:38:04 Train Epoch: 13 [40/477], Current Loss: 8.812e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0249, Train time: 6.8284, Iter time: 6.8533
+11/05 14:42:14 Train Epoch: 13 [80/477], Current Loss: 8.808e-01 Pos: 0.393 Neg: 0.488	Data time: 0.0066, Train time: 6.2453, Iter time: 6.2520
+11/05 14:46:26 Train Epoch: 13 [120/477], Current Loss: 8.812e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0070, Train time: 6.2877, Iter time: 6.2947
+11/05 14:50:32 Train Epoch: 13 [160/477], Current Loss: 8.807e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0068, Train time: 6.1607, Iter time: 6.1675
+11/05 14:54:40 Train Epoch: 13 [200/477], Current Loss: 8.828e-01 Pos: 0.390 Neg: 0.492	Data time: 0.0081, Train time: 6.1805, Iter time: 6.1886
+11/05 14:58:45 Train Epoch: 13 [240/477], Current Loss: 8.815e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0075, Train time: 6.1278, Iter time: 6.1353
+11/05 15:02:53 Train Epoch: 13 [280/477], Current Loss: 8.813e-01 Pos: 0.389 Neg: 0.493	Data time: 0.0083, Train time: 6.1770, Iter time: 6.1854
+11/05 15:06:59 Train Epoch: 13 [320/477], Current Loss: 8.817e-01 Pos: 0.394 Neg: 0.488	Data time: 0.0079, Train time: 6.1433, Iter time: 6.1512
+11/05 15:11:38 Train Epoch: 13 [360/477], Current Loss: 8.814e-01 Pos: 0.392 Neg: 0.490	Data time: 0.0117, Train time: 6.9574, Iter time: 6.9691
+11/05 15:15:45 Train Epoch: 13 [400/477], Current Loss: 8.809e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0097, Train time: 6.1817, Iter time: 6.1914
+11/05 15:19:51 Train Epoch: 13 [440/477], Current Loss: 8.814e-01 Pos: 0.388 Neg: 0.493	Data time: 0.0090, Train time: 6.1265, Iter time: 6.1355
+11/05 15:23:27 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 15:23:27 Resetting the data loader seed to 0
+11/05 15:26:54 Validation iter 101 / 400 : Data Loading Time: 0.028, Feature Extraction Time: 0.885, Matching Time: 1.114, Loss: 0.995, RTE: 168.828, RRE: 0.698, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 15:30:10 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.886, Matching Time: 1.083, Loss: 0.994, RTE: 168.935, RRE: 0.664, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 15:33:28 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.883, Matching Time: 1.081, Loss: 0.995, RTE: 172.178, RRE: 0.665, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 15:36:38 Final Loss: 0.991, RTE: 171.223, RRE: 0.684, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 15:36:38 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/05 15:36:38  Epoch: 14, LR: [0.08775210229989679]
+11/05 15:37:00 Train Epoch: 14 [0/477], Current Loss: 8.812e-01 Pos: 0.390 Neg: 0.491	Data time: 14.7927, Train time: 6.9810, Iter time: 21.7737
+11/05 15:41:29 Train Epoch: 14 [40/477], Current Loss: 8.914e-01 Pos: 0.373 Neg: 0.518	Data time: 0.0308, Train time: 6.6740, Iter time: 6.7047
+11/05 15:45:49 Train Epoch: 14 [80/477], Current Loss: 8.823e-01 Pos: 0.393 Neg: 0.489	Data time: 0.0073, Train time: 6.5114, Iter time: 6.5188
+11/05 15:49:59 Train Epoch: 14 [120/477], Current Loss: 8.818e-01 Pos: 0.395 Neg: 0.487	Data time: 0.0067, Train time: 6.2194, Iter time: 6.2261
+11/05 15:54:00 Train Epoch: 14 [160/477], Current Loss: 8.811e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0072, Train time: 6.0222, Iter time: 6.0294
+11/05 15:58:13 Train Epoch: 14 [200/477], Current Loss: 8.817e-01 Pos: 0.387 Neg: 0.494	Data time: 0.0076, Train time: 6.3226, Iter time: 6.3302
+11/05 16:02:20 Train Epoch: 14 [240/477], Current Loss: 8.813e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0085, Train time: 6.1562, Iter time: 6.1647
+11/05 16:06:24 Train Epoch: 14 [280/477], Current Loss: 8.809e-01 Pos: 0.389 Neg: 0.492	Data time: 0.0088, Train time: 6.1037, Iter time: 6.1125
+11/05 16:10:32 Train Epoch: 14 [320/477], Current Loss: 8.806e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0095, Train time: 6.1949, Iter time: 6.2043
+11/05 16:15:13 Train Epoch: 14 [360/477], Current Loss: 8.810e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0138, Train time: 7.0081, Iter time: 7.0219
+11/05 16:19:22 Train Epoch: 14 [400/477], Current Loss: 8.807e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0103, Train time: 6.2217, Iter time: 6.2320
+11/05 16:23:26 Train Epoch: 14 [440/477], Current Loss: 8.805e-01 Pos: 0.391 Neg: 0.489	Data time: 0.0098, Train time: 6.0781, Iter time: 6.0879
+11/05 16:27:08 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 16:27:08 Resetting the data loader seed to 0
+11/05 16:30:33 Validation iter 101 / 400 : Data Loading Time: 0.035, Feature Extraction Time: 0.884, Matching Time: 1.091, Loss: 0.980, RTE: 173.041, RRE: 0.702, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 16:33:50 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.886, Matching Time: 1.078, Loss: 0.987, RTE: 181.814, RRE: 0.723, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 16:37:10 Validation iter 301 / 400 : Data Loading Time: 0.009, Feature Extraction Time: 0.879, Matching Time: 1.087, Loss: 0.990, RTE: 170.067, RRE: 0.681, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 16:40:19 Final Loss: 0.992, RTE: 172.631, RRE: 0.692, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 16:40:19 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/05 16:40:19  Epoch: 15, LR: [0.08687458127689783]
+11/05 16:40:41 Train Epoch: 15 [0/477], Current Loss: 8.806e-01 Pos: 0.391 Neg: 0.490	Data time: 14.5528, Train time: 6.9915, Iter time: 21.5443
+11/05 16:45:01 Train Epoch: 15 [40/477], Current Loss: 8.814e-01 Pos: 0.380 Neg: 0.501	Data time: 0.0386, Train time: 6.4623, Iter time: 6.5009
+11/05 16:49:29 Train Epoch: 15 [80/477], Current Loss: 8.814e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0090, Train time: 6.6780, Iter time: 6.6869
+11/05 16:53:34 Train Epoch: 15 [120/477], Current Loss: 8.808e-01 Pos: 0.386 Neg: 0.494	Data time: 0.0066, Train time: 6.1348, Iter time: 6.1414
+11/05 16:57:43 Train Epoch: 15 [160/477], Current Loss: 8.808e-01 Pos: 0.390 Neg: 0.490	Data time: 0.0068, Train time: 6.2025, Iter time: 6.2093
+11/05 17:01:50 Train Epoch: 15 [200/477], Current Loss: 8.817e-01 Pos: 0.391 Neg: 0.491	Data time: 0.0079, Train time: 6.1628, Iter time: 6.1707
+11/05 17:05:53 Train Epoch: 15 [240/477], Current Loss: 8.807e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0077, Train time: 6.0786, Iter time: 6.0863
+11/05 17:10:02 Train Epoch: 15 [280/477], Current Loss: 8.805e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0082, Train time: 6.2104, Iter time: 6.2187
+11/05 17:14:11 Train Epoch: 15 [320/477], Current Loss: 8.805e-01 Pos: 0.390 Neg: 0.490	Data time: 0.0088, Train time: 6.2246, Iter time: 6.2333
+11/05 17:18:46 Train Epoch: 15 [360/477], Current Loss: 8.811e-01 Pos: 0.388 Neg: 0.493	Data time: 0.0114, Train time: 6.8660, Iter time: 6.8773
+11/05 17:22:56 Train Epoch: 15 [400/477], Current Loss: 8.807e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0086, Train time: 6.2241, Iter time: 6.2326
+11/05 17:27:07 Train Epoch: 15 [440/477], Current Loss: 8.804e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0098, Train time: 6.2629, Iter time: 6.2728
+11/05 17:30:46 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 17:30:46 Resetting the data loader seed to 0
+11/05 17:34:09 Validation iter 101 / 400 : Data Loading Time: 0.039, Feature Extraction Time: 0.895, Matching Time: 1.059, Loss: 0.986, RTE: 185.579, RRE: 0.698, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 17:37:26 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.883, Matching Time: 1.069, Loss: 0.991, RTE: 178.818, RRE: 0.689, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 17:40:45 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.884, Matching Time: 1.073, Loss: 0.993, RTE: 174.277, RRE: 0.686, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 17:43:58 Final Loss: 0.990, RTE: 171.153, RRE: 0.682, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 17:43:58 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/05 17:43:58  Epoch: 16, LR: [0.08600583546412885]
+11/05 17:44:17 Train Epoch: 16 [0/477], Current Loss: 8.806e-01 Pos: 0.388 Neg: 0.493	Data time: 11.5923, Train time: 6.7251, Iter time: 18.3174
+11/05 17:48:25 Train Epoch: 16 [40/477], Current Loss: 8.804e-01 Pos: 0.392 Neg: 0.488	Data time: 0.0337, Train time: 6.1560, Iter time: 6.1897
+11/05 17:53:05 Train Epoch: 16 [80/477], Current Loss: 8.807e-01 Pos: 0.394 Neg: 0.487	Data time: 0.0091, Train time: 7.0046, Iter time: 7.0137
+11/05 17:57:15 Train Epoch: 16 [120/477], Current Loss: 8.804e-01 Pos: 0.391 Neg: 0.489	Data time: 0.0067, Train time: 6.2495, Iter time: 6.2563
+11/05 18:01:21 Train Epoch: 16 [160/477], Current Loss: 8.806e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0070, Train time: 6.1339, Iter time: 6.1409
+11/05 18:05:34 Train Epoch: 16 [200/477], Current Loss: 8.805e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0070, Train time: 6.3090, Iter time: 6.3160
+11/05 18:09:46 Train Epoch: 16 [240/477], Current Loss: 1.393e+00 Pos: 0.393 Neg: 1.001	Data time: 0.0076, Train time: 6.2964, Iter time: 6.3040
+11/05 18:13:51 Train Epoch: 16 [280/477], Current Loss: 8.888e-01 Pos: 0.403 Neg: 0.486	Data time: 0.0080, Train time: 6.1168, Iter time: 6.1248
+11/05 18:17:58 Train Epoch: 16 [320/477], Current Loss: 1.271e+00 Pos: 0.545 Neg: 0.726	Data time: 0.0095, Train time: 6.1774, Iter time: 6.1869
+11/05 18:22:41 Train Epoch: 16 [360/477], Current Loss: 8.975e-01 Pos: 0.359 Neg: 0.539	Data time: 0.0127, Train time: 7.0547, Iter time: 7.0675
+11/05 18:26:52 Train Epoch: 16 [400/477], Current Loss: 8.897e-01 Pos: 0.387 Neg: 0.502	Data time: 0.0097, Train time: 6.2506, Iter time: 6.2603
+11/05 18:30:55 Train Epoch: 16 [440/477], Current Loss: 8.837e-01 Pos: 0.393 Neg: 0.491	Data time: 0.0099, Train time: 6.0774, Iter time: 6.0873
+11/05 18:34:31 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 18:34:31 Resetting the data loader seed to 0
+11/05 18:37:57 Validation iter 101 / 400 : Data Loading Time: 0.035, Feature Extraction Time: 0.880, Matching Time: 1.103, Loss: 0.991, RTE: 172.263, RRE: 0.687, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 18:41:08 Validation iter 201 / 400 : Data Loading Time: 0.007, Feature Extraction Time: 0.879, Matching Time: 1.061, Loss: 0.992, RTE: 169.601, RRE: 0.696, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 18:44:16 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.872, Matching Time: 1.041, Loss: 0.990, RTE: 176.322, RRE: 0.706, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 18:47:28 Final Loss: 0.989, RTE: 179.219, RRE: 0.720, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 18:47:28 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/05 18:47:28  Epoch: 17, LR: [0.08514577710948756]
+11/05 18:47:47 Train Epoch: 17 [0/477], Current Loss: 8.860e-01 Pos: 0.392 Neg: 0.494	Data time: 11.9883, Train time: 7.0213, Iter time: 19.0096
+11/05 18:51:57 Train Epoch: 17 [40/477], Current Loss: 8.967e-01 Pos: 0.439 Neg: 0.458	Data time: 0.0358, Train time: 6.2052, Iter time: 6.2411
+11/05 18:56:30 Train Epoch: 17 [80/477], Current Loss: 8.844e-01 Pos: 0.392 Neg: 0.492	Data time: 0.0087, Train time: 6.8224, Iter time: 6.8311
+11/05 19:00:38 Train Epoch: 17 [120/477], Current Loss: 8.831e-01 Pos: 0.389 Neg: 0.494	Data time: 0.0068, Train time: 6.1771, Iter time: 6.1839
+11/05 19:04:46 Train Epoch: 17 [160/477], Current Loss: 8.819e-01 Pos: 0.397 Neg: 0.485	Data time: 0.0074, Train time: 6.1937, Iter time: 6.2011
+11/05 19:08:53 Train Epoch: 17 [200/477], Current Loss: 8.817e-01 Pos: 0.397 Neg: 0.484	Data time: 0.0071, Train time: 6.1762, Iter time: 6.1833
+11/05 19:13:05 Train Epoch: 17 [240/477], Current Loss: 8.833e-01 Pos: 0.396 Neg: 0.488	Data time: 0.0081, Train time: 6.2972, Iter time: 6.3053
+11/05 19:17:14 Train Epoch: 17 [280/477], Current Loss: 8.841e-01 Pos: 0.394 Neg: 0.490	Data time: 0.0085, Train time: 6.2130, Iter time: 6.2215
+11/05 19:21:25 Train Epoch: 17 [320/477], Current Loss: 8.862e-01 Pos: 0.400 Neg: 0.486	Data time: 0.0090, Train time: 6.2516, Iter time: 6.2606
+11/05 19:26:13 Train Epoch: 17 [360/477], Current Loss: 8.836e-01 Pos: 0.386 Neg: 0.497	Data time: 0.0109, Train time: 7.1955, Iter time: 7.2064
+11/05 19:30:42 Train Epoch: 17 [400/477], Current Loss: 8.824e-01 Pos: 0.386 Neg: 0.496	Data time: 0.0123, Train time: 6.7216, Iter time: 6.7339
+11/05 19:34:51 Train Epoch: 17 [440/477], Current Loss: 8.825e-01 Pos: 0.389 Neg: 0.493	Data time: 0.0106, Train time: 6.1990, Iter time: 6.2096
+11/05 19:38:28 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 19:38:29 Resetting the data loader seed to 0
+11/05 19:41:46 Validation iter 101 / 400 : Data Loading Time: 0.024, Feature Extraction Time: 0.881, Matching Time: 1.035, Loss: 0.986, RTE: 189.535, RRE: 0.665, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 19:45:06 Validation iter 201 / 400 : Data Loading Time: 0.009, Feature Extraction Time: 0.893, Matching Time: 1.055, Loss: 0.983, RTE: 182.189, RRE: 0.706, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 19:48:31 Validation iter 301 / 400 : Data Loading Time: 0.009, Feature Extraction Time: 0.900, Matching Time: 1.073, Loss: 0.987, RTE: 176.192, RRE: 0.707, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 19:51:44 Final Loss: 0.986, RTE: 172.314, RRE: 0.690, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 19:51:44 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/05 19:51:44  Epoch: 18, LR: [0.08429431933839268]
+11/05 19:52:07 Train Epoch: 18 [0/477], Current Loss: 8.817e-01 Pos: 0.391 Neg: 0.491	Data time: 13.8892, Train time: 8.1406, Iter time: 22.0298
+11/05 19:56:17 Train Epoch: 18 [40/477], Current Loss: 8.816e-01 Pos: 0.393 Neg: 0.488	Data time: 0.0157, Train time: 6.2321, Iter time: 6.2478
+11/05 20:00:57 Train Epoch: 18 [80/477], Current Loss: 8.962e-01 Pos: 0.407 Neg: 0.489	Data time: 0.0084, Train time: 6.9832, Iter time: 6.9916
+11/05 20:05:09 Train Epoch: 18 [120/477], Current Loss: 8.827e-01 Pos: 0.394 Neg: 0.489	Data time: 0.0072, Train time: 6.3050, Iter time: 6.3123
+11/05 20:09:18 Train Epoch: 18 [160/477], Current Loss: 8.842e-01 Pos: 0.398 Neg: 0.486	Data time: 0.0080, Train time: 6.2072, Iter time: 6.2153
+11/05 20:13:26 Train Epoch: 18 [200/477], Current Loss: 8.822e-01 Pos: 0.395 Neg: 0.488	Data time: 0.0076, Train time: 6.2102, Iter time: 6.2178
+11/05 20:17:32 Train Epoch: 18 [240/477], Current Loss: 8.840e-01 Pos: 0.395 Neg: 0.489	Data time: 0.0074, Train time: 6.1234, Iter time: 6.1308
+11/05 20:21:39 Train Epoch: 18 [280/477], Current Loss: 8.824e-01 Pos: 0.397 Neg: 0.485	Data time: 0.0085, Train time: 6.1657, Iter time: 6.1742
+11/05 20:25:43 Train Epoch: 18 [320/477], Current Loss: 8.818e-01 Pos: 0.389 Neg: 0.493	Data time: 0.0085, Train time: 6.0892, Iter time: 6.0977
+11/05 20:29:57 Train Epoch: 18 [360/477], Current Loss: 8.813e-01 Pos: 0.389 Neg: 0.492	Data time: 0.0096, Train time: 6.3475, Iter time: 6.3572
+11/05 20:34:24 Train Epoch: 18 [400/477], Current Loss: 8.927e-01 Pos: 0.365 Neg: 0.528	Data time: 0.0111, Train time: 6.6555, Iter time: 6.6665
+11/05 20:38:36 Train Epoch: 18 [440/477], Current Loss: 8.824e-01 Pos: 0.383 Neg: 0.500	Data time: 0.0094, Train time: 6.3034, Iter time: 6.3127
+11/05 20:42:15 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 20:42:15 Resetting the data loader seed to 0
+11/05 20:45:34 Validation iter 101 / 400 : Data Loading Time: 0.034, Feature Extraction Time: 0.883, Matching Time: 1.040, Loss: 0.991, RTE: 178.940, RRE: 0.727, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 20:48:51 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.881, Matching Time: 1.052, Loss: 0.986, RTE: 169.034, RRE: 0.685, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 20:52:06 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.882, Matching Time: 1.051, Loss: 0.989, RTE: 170.078, RRE: 0.695, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 20:55:13 Final Loss: 0.986, RTE: 172.015, RRE: 0.696, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 20:55:13 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/05 20:55:13  Epoch: 19, LR: [0.08345137614500875]
+11/05 20:55:35 Train Epoch: 19 [0/477], Current Loss: 8.812e-01 Pos: 0.390 Neg: 0.491	Data time: 13.9650, Train time: 7.6797, Iter time: 21.6447
+11/05 20:59:45 Train Epoch: 19 [40/477], Current Loss: 8.852e-01 Pos: 0.397 Neg: 0.488	Data time: 0.0086, Train time: 6.2358, Iter time: 6.2444
+11/05 21:04:19 Train Epoch: 19 [80/477], Current Loss: 8.829e-01 Pos: 0.394 Neg: 0.489	Data time: 0.0080, Train time: 6.8406, Iter time: 6.8487
+11/05 21:08:34 Train Epoch: 19 [120/477], Current Loss: 8.820e-01 Pos: 0.401 Neg: 0.481	Data time: 0.0078, Train time: 6.3755, Iter time: 6.3833
+11/05 21:12:41 Train Epoch: 19 [160/477], Current Loss: 8.818e-01 Pos: 0.388 Neg: 0.494	Data time: 0.0071, Train time: 6.1553, Iter time: 6.1625
+11/05 21:16:56 Train Epoch: 19 [200/477], Current Loss: 8.829e-01 Pos: 0.398 Neg: 0.484	Data time: 0.0079, Train time: 6.3762, Iter time: 6.3841
+11/05 21:21:05 Train Epoch: 19 [240/477], Current Loss: 8.822e-01 Pos: 0.391 Neg: 0.491	Data time: 0.0079, Train time: 6.2287, Iter time: 6.2366
+11/05 21:25:18 Train Epoch: 19 [280/477], Current Loss: 8.814e-01 Pos: 0.394 Neg: 0.487	Data time: 0.0089, Train time: 6.3054, Iter time: 6.3143
+11/05 21:29:23 Train Epoch: 19 [320/477], Current Loss: 8.811e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0093, Train time: 6.1095, Iter time: 6.1188
+11/05 21:33:33 Train Epoch: 19 [360/477], Current Loss: 8.815e-01 Pos: 0.395 Neg: 0.486	Data time: 0.0087, Train time: 6.2417, Iter time: 6.2504
+11/05 21:38:16 Train Epoch: 19 [400/477], Current Loss: 8.814e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0146, Train time: 7.0631, Iter time: 7.0776
+11/05 21:42:28 Train Epoch: 19 [440/477], Current Loss: 8.818e-01 Pos: 0.396 Neg: 0.486	Data time: 0.0094, Train time: 6.2943, Iter time: 6.3037
+11/05 21:46:03 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 21:46:03 Resetting the data loader seed to 0
+11/05 21:49:28 Validation iter 101 / 400 : Data Loading Time: 0.029, Feature Extraction Time: 0.894, Matching Time: 1.089, Loss: 0.986, RTE: 157.035, RRE: 0.656, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 21:52:45 Validation iter 201 / 400 : Data Loading Time: 0.009, Feature Extraction Time: 0.884, Matching Time: 1.084, Loss: 0.991, RTE: 169.585, RRE: 0.709, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 21:55:59 Validation iter 301 / 400 : Data Loading Time: 0.007, Feature Extraction Time: 0.879, Matching Time: 1.072, Loss: 0.991, RTE: 168.789, RRE: 0.699, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 21:59:10 Final Loss: 0.991, RTE: 171.897, RRE: 0.701, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 21:59:10 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/05 21:59:10  Epoch: 20, LR: [0.08261686238355867]
+11/05 21:59:30 Train Epoch: 20 [0/477], Current Loss: 8.807e-01 Pos: 0.391 Neg: 0.490	Data time: 12.7646, Train time: 7.1392, Iter time: 19.9038
+11/05 22:03:49 Train Epoch: 20 [40/477], Current Loss: 8.821e-01 Pos: 0.374 Neg: 0.508	Data time: 0.0290, Train time: 6.4363, Iter time: 6.4653
+11/05 22:08:29 Train Epoch: 20 [80/477], Current Loss: 8.821e-01 Pos: 0.393 Neg: 0.489	Data time: 0.0106, Train time: 6.9926, Iter time: 7.0031
+11/05 22:12:50 Train Epoch: 20 [120/477], Current Loss: 8.820e-01 Pos: 0.391 Neg: 0.491	Data time: 0.0080, Train time: 6.5280, Iter time: 6.5360
+11/05 22:17:05 Train Epoch: 20 [160/477], Current Loss: 8.811e-01 Pos: 0.397 Neg: 0.485	Data time: 0.0082, Train time: 6.3514, Iter time: 6.3595
+11/05 22:21:14 Train Epoch: 20 [200/477], Current Loss: 8.809e-01 Pos: 0.395 Neg: 0.485	Data time: 0.0074, Train time: 6.2189, Iter time: 6.2263
+11/05 22:25:23 Train Epoch: 20 [240/477], Current Loss: 8.812e-01 Pos: 0.388 Neg: 0.493	Data time: 0.0079, Train time: 6.2254, Iter time: 6.2334
+11/05 22:29:35 Train Epoch: 20 [280/477], Current Loss: 8.810e-01 Pos: 0.393 Neg: 0.488	Data time: 0.0083, Train time: 6.2787, Iter time: 6.2870
+11/05 22:33:40 Train Epoch: 20 [320/477], Current Loss: 8.813e-01 Pos: 0.389 Neg: 0.492	Data time: 0.0089, Train time: 6.1134, Iter time: 6.1224
+11/05 22:37:49 Train Epoch: 20 [360/477], Current Loss: 8.810e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0089, Train time: 6.2243, Iter time: 6.2332
+11/05 22:42:28 Train Epoch: 20 [400/477], Current Loss: 8.809e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0125, Train time: 6.9739, Iter time: 6.9864
+11/05 22:46:38 Train Epoch: 20 [440/477], Current Loss: 8.810e-01 Pos: 0.386 Neg: 0.495	Data time: 0.0106, Train time: 6.2172, Iter time: 6.2278
+11/05 22:50:18 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 22:50:18 Resetting the data loader seed to 0
+11/05 22:53:44 Validation iter 101 / 400 : Data Loading Time: 0.026, Feature Extraction Time: 0.897, Matching Time: 1.099, Loss: 0.989, RTE: 172.914, RRE: 0.722, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 22:56:59 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.886, Matching Time: 1.080, Loss: 0.992, RTE: 172.737, RRE: 0.736, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 23:00:18 Validation iter 301 / 400 : Data Loading Time: 0.007, Feature Extraction Time: 0.886, Matching Time: 1.079, Loss: 0.993, RTE: 174.549, RRE: 0.727, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 23:03:32 Final Loss: 0.993, RTE: 173.920, RRE: 0.710, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/05 23:03:32 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/05 23:03:32  Epoch: 21, LR: [0.08179069375972309]
+11/05 23:03:53 Train Epoch: 21 [0/477], Current Loss: 8.807e-01 Pos: 0.390 Neg: 0.491	Data time: 12.9640, Train time: 7.2016, Iter time: 20.1656
+11/05 23:08:09 Train Epoch: 21 [40/477], Current Loss: 8.810e-01 Pos: 0.388 Neg: 0.493	Data time: 0.0089, Train time: 6.3973, Iter time: 6.4062
+11/05 23:12:20 Train Epoch: 21 [80/477], Current Loss: 8.808e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0072, Train time: 6.2752, Iter time: 6.2824
+11/05 23:16:43 Train Epoch: 21 [120/477], Current Loss: 8.821e-01 Pos: 0.399 Neg: 0.483	Data time: 0.0093, Train time: 6.5591, Iter time: 6.5683
+11/05 23:20:49 Train Epoch: 21 [160/477], Current Loss: 8.810e-01 Pos: 0.387 Neg: 0.495	Data time: 0.0068, Train time: 6.1541, Iter time: 6.1609
+11/05 23:25:02 Train Epoch: 21 [200/477], Current Loss: 8.806e-01 Pos: 0.391 Neg: 0.490	Data time: 0.0080, Train time: 6.3062, Iter time: 6.3142
+11/05 23:29:09 Train Epoch: 21 [240/477], Current Loss: 8.806e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0076, Train time: 6.1617, Iter time: 6.1693
+11/05 23:33:22 Train Epoch: 21 [280/477], Current Loss: 8.812e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0075, Train time: 6.3244, Iter time: 6.3319
+11/05 23:37:29 Train Epoch: 21 [320/477], Current Loss: 8.809e-01 Pos: 0.386 Neg: 0.495	Data time: 0.0090, Train time: 6.1504, Iter time: 6.1594
+11/05 23:41:38 Train Epoch: 21 [360/477], Current Loss: 8.812e-01 Pos: 0.389 Neg: 0.492	Data time: 0.0090, Train time: 6.2209, Iter time: 6.2299
+11/05 23:46:14 Train Epoch: 21 [400/477], Current Loss: 8.811e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0123, Train time: 6.8822, Iter time: 6.8945
+11/05 23:50:28 Train Epoch: 21 [440/477], Current Loss: 8.809e-01 Pos: 0.389 Neg: 0.492	Data time: 0.0092, Train time: 6.3401, Iter time: 6.3493
+11/05 23:54:08 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/05 23:54:08 Resetting the data loader seed to 0
+11/05 23:57:40 Validation iter 101 / 400 : Data Loading Time: 0.036, Feature Extraction Time: 0.891, Matching Time: 1.154, Loss: 0.988, RTE: 182.233, RRE: 0.728, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/06 00:00:58 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.896, Matching Time: 1.104, Loss: 0.989, RTE: 176.370, RRE: 0.713, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/06 00:04:17 Validation iter 301 / 400 : Data Loading Time: 0.009, Feature Extraction Time: 0.889, Matching Time: 1.099, Loss: 0.990, RTE: 176.065, RRE: 0.711, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/06 00:07:29 Final Loss: 0.990, RTE: 172.262, RRE: 0.701, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/06 00:07:30 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/06 00:07:30  Epoch: 22, LR: [0.08097278682212584]
+11/06 00:07:51 Train Epoch: 22 [0/477], Current Loss: 8.807e-01 Pos: 0.395 Neg: 0.485	Data time: 13.6884, Train time: 6.9648, Iter time: 20.6532
+11/06 00:11:56 Train Epoch: 22 [40/477], Current Loss: 8.807e-01 Pos: 0.393 Neg: 0.488	Data time: 0.0238, Train time: 6.1223, Iter time: 6.1462
+11/06 00:16:04 Train Epoch: 22 [80/477], Current Loss: 8.809e-01 Pos: 0.393 Neg: 0.488	Data time: 0.0068, Train time: 6.1838, Iter time: 6.1906
+11/06 00:20:39 Train Epoch: 22 [120/477], Current Loss: 8.812e-01 Pos: 0.387 Neg: 0.494	Data time: 0.0093, Train time: 6.8556, Iter time: 6.8649
+11/06 00:24:43 Train Epoch: 22 [160/477], Current Loss: 8.804e-01 Pos: 0.392 Neg: 0.488	Data time: 0.0070, Train time: 6.0919, Iter time: 6.0990
+11/06 00:28:52 Train Epoch: 22 [200/477], Current Loss: 8.812e-01 Pos: 0.385 Neg: 0.497	Data time: 0.0068, Train time: 6.2237, Iter time: 6.2305
+11/06 00:33:07 Train Epoch: 22 [240/477], Current Loss: 8.810e-01 Pos: 0.392 Neg: 0.489	Data time: 0.0086, Train time: 6.3664, Iter time: 6.3750
+11/06 00:37:11 Train Epoch: 22 [280/477], Current Loss: 8.807e-01 Pos: 0.395 Neg: 0.486	Data time: 0.0079, Train time: 6.0843, Iter time: 6.0922
+11/06 00:41:24 Train Epoch: 22 [320/477], Current Loss: 8.806e-01 Pos: 0.392 Neg: 0.488	Data time: 0.0086, Train time: 6.3354, Iter time: 6.3440
+11/06 00:45:29 Train Epoch: 22 [360/477], Current Loss: 8.812e-01 Pos: 0.392 Neg: 0.490	Data time: 0.0086, Train time: 6.1161, Iter time: 6.1247
+11/06 00:50:06 Train Epoch: 22 [400/477], Current Loss: 8.805e-01 Pos: 0.388 Neg: 0.492	Data time: 0.0123, Train time: 6.9074, Iter time: 6.9198
+11/06 00:54:19 Train Epoch: 22 [440/477], Current Loss: 8.805e-01 Pos: 0.392 Neg: 0.488	Data time: 0.0098, Train time: 6.2948, Iter time: 6.3046
+11/06 00:57:58 Saving checkpoint: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-05_01-31-22/checkpoint.pth ...
+11/06 00:57:58 Resetting the data loader seed to 0
+11/06 01:01:16 Validation iter 101 / 400 : Data Loading Time: 0.028, Feature Extraction Time: 0.863, Matching Time: 1.057, Loss: 0.994, RTE: 172.051, RRE: 0.671, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/06 01:04:33 Validation iter 201 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.873, Matching Time: 1.059, Loss: 0.991, RTE: 172.346, RRE: 0.695, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/06 01:07:48 Validation iter 301 / 400 : Data Loading Time: 0.008, Feature Extraction Time: 0.875, Matching Time: 1.058, Loss: 0.989, RTE: 168.390, RRE: 0.696, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/06 01:10:57 Final Loss: 0.990, RTE: 173.591, RRE: 0.705, Hit Ratio: 0.001, Feat Match Ratio: 0.000
+11/06 01:10:57 Current best val model with feat_match_ratio: 0.0 at epoch 1
+11/06 01:10:57  Epoch: 23, LR: [0.08016305895390459]
+11/06 01:11:19 Train Epoch: 23 [0/477], Current Loss: 8.804e-01 Pos: 0.393 Neg: 0.488	Data time: 14.3961, Train time: 7.7215, Iter time: 22.1176
+11/06 01:15:48 Train Epoch: 23 [40/477], Current Loss: 8.808e-01 Pos: 0.383 Neg: 0.497	Data time: 0.0155, Train time: 6.6908, Iter time: 6.7063
+11/06 01:20:00 Train Epoch: 23 [80/477], Current Loss: 8.806e-01 Pos: 0.394 Neg: 0.487	Data time: 0.0074, Train time: 6.3064, Iter time: 6.3138
+11/06 01:24:44 Train Epoch: 23 [120/477], Current Loss: 8.808e-01 Pos: 0.389 Neg: 0.492	Data time: 0.0091, Train time: 7.0951, Iter time: 7.1042
+11/06 01:28:52 Train Epoch: 23 [160/477], Current Loss: 8.809e-01 Pos: 0.396 Neg: 0.485	Data time: 0.0069, Train time: 6.1689, Iter time: 6.1759
+11/06 01:33:17 Train Epoch: 23 [200/477], Current Loss: 8.809e-01 Pos: 0.394 Neg: 0.487	Data time: 0.0079, Train time: 6.6209, Iter time: 6.6289
+11/06 01:37:29 Train Epoch: 23 [240/477], Current Loss: 8.803e-01 Pos: 0.390 Neg: 0.490	Data time: 0.0082, Train time: 6.2939, Iter time: 6.3021
+11/06 01:41:51 Train Epoch: 23 [280/477], Current Loss: 8.806e-01 Pos: 0.388 Neg: 0.493	Data time: 0.0102, Train time: 6.5529, Iter time: 6.5631
+11/06 01:46:15 Train Epoch: 23 [320/477], Current Loss: 8.804e-01 Pos: 0.390 Neg: 0.491	Data time: 0.0097, Train time: 6.5701, Iter time: 6.5798
+./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16--gtremoval2/2020-11-06_01-47-05
 Host:  bb8
 Conda  /home/allie/miniconda3/condabin/conda
 /home/allie/code/benchmark/FCGF
-Version:  f0863a9ba4a29f677c0ddd2248cf4e56b9318add
+Version:  5002ea8a5a10230c9c771aa8ac7991fcc03b0502
 Git diff
 
 diff --git a/config.py b/config.py
-index 476402d..6c9fb68 100644
+index 6c9fb68..9e1ccb9 100644
 --- a/config.py
 +++ b/config.py
-@@ -94,9 +94,9 @@ misc_arg.add_argument('--weights', type=str, default=None)
+@@ -90,7 +90,7 @@ opt_arg.add_argument(
+ 
+ misc_arg = add_argument_group('Misc')
+ misc_arg.add_argument('--use_gpu', type=str2bool, default=True)
+-misc_arg.add_argument('--weights', type=str, default=None)
++misc_arg.add_argument('--weights', type=str, default="")
  misc_arg.add_argument('--weights_dir', type=str, default=None)
  misc_arg.add_argument('--resume', type=str, default=None)
  misc_arg.add_argument('--resume_dir', type=str, default=None)
--misc_arg.add_argument('--train_num_thread', type=int, default=2)
--misc_arg.add_argument('--val_num_thread', type=int, default=1)
--misc_arg.add_argument('--test_num_thread', type=int, default=2)
-+misc_arg.add_argument('--train_num_thread', type=int, default=8)#2)
-+misc_arg.add_argument('--val_num_thread', type=int, default=8)
-+misc_arg.add_argument('--test_num_thread', type=int, default=8)#2)
- misc_arg.add_argument('--fast_validation', type=str2bool, default=False)
- misc_arg.add_argument(
-     '--nn_max_n',
-@@ -112,14 +112,28 @@ data_arg.add_argument(
-     '--threed_match_dir', type=str, default="/home/chrischoy/datasets/FCGF/threedmatch")
- data_arg.add_argument(
-     '--kitti_root', type=str, default="/home/chrischoy/datasets/FCGF/kitti/")
-+
- data_arg.add_argument(
-     '--kitti_max_time_diff',
-     type=int,
-     default=3,
-     help='max time difference between pairs (non inclusive)')
-+
- data_arg.add_argument('--kitti_date', type=str, default='2011_09_26')
- 
- 
-+#arguments for KITTI map dataset
-+#for kitti ground truth poses (optimized by loop-closing SLAM)
-+data_arg.add_argument(
-+    '--path_cmrdata', type=str, default="/home/allie/dataset/cmr_original") 
-+data_arg.add_argument(
-+    '--depth_max', type=float, default=50) 
-+data_arg.add_argument(
-+    '--num_min_map_points', type=int, default=2e4) 
-+
-+
-+
-+
- def get_config():
-   args = parser.parse_args()
-   return args
 diff --git a/lib/data_loaders.py b/lib/data_loaders.py
-index 2bc475a..e0e264d 100644
+index e0e264d..fe07a78 100644
 --- a/lib/data_loaders.py
 +++ b/lib/data_loaders.py
-@@ -18,10 +18,42 @@ import lib.transforms as t
- import MinkowskiEngine as ME
- 
- import open3d as o3d
-+import pickle
- 
- kitti_cache = {}
- kitti_icp_cache = {}
- 
-+eps = 1e-10
-+import csv
-+def read_csv_file(path_file):
-+    lines = []
-+    with open(path_file, "r") as f:
-+        reader = csv.reader(f, delimiter="\t")
-+        for i, line in enumerate(reader):
-+            if i >= 1:
-+                lines.append(np.asarray(line[0].split(',')[1:]).astype('float'))
-+    return lines
-+
-+
-+def pred_to_matrix_np(pred):
-+
-+    cam_T = np.tile(np.eye(4)[np.newaxis,:,:],[pred.shape[0], 1, 1])
-+    cam_T[:,0:3, 3] = pred[:, 0:3]
-+    s = np.tile(np.linalg.norm(pred[:,3:], axis=1)[:,np.newaxis],[1,4])
-+
-+    q = pred[:,3:] / (s+eps)
-+
-+    cam_T[:,0,0] = 1- 2*s[:,0]*(q[:,2]**2 + q[:,3]**2)
-+    cam_T[:,0,1] = 2   *s[:,0]*(q[:,1] * q[:,2] - q[:,3] * q[:,0])
-+    cam_T[:,0,2] = 2   *s[:,0]*(q[:,1] * q[:,3] + q[:,2] * q[:,0])
-+    cam_T[:,1,0] = 2   *s[:,0]*(q[:,1]*q[:,2] + q[:,3]*q[:,0])
-+    cam_T[:,1,1] = 1- 2*s[:,0]*(q[:,1]**2 + q[:,3]**2)
-+    cam_T[:,1,2] = 2   *s[:,0]*(q[:,2] * q[:,3] - q[:,1] * q[:,0])
-+    cam_T[:,2,0] = 2   *s[:,0]*(q[:,1] * q[:,3] - q[:,2] * q[:,0])
-+    cam_T[:,2,1] = 2   *s[:,0]*(q[:,2] * q[:,3] + q[:,1] * q[:,0])
-+    cam_T[:,2,2] = 1 -2*s[:,0]*(q[:,1]**2 + q[:,2]**2)
+@@ -692,7 +692,7 @@ class KITTIMapDataset(PairDataset):
+         self.split = phase
+         self.config = config
+ 
+-        self.path_map_dict = os.path.join(root, "kitti_map_files_d3feat_%s.pkl" % self.split)
++        self.path_map_dict = os.path.join(root, "kitti_map_files_d3feat_%s_fcgf.pkl" % self.split)
+         self.read_map_data()
+         self.prepare_kitti_ply()#split=split)
+        
+@@ -712,10 +712,10 @@ class KITTIMapDataset(PairDataset):
+         for id_log in subset_names:
+             path_map = os.path.join(self.root, "kitti_maps_cmr_new", "map-%02d_0.05.ply" % (int(id_log)))
+             print("Load map : ", path_map)
+-            pcd = open3d.io.read_point_cloud(path_map)
+-            pcd = pcd.voxel_down_sample(self.config.first_subsampling_dl)
+-            pcd, ind = pcd.remove_radius_outlier(nb_points=7, radius=self.config.first_subsampling_dl*2)
+-            self.dict_maps[id_log] = torch.Tensor(np.asarray(pcd.points))#.to(self.config.device)
++            pcd = o3d.io.read_point_cloud(path_map)
++            pcd = pcd.voxel_down_sample(self.config.voxel_size)
++            pcd, ind = pcd.remove_radius_outlier(nb_points=7, radius=self.config.voxel_size*2)
++            self.dict_maps[id_log] = np.asarray(pcd.points)#torch.Tensor(np.asarray(pcd.points))#.to(self.config.device)
+ 
+ 
+         with open(self.path_map_dict, 'wb') as f: 
+@@ -724,7 +724,7 @@ class KITTIMapDataset(PairDataset):
+             print('Saved!')    
+ 
+     def get_local_map(self,T_lidar, drive):#, force_select_points=False):
+-        dist = torch.sqrt(((self.dict_maps[drive] - T_lidar[0:3,3])**2).sum(axis=1))
++        dist = np.sqrt(((self.dict_maps[drive] - T_lidar[0:3,3])**2).sum(axis=1))
+         ind_valid_local = dist < self.config.depth_max
+ 
+         return self.dict_maps[drive][ind_valid_local]
+@@ -780,31 +780,47 @@ class KITTIMapDataset(PairDataset):
+             xyz1 = scale * xyz1
+ 
+         # Voxelization
+-        xyz0_th = xyz0#torch.from_numpy(xyz0)
++        xyz0_th = torch.from_numpy(xyz0)#xyz0#torch.from_numpy(xyz0)
+         xyz1_th = torch.from_numpy(xyz1)
+     
+         sel0 = ME.utils.sparse_quantize(xyz0_th / self.voxel_size, return_index=True)
+         sel1 = ME.utils.sparse_quantize(xyz1_th / self.voxel_size, return_index=True)
+     
+         # Make point clouds using voxelized points
+-        pcd0 = make_open3d_point_cloud(xyz0[sel0])
+-        pcd1 = make_open3d_point_cloud(xyz1[sel1])
++        #pcd0 = make_open3d_point_cloud(xyz0[sel0])
++        #pcd1 = make_open3d_point_cloud(xyz1[sel1])
++
++        import copy
++        pcd0_trans = make_open3d_point_cloud(xyz0[sel0])
++        pcd0_trans.transform(trans)
++        xyz0_sel_trans = np.asarray(pcd0_trans.points)
++        h_ground = -1.5
++        ind_0 = xyz0_sel_trans[:,2] > h_ground
++        ind_1 = xyz1[sel1][:,2] > h_ground
++
++        pcd0 = make_open3d_point_cloud(xyz0[sel0][ind_0])
++        pcd1 = make_open3d_point_cloud(xyz1[sel1][ind_1])
++    
++        #xyz0_th = torch.from_numpy(xyz0)#xyz0#torch.from_numpy(xyz0)
++        #xyz1_th = torch.from_numpy(xyz1)
+     
+         # Get matches
+         matches = get_matching_indices(pcd0, pcd1, trans, matching_search_voxel_size)
+-        #if len(matches) < 1000:
+-        #  raise ValueError(f"{drive}, {t0}, {t1}")
++        if len(matches) < 1000:
++            raise ValueError(f"{drive}, {idx}")
+         #matches = np.array(matches)
+ 
+ 
+         # Get features
+-        npts0 = len(sel0)
+-        npts1 = len(sel1)
+-    
++
+         feats_train0, feats_train1 = [], []
+     
+-        unique_xyz0_th = xyz0_th[sel0]
+-        unique_xyz1_th = xyz1_th[sel1]
++        unique_xyz0_th = xyz0_th[sel0][ind_0]
++        unique_xyz1_th = xyz1_th[sel1][ind_1]
++        npts0 = unique_xyz0_th.shape[0]
++        npts1 = unique_xyz1_th.shape[0]
++    
 +
-+    return cam_T
- 
- def collate_pair_fn(list_data):
-   xyz0, xyz1, coords0, coords1, feats0, feats1, matching_inds, trans = list(
-@@ -48,7 +80,6 @@ def collate_pair_fn(list_data):
-     xyz_batch1.append(to_tensor(xyz1[batch_id]))
- 
-     trans_batch.append(to_tensor(trans[batch_id]))
--
-     matching_inds_batch.append(
-         torch.from_numpy(np.array(matching_inds[batch_id]) + curr_start_inds))
-     len_batch.append([N0, N1])
-@@ -632,8 +663,231 @@ class ThreeDMatchPairDataset(IndoorPairDataset):
-       'test': './config/test_3dmatch.txt'
-   }
+     
+         feats_train0.append(torch.ones((npts0, 1)))
+         feats_train1.append(torch.ones((npts1, 1)))
+@@ -818,8 +834,9 @@ class KITTIMapDataset(PairDataset):
+         #print("single batch = ")
+         #print(coords0.shape)
+         #print(coords1.shape)
+-        #print(len(matches) )        
++           
+         if False:#len(matches) < 10:#coords0.shape[0] < 10 or coords1.shape[0] < 10:
++            print("num matches = ", len(matches) )     
+             #print("matches shape = ", matches.shape)
+ 
+             print(coords0)
+@@ -850,7 +867,7 @@ class KITTIMapDataset(PairDataset):
+             o3d.io.write_point_cloud("unique_xyz0_th_trans_%d.ply" % idx, pcd_target) 
+ #    
+ 
+-            #import pdb; pdb.set_trace()
++            import pdb; pdb.set_trace()
+             #pcd_target = o3d.geometry.PointCloud()
+             #pcd_target.points = o3d.utility.Vector3dVector(coords0)
+             #o3d.io.write_point_cloud("coords0.ply" , pcd_target) 
+diff --git a/lib/eval.py b/lib/eval.py
+index 4afa0ef..7ef9b67 100644
+--- a/lib/eval.py
++++ b/lib/eval.py
+@@ -17,6 +17,7 @@ def find_nn_cpu(feat0, feat1, return_distance=False):
+ 
+ def find_nn_gpu(F0, F1, nn_max_n=-1, return_distance=False, dist_type='SquareL2'):
+   # Too much memory if F0 or F1 large. Divide the F0
++
+   if nn_max_n > 1:
+     N = len(F0)
+     C = int(np.ceil(N / nn_max_n))
+diff --git a/lib/trainer.py b/lib/trainer.py
+index e6299f8..bd950bc 100644
+--- a/lib/trainer.py
++++ b/lib/trainer.py
+@@ -330,9 +330,62 @@ class ContrastiveLossTrainer(AlignmentTrainer):
+       F1 = self.model(sinput1).F
+       feat_timer.toc()
  
-+class KITTIMapDataset(PairDataset):
-+    AUGMENT = None
-+    DATA_FILES = {
-+        'train': './config/train_kitti_map.txt', #log ids
-+        'val': './config/val_kitti_map.txt',
-+        'test': './config/test_kitti_map.txt'
-+    }
-+    TEST_RANDOM_ROTATION = False
-+    IS_ODOMETRY = True
-+    #MAX_TIME_DIFF = 3
-+
-+    def __init__(self,
-+               phase,
-+               transform=None,
-+               random_rotation=True,
-+               random_scale=True,
-+               manual_seed=False,
-+               config=None):
-+
-+
-+    #(self, root, split, config, input_threads=8, first_subsampling_dl=0.30):#, load_test=False):
-+        
-+        PairDataset.__init__(self, phase, transform, random_rotation, random_scale,
-+                         manual_seed, config)
-+
-+        self.root = root = os.path.join(config.kitti_root, 'dataset')
-+        self.split = phase
-+        self.config = config
-+
-+        self.path_map_dict = os.path.join(root, "kitti_map_files_d3feat_%s.pkl" % self.split)
-+        self.read_map_data()
-+        self.prepare_kitti_ply()#split=split)
-+       
-+
-+    def __len__(self):
-+        return self.num
-+
-+    def read_map_data(self):
-+        if os.path.exists(self.path_map_dict):
-+            with open(self.path_map_dict, 'rb') as f:
-+                self.dict_maps = pickle.load(f)
-+            return 
-+
-+
-+        subset_names = open(self.DATA_FILES[self.split]).read().split()
-+        self.dict_maps = {}
-+        for id_log in subset_names:
-+            path_map = os.path.join(self.root, "kitti_maps_cmr_new", "map-%02d_0.05.ply" % (int(id_log)))
-+            print("Load map : ", path_map)
-+            pcd = open3d.io.read_point_cloud(path_map)
-+            pcd = pcd.voxel_down_sample(self.config.first_subsampling_dl)
-+            pcd, ind = pcd.remove_radius_outlier(nb_points=7, radius=self.config.first_subsampling_dl*2)
-+            self.dict_maps[id_log] = torch.Tensor(np.asarray(pcd.points))#.to(self.config.device)
-+
-+
-+        with open(self.path_map_dict, 'wb') as f: 
-+            print('Saving map file to ', self.path_map_dict)
-+            pickle.dump(self.dict_maps, f)
-+            print('Saved!')    
-+
-+    def get_local_map(self,T_lidar, drive):#, force_select_points=False):
-+        dist = torch.sqrt(((self.dict_maps[drive] - T_lidar[0:3,3])**2).sum(axis=1))
-+        ind_valid_local = dist < self.config.depth_max
-+
-+        return self.dict_maps[drive][ind_valid_local]
-+
-+            
-+    def prepare_kitti_ply(self):#, split='train'):
-+        #max_time_diff = self.MAX_TIME_DIFF
-+        subset_names = open(self.DATA_FILES[self.split]).read().split()
-+        self.all_pos = []
-+        for dirname in subset_names:
-+            drive_id = int(dirname)
-+            fnames = glob.glob(self.root + '/sequences/%02d/velodyne/*.bin' % drive_id)
-+
-+            assert len(fnames) > 0, f"Make sure that the path {self.root} has data {dirname}"
-+            inames = sorted([int(os.path.split(fname)[-1][:-4]) for fname in fnames])
-+            path_poses = os.path.join(self.config.path_cmrdata, self.split, "kitti-%02d.csv" % drive_id)
-+            list_gt_poses = read_csv_file(path_poses)
-+
-+            for i in range(0,len(inames),2):# curr_time in inames:
-+                
-+
-+                T = pred_to_matrix_np(np.asarray(list_gt_poses[i][np.newaxis,[0,1,2,6,3,4,5]]))[0]
-+                xyz0 = self.get_local_map(T, dirname)
-+
-+                #use the local map as the source
-+                T = np.linalg.inv(T) 
-+                if xyz0.shape[0] < self.config.num_min_map_points:
-+                    continue
-+                
-+                self.files.append((drive_id, inames[i]))#, next_time))
-+                self.all_pos.append( torch.Tensor(T))#.to(self.config.device))
-+        self.num = len(self.files)
++      #import pdb; pdb.set_trace()
++      if False:
 +
-+    def __getitem__(self,idx):# split, idx):
-+        drive = self.files[idx][0]
-+        #t0, t1 = self.files[self.split][idx][1], self.files[self.split][idx][2]
-+
-+        #LiDAR is the target
-+        fname1 = self._get_velodyne_fn(drive,  self.files[idx][1])
-+        xyzr1 = np.fromfile(fname1, dtype=np.float32).reshape(-1, 4) 
-+        xyz1 = xyzr1[:, :3]
-+        
-+        #map is the source
-+        xyz0 = self.get_local_map( np.linalg.inv(self.all_pos[idx]), str(drive))
-+        trans = self.all_pos[idx]# M2
-+
-+        matching_search_voxel_size = self.matching_search_voxel_size
-+        if self.random_scale and random.random() < 0.95:
-+            scale = self.min_scale + \
-+                (self.max_scale - self.min_scale) * random.random()
-+            matching_search_voxel_size *= scale
-+            xyz0 = scale * xyz0
-+            xyz1 = scale * xyz1
-+
-+        # Voxelization
-+        xyz0_th = xyz0#torch.from_numpy(xyz0)
-+        xyz1_th = torch.from_numpy(xyz1)
++          from sklearn.decomposition import PCA
++          import open3d as o3d
++          pc0 = o3d.geometry.PointCloud()
++          pc0.points = o3d.utility.Vector3dVector(xyz0.numpy())
++          pca = PCA(n_components=3)
 +    
-+        sel0 = ME.utils.sparse_quantize(xyz0_th / self.voxel_size, return_index=True)
-+        sel1 = ME.utils.sparse_quantize(xyz1_th / self.voxel_size, return_index=True)
++          colors =   pca.fit_transform(torch.cat((F0, F1), axis=0).cpu().numpy())
++          colors -= colors.min()
++          colors /= colors.max()
++          pc0.colors = o3d.utility.Vector3dVector(colors[0:F0.shape[0]])
 +    
-+        # Make point clouds using voxelized points
-+        pcd0 = make_open3d_point_cloud(xyz0[sel0])
-+        pcd1 = make_open3d_point_cloud(xyz1[sel1])
++          o3d.io.write_point_cloud("pc0.ply" , pc0) 
++          pc0.transform(T_gt.numpy())
++          o3d.io.write_point_cloud("pc0_trans.ply" , pc0) 
 +    
-+        # Get matches
-+        matches = get_matching_indices(pcd0, pcd1, trans, matching_search_voxel_size)
-+        #if len(matches) < 1000:
-+        #  raise ValueError(f"{drive}, {t0}, {t1}")
-+        #matches = np.array(matches)
++          pc1 = o3d.geometry.PointCloud()
++          pc1.points = o3d.utility.Vector3dVector(xyz1.numpy())
++          pc1.colors = o3d.utility.Vector3dVector(colors[F0.shape[0]:])
++          o3d.io.write_point_cloud("pc1.ply" , pc1) 
 +
 +
-+        # Get features
-+        npts0 = len(sel0)
-+        npts1 = len(sel1)
-+    
-+        feats_train0, feats_train1 = [], []
-+    
-+        unique_xyz0_th = xyz0_th[sel0]
-+        unique_xyz1_th = xyz1_th[sel1]
-+    
-+        feats_train0.append(torch.ones((npts0, 1)))
-+        feats_train1.append(torch.ones((npts1, 1)))
-+    
-+        feats0 = torch.cat(feats_train0, 1)
-+        feats1 = torch.cat(feats_train1, 1)
-+    
-+        coords0 = torch.floor(unique_xyz0_th / self.voxel_size)
-+        coords1 = torch.floor(unique_xyz1_th / self.voxel_size)
++          ind_0 = input_dict['correspondences'][:,0].type(torch.long)
++          ind_1 = input_dict['correspondences'][:,1].type(torch.long)
 +
-+        #print("single batch = ")
-+        #print(coords0.shape)
-+        #print(coords1.shape)
-+        #print(len(matches) )        
-+        if False:#len(matches) < 10:#coords0.shape[0] < 10 or coords1.shape[0] < 10:
-+            #print("matches shape = ", matches.shape)
++          pc1.points = o3d.utility.Vector3dVector(xyz1[ind_1].numpy())
++          pc1.colors = o3d.utility.Vector3dVector(colors[F0.shape[0]:][ind_1])
++          o3d.io.write_point_cloud("pc1_corr.ply" , pc1) 
 +
-+            print(coords0)
-+#    
-+#    
-+            pcd_target = o3d.geometry.PointCloud()
-+            pcd_target.points = o3d.utility.Vector3dVector(coords0)
-+            o3d.io.write_point_cloud("coords0_before_%d.ply" % idx , pcd_target) 
-+#    
-+            pcd_target = o3d.geometry.PointCloud()
-+            pcd_target.points = o3d.utility.Vector3dVector(coords1)
-+            o3d.io.write_point_cloud("coords1_before_%d.ply" % idx, pcd_target) 
-+#    
-+    
-+            pcd_target = o3d.geometry.PointCloud()
-+            pcd_target.points = o3d.utility.Vector3dVector(unique_xyz1_th)
-+            o3d.io.write_point_cloud("unique_xyz1_th_%d.ply"% idx , pcd_target) 
-+#    
-+    
-+            pcd_target = o3d.geometry.PointCloud()
-+            pcd_target.points = o3d.utility.Vector3dVector(unique_xyz0_th)
-+            o3d.io.write_point_cloud("unique_xyz0_th_%d.ply"% idx , pcd_target)         
-+#    
-+            pcd_target = o3d.geometry.PointCloud()
-+            pcd_target.points = o3d.utility.Vector3dVector(unique_xyz0_th)
-+            pcd_target.transform(trans)
-+    
-+            o3d.io.write_point_cloud("unique_xyz0_th_trans_%d.ply" % idx, pcd_target) 
-+#    
 +
-+            #import pdb; pdb.set_trace()
-+            #pcd_target = o3d.geometry.PointCloud()
-+            #pcd_target.points = o3d.utility.Vector3dVector(coords0)
-+            #o3d.io.write_point_cloud("coords0.ply" , pcd_target) 
-+#    
-+            #pcd_target = o3d.geometry.PointCloud()
-+            #pcd_target.points = o3d.utility.Vector3dVector(coords1)
-+            #o3d.io.write_point_cloud("coords1.ply" , pcd_target) 
++          pc0.points = o3d.utility.Vector3dVector(xyz0[ind_0].numpy())
++          pc0.colors = o3d.utility.Vector3dVector(colors[:F0.shape[0]][ind_0])
++          pc0.transform(T_gt.numpy())
++          o3d.io.write_point_cloud("pc0_trans_corr.ply" , pc0) 
 +
 +
-+        if self.transform: #add noises to the point clouds
-+          coords0, feats0 = self.transform(coords0, feats0)
-+          coords1, feats1 = self.transform(coords1, feats1)
-+        
 +
-+        return (unique_xyz0_th.float(), unique_xyz1_th.float(), coords0.int(),
-+                coords1.int(), feats0.float(), feats1.float(), matches, trans)
 +
-+    def _get_velodyne_fn(self, drive, t):
-+        if self.IS_ODOMETRY:
-+            fname = self.root + '/sequences/%02d/velodyne/%06d.bin' % (drive, t)
-+        else:
-+            fname = self.root + \
-+                    '/' + self.date + '_drive_%04d_sync/velodyne_points/data/%010d.bin' % (
-+                        drive, t)
-+        return fname
+       matching_timer.tic()
+       xyz0, xyz1, T_gt = input_dict['pcd0'], input_dict['pcd1'], input_dict['T_gt']
+       xyz0_corr, xyz1_corr = self.find_corr(xyz0, xyz1, F0, F1, subsample_size=5000)
 +
-+    #def get_position_transform(self, pos0, pos1, invert=False):
-+    #    T0 = self.pos_transform(pos0)
-+    #    T1 = self.pos_transform(pos1)
-+    #    return (np.dot(T1, np.linalg.inv(T0)).T if not invert else np.dot(
-+    #        np.linalg.inv(T1), T0).T)
-+#
 +
 +
++      #pc0.points = o3d.utility.Vector3dVector(xyz0_corr.numpy())
++      #pc0.transform(T_gt.numpy())
++      #o3d.io.write_point_cloud("xyz0_corr_trans.ply" , pc0) 
++#
++      #pc0.points = o3d.utility.Vector3dVector(xyz1_corr.numpy())
++      #o3d.io.write_point_cloud("xyz1_corr_trans.ply" , pc0) 
 +
- 
--ALL_DATASETS = [ThreeDMatchPairDataset, KITTIPairDataset, KITTINMPairDataset]
-+ALL_DATASETS = [ThreeDMatchPairDataset, KITTIPairDataset, KITTINMPairDataset, KITTIMapDataset]
- dataset_str_mapping = {d.__name__: d for d in ALL_DATASETS}
- 
- 
-diff --git a/lib/trainer.py b/lib/trainer.py
-index e4c230b..e6299f8 100644
---- a/lib/trainer.py
-+++ b/lib/trainer.py
-@@ -234,12 +234,12 @@ class ContrastiveLossTrainer(AlignmentTrainer):
-         # pairs consist of (xyz1 index, xyz0 index)
-         sinput0 = ME.SparseTensor(
-             input_dict['sinput0_F'].to(self.device),
--            coordinates=input_dict['sinput0_C'].to(self.device))
-+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
-         F0 = self.model(sinput0).F
- 
-         sinput1 = ME.SparseTensor(
-             input_dict['sinput1_F'].to(self.device),
--            coordinates=input_dict['sinput1_C'].to(self.device))
-+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
-         F1 = self.model(sinput1).F
- 
-         N0, N1 = len(sinput0), len(sinput1)
-@@ -316,14 +316,17 @@ class ContrastiveLossTrainer(AlignmentTrainer):
- 
-       # pairs consist of (xyz1 index, xyz0 index)
-       feat_timer.tic()
-+      
-+      coords=input_dict['sinput0_C'].to(self.device)
-       sinput0 = ME.SparseTensor(
-           input_dict['sinput0_F'].to(self.device),
--          coordinates=input_dict['sinput0_C'].to(self.device))
-+          coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
 +
-       F0 = self.model(sinput0).F
- 
-       sinput1 = ME.SparseTensor(
-           input_dict['sinput1_F'].to(self.device),
--          coordinates=input_dict['sinput1_C'].to(self.device))
-+          coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
-       F1 = self.model(sinput1).F
-       feat_timer.toc()
- 
-@@ -473,12 +476,12 @@ class HardestContrastiveLossTrainer(ContrastiveLossTrainer):
- 
-         sinput0 = ME.SparseTensor(
-             input_dict['sinput0_F'].to(self.device),
--            coordinates=input_dict['sinput0_C'].to(self.device))
-+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
-         F0 = self.model(sinput0).F
- 
-         sinput1 = ME.SparseTensor(
-             input_dict['sinput1_F'].to(self.device),
--            coordinates=input_dict['sinput1_C'].to(self.device))
-+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
- 
-         F1 = self.model(sinput1).F
- 
-@@ -604,12 +607,12 @@ class TripletLossTrainer(ContrastiveLossTrainer):
-         # pairs consist of (xyz1 index, xyz0 index)
-         sinput0 = ME.SparseTensor(
-             input_dict['sinput0_F'].to(self.device),
--            coordinates=input_dict['sinput0_C'].to(self.device))
-+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
-         F0 = self.model(sinput0).F
- 
-         sinput1 = ME.SparseTensor(
-             input_dict['sinput1_F'].to(self.device),
--            coordinates=input_dict['sinput1_C'].to(self.device))
-+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
-         F1 = self.model(sinput1).F
- 
-         pos_pairs = input_dict['correspondences']
-diff --git a/model/residual_block.py b/model/residual_block.py
-index f06fc5a..759597f 100644
---- a/model/residual_block.py
-+++ b/model/residual_block.py
-@@ -29,7 +29,7 @@ class BasicBlockBase(nn.Module):
-         kernel_size=3,
-         stride=1,
-         dilation=dilation,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm2 = get_norm(self.NORM_TYPE, planes, bn_momentum=bn_momentum, D=D)
-     self.downsample = downsample
-diff --git a/model/resunet.py b/model/resunet.py
-index 6a0e2e1..eb9a4e2 100644
---- a/model/resunet.py
-+++ b/model/resunet.py
-@@ -34,7 +34,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=conv1_kernel_size,
-         stride=1,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm1 = get_norm(NORM_TYPE, CHANNELS[1], bn_momentum=bn_momentum, D=D)
- 
-@@ -47,7 +47,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm2 = get_norm(NORM_TYPE, CHANNELS[2], bn_momentum=bn_momentum, D=D)
- 
-@@ -60,7 +60,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm3 = get_norm(NORM_TYPE, CHANNELS[3], bn_momentum=bn_momentum, D=D)
- 
-@@ -73,7 +73,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm4 = get_norm(NORM_TYPE, CHANNELS[4], bn_momentum=bn_momentum, D=D)
- 
-@@ -86,7 +86,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm4_tr = get_norm(NORM_TYPE, TR_CHANNELS[4], bn_momentum=bn_momentum, D=D)
- 
-@@ -99,7 +99,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm3_tr = get_norm(NORM_TYPE, TR_CHANNELS[3], bn_momentum=bn_momentum, D=D)
- 
-@@ -112,7 +112,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=3,
-         stride=2,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
-     self.norm2_tr = get_norm(NORM_TYPE, TR_CHANNELS[2], bn_momentum=bn_momentum, D=D)
- 
-@@ -125,7 +125,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=1,
-         stride=1,
-         dilation=1,
--        bias=False,
-+        has_bias=False,
-         dimension=D)
- 
-     # self.block1_tr = BasicBlockBN(TR_CHANNELS[1], TR_CHANNELS[1], bn_momentum=bn_momentum, D=D)
-@@ -136,7 +136,7 @@ class ResUNet2(ME.MinkowskiNetwork):
-         kernel_size=1,
-         stride=1,
-         dilation=1,
--        bias=True,
-+        has_bias=True,
-         dimension=D)
- 
-   def forward(self, x):
-@@ -187,8 +187,8 @@ class ResUNet2(ME.MinkowskiNetwork):
-     if self.normalize_feature:
-       return ME.SparseTensor(
-           out.F / torch.norm(out.F, p=2, dim=1, keepdim=True),
--          coordinate_map_key=out.coordinate_map_key,
--          coordinate_manager=out.coordinate_manager)
-+          coords_key=out.coords_key,#out.coordinate_map_key,
-+          coords_manager=out.coords_man)#out.coordinate_manager)
-     else:
-       return out
- 
-@@ -244,3 +244,8 @@ class ResUNetIN2D(ResUNetBN2D):
- class ResUNetIN2E(ResUNetBN2E):
-   NORM_TYPE = 'BN'
-   BLOCK_NORM_TYPE = 'IN'
 +
-+class ResUNetBN2C(ResUNet2):
-+  NORM_TYPE = 'BN'
-+  CHANNELS = [None, 32, 64, 128, 256]
-+  TR_CHANNELS = [None, 64, 64, 64, 128]
-\ No newline at end of file
-diff --git a/scripts/train_fcgf_kitti.sh b/scripts/train_fcgf_kitti.sh
-index de073fd..64a0e8e 100755
---- a/scripts/train_fcgf_kitti.sh
-+++ b/scripts/train_fcgf_kitti.sh
-@@ -3,20 +3,20 @@ export PATH_POSTFIX=$1
- export MISC_ARGS=$2
- 
- export DATA_ROOT="./outputs/Experiments"
--export DATASET=${DATASET:-KITTINMPairDataset}
-+export DATASET=${DATASET:-KITTIMapDataset} #KITTINMPairDataset}
- export TRAINER=${TRAINER:-HardestContrastiveLossTrainer}
- export MODEL=${MODEL:-ResUNetBN2C}
- export MODEL_N_OUT=${MODEL_N_OUT:-16}
- export OPTIMIZER=${OPTIMIZER:-SGD}
- export LR=${LR:-1e-1}
- export MAX_EPOCH=${MAX_EPOCH:-200}
--export BATCH_SIZE=${BATCH_SIZE:-8}
-+export BATCH_SIZE=${BATCH_SIZE:-6}
- export ITER_SIZE=${ITER_SIZE:-1}
- export VOXEL_SIZE=${VOXEL_SIZE:-0.3}
- export POSITIVE_PAIR_SEARCH_VOXEL_SIZE_MULTIPLIER=${POSITIVE_PAIR_SEARCH_VOXEL_SIZE_MULTIPLIER:-1.5}
- export CONV1_KERNEL_SIZE=${CONV1_KERNEL_SIZE:-5}
- export EXP_GAMMA=${EXP_GAMMA:-0.99}
--export RANDOM_SCALE=${RANDOM_SCALE:-True}
-+export RANDOM_SCALE=${RANDOM_SCALE:-False} #scale doesn't work for the local map
- export TIME=$(date +"%Y-%m-%d_%H-%M-%S")
- export KITTI_PATH=${KITTI_PATH:-/home/chrischoy/datasets/KITTI_FCGF}
- export VERSION=$(git rev-parse HEAD)
-
-Tue Nov  3 01:04:07 2020       
-+-----------------------------------------------------------------------------+
-| NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |
-|-------------------------------+----------------------+----------------------+
-| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
-| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
-|===============================+======================+======================|
-|   0  GeForce GTX TIT...  On   | 00000000:05:00.0 Off |                  N/A |
-| 50%   83C    P2   139W / 250W |  12207MiB / 12211MiB |     93%      Default |
-+-------------------------------+----------------------+----------------------+
-|   1  GeForce GTX TIT...  On   | 00000000:06:00.0 Off |                  N/A |
-| 27%   65C    P8    17W / 250W |     11MiB / 12212MiB |      0%      Default |
-+-------------------------------+----------------------+----------------------+
-|   2  GeForce GTX TIT...  On   | 00000000:09:00.0 Off |                  N/A |
-| 52%   83C    P2   102W / 250W |   9539MiB / 12212MiB |      0%      Default |
-+-------------------------------+----------------------+----------------------+
-|   3  GeForce GTX TIT...  On   | 00000000:0A:00.0 Off |                  N/A |
-| 40%   77C    P5    25W / 250W |     11MiB / 12212MiB |      0%      Default |
-+-------------------------------+----------------------+----------------------+
-                                                                               
-+-----------------------------------------------------------------------------+
-| Processes:                                                       GPU Memory |
-|  GPU       PID   Type   Process name                             Usage      |
-|=============================================================================|
-|    0      4990      C   python3                                    12196MiB |
-|    2     14147      C   python3                                     9528MiB |
-+-----------------------------------------------------------------------------+
-11/03 01:04:09 ===> Configurations
-11/03 01:04:09     out_dir: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-03_01-04-07
-11/03 01:04:09     trainer: HardestContrastiveLossTrainer
-11/03 01:04:09     save_freq_epoch: 1
-11/03 01:04:09     batch_size: 6
-11/03 01:04:09     val_batch_size: 1
-11/03 01:04:09     use_hard_negative: True
-11/03 01:04:09     hard_negative_sample_ratio: 0.05
-11/03 01:04:09     hard_negative_max_num: 3000
-11/03 01:04:09     num_pos_per_batch: 1024
-11/03 01:04:09     num_hn_samples_per_batch: 256
-11/03 01:04:09     neg_thresh: 1.4
-11/03 01:04:09     pos_thresh: 0.1
-11/03 01:04:09     neg_weight: 1
-11/03 01:04:09     use_random_scale: False
-11/03 01:04:09     min_scale: 0.8
-11/03 01:04:09     max_scale: 1.2
-11/03 01:04:09     use_random_rotation: True
-11/03 01:04:09     rotation_range: 360
-11/03 01:04:09     train_phase: train
-11/03 01:04:09     val_phase: val
-11/03 01:04:09     test_phase: test
-11/03 01:04:09     stat_freq: 40
-11/03 01:04:09     test_valid: True
-11/03 01:04:09     val_max_iter: 400
-11/03 01:04:09     val_epoch_freq: 1
-11/03 01:04:09     positive_pair_search_voxel_size_multiplier: 1.5
-11/03 01:04:09     hit_ratio_thresh: 0.3
-11/03 01:04:09     triplet_num_pos: 256
-11/03 01:04:09     triplet_num_hn: 512
-11/03 01:04:09     triplet_num_rand: 1024
-11/03 01:04:09     model: ResUNetBN2C
-11/03 01:04:09     model_n_out: 16
-11/03 01:04:09     conv1_kernel_size: 5
-11/03 01:04:09     normalize_feature: True
-11/03 01:04:09     dist_type: L2
-11/03 01:04:09     best_val_metric: feat_match_ratio
-11/03 01:04:09     optimizer: SGD
-11/03 01:04:09     max_epoch: 200
-11/03 01:04:09     lr: 0.1
-11/03 01:04:09     momentum: 0.8
-11/03 01:04:09     sgd_momentum: 0.9
-11/03 01:04:09     sgd_dampening: 0.1
-11/03 01:04:09     adam_beta1: 0.9
-11/03 01:04:09     adam_beta2: 0.999
-11/03 01:04:09     weight_decay: 0.0001
-11/03 01:04:09     iter_size: 1
-11/03 01:04:09     bn_momentum: 0.05
-11/03 01:04:09     exp_gamma: 0.99
-11/03 01:04:09     scheduler: ExpLR
-11/03 01:04:09     icp_cache_path: /home/chrischoy/datasets/FCGF/kitti/icp/
-11/03 01:04:09     use_gpu: True
-11/03 01:04:09     weights: None
-11/03 01:04:09     weights_dir: None
-11/03 01:04:09     resume: None
-11/03 01:04:09     resume_dir: None
-11/03 01:04:09     train_num_thread: 8
-11/03 01:04:09     val_num_thread: 8
-11/03 01:04:09     test_num_thread: 8
-11/03 01:04:09     fast_validation: False
-11/03 01:04:09     nn_max_n: 500
-11/03 01:04:09     dataset: KITTIMapDataset
-11/03 01:04:09     voxel_size: 0.3
-11/03 01:04:09     threed_match_dir: /home/chrischoy/datasets/FCGF/threedmatch
-11/03 01:04:09     kitti_root: /home/allie/dataset/kitti_odometry/
-11/03 01:04:09     kitti_max_time_diff: 3
-11/03 01:04:09     kitti_date: 2011_09_26
-11/03 01:04:09     path_cmrdata: /home/allie/dataset/cmr_original
-11/03 01:04:09     depth_max: 50
-11/03 01:04:09     num_min_map_points: 20000.0
-11/03 01:06:57 ResUNetBN2C(
-  (conv1): MinkowskiConvolution(in=1, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
-  (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block1): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=32, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=32, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv2): MinkowskiConvolution(in=32, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
-  (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block2): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv3): MinkowskiConvolution(in=64, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
-  (norm3): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block3): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv4): MinkowskiConvolution(in=128, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
-  (norm4): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block4): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=256, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=256, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv4_tr): MinkowskiConvolutionTranspose(in=256, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
-  (norm4_tr): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block4_tr): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv3_tr): MinkowskiConvolutionTranspose(in=256, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
-  (norm3_tr): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block3_tr): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv2_tr): MinkowskiConvolutionTranspose(in=128, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
-  (norm2_tr): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  (block2_tr): BasicBlockBN(
-    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
-    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
-  )
-  (conv1_tr): MinkowskiConvolution(in=96, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
-  (final): MinkowskiConvolution(in=64, out=16, region_type=RegionType.HYPERCUBE, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
-)
-11/03 01:07:00 Resetting the data loader seed to 0
-/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/MinkowskiEngine/SparseTensor.py:260: UserWarning: Coords implicitly converted to torch.IntTensor. To remove this warning, use `.int()` to convert the coords into an torch.IntTensor
-  'To remove this warning, use `.int()` to convert the ' +
-/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/MinkowskiEngine/SparseTensor.py:267: UserWarning: Coords implicitly converted to CPU type. To remove this warning, use `.cpu()` to convert the coords into a CPU type
-  'To remove this warning, use `.cpu()` to convert the ' +
-11/03 01:10:36 Validation iter 101 / 400 : Data Loading Time: 0.062, Feature Extraction Time: 1.172, Matching Time: 0.883, Loss: 0.999, RTE: 250.249, RRE: 0.855, Hit Ratio: 0.000, Feat Match Ratio: 0.000
-11/03 01:14:04 Validation iter 201 / 400 : Data Loading Time: 0.014, Feature Extraction Time: 1.170, Matching Time: 0.879, Loss: 0.998, RTE: 222.577, RRE: 0.821, Hit Ratio: 0.000, Feat Match Ratio: 0.000
-11/03 01:17:31 Validation iter 301 / 400 : Data Loading Time: 0.017, Feature Extraction Time: 1.159, Matching Time: 0.880, Loss: 0.995, RTE: 217.632, RRE: 0.824, Hit Ratio: 0.000, Feat Match Ratio: 0.000
-11/03 01:20:47 Final Loss: 0.995, RTE: 224.363, RRE: 0.844, Hit Ratio: 0.000, Feat Match Ratio: 0.000
-/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:449: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
-  "please use `get_last_lr()`.", UserWarning)
-11/03 01:20:47  Epoch: 1, LR: [0.1]
-11/03 01:21:22 Train Epoch: 1 [0/477], Current Loss: 1.704e+00 Pos: 0.724 Neg: 0.980	Data time: 26.4148, Train time: 8.3080, Iter time: 34.7228
-11/03 01:26:58 Train Epoch: 1 [40/477], Current Loss: 1.344e+00 Pos: 0.288 Neg: 1.057	Data time: 0.1094, Train time: 8.2677, Iter time: 8.3771
++
+       T_est = te.est_quad_linear_robust(xyz0
\ No newline at end of file
diff --git a/scripts/train_fcgf_kitti.sh b/scripts/train_fcgf_kitti.sh
index 64a0e8e..09e4c81 100755
--- a/scripts/train_fcgf_kitti.sh
+++ b/scripts/train_fcgf_kitti.sh
@@ -13,7 +13,7 @@ export MAX_EPOCH=${MAX_EPOCH:-200}
 export BATCH_SIZE=${BATCH_SIZE:-6}
 export ITER_SIZE=${ITER_SIZE:-1}
 export VOXEL_SIZE=${VOXEL_SIZE:-0.3}
-export POSITIVE_PAIR_SEARCH_VOXEL_SIZE_MULTIPLIER=${POSITIVE_PAIR_SEARCH_VOXEL_SIZE_MULTIPLIER:-1.5}
+export POSITIVE_PAIR_SEARCH_VOXEL_SIZE_MULTIPLIER=${POSITIVE_PAIR_SEARCH_VOXEL_SIZE_MULTIPLIER:-0.5} #1,5 -> 0.5 otherwise it might generate too many pairs from the dense map
 export CONV1_KERNEL_SIZE=${CONV1_KERNEL_SIZE:-5}
 export EXP_GAMMA=${EXP_GAMMA:-0.99}
 export RANDOM_SCALE=${RANDOM_SCALE:-False} #scale doesn't work for the local map

Fri Nov  6 01:47:05 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX TIT...  On   | 00000000:05:00.0 Off |                  N/A |
| 23%   62C    P8    32W / 250W |      0MiB / 12211MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX TIT...  On   | 00000000:06:00.0 Off |                  N/A |
| 29%   65C    P8    17W / 250W |      0MiB / 12212MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX TIT...  On   | 00000000:09:00.0 Off |                  N/A |
| 53%   83C    P2    96W / 250W |  11249MiB / 12212MiB |    100%      Default |
+-------------------------------+----------------------+----------------------+
|   3  GeForce GTX TIT...  On   | 00000000:0A:00.0 Off |                  N/A |
| 43%   81C    P2   100W / 250W |   2410MiB / 12212MiB |     40%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    2      6811      C   python3                                    11238MiB |
|    3      9051      C   python                                      2399MiB |
+-----------------------------------------------------------------------------+
11/06 01:47:07 ===> Configurations
11/06 01:47:07     out_dir: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16--gtremoval2/2020-11-06_01-47-05
11/06 01:47:07     trainer: HardestContrastiveLossTrainer
11/06 01:47:07     save_freq_epoch: 1
11/06 01:47:07     batch_size: 6
11/06 01:47:07     val_batch_size: 1
11/06 01:47:07     use_hard_negative: True
11/06 01:47:07     hard_negative_sample_ratio: 0.05
11/06 01:47:07     hard_negative_max_num: 3000
11/06 01:47:07     num_pos_per_batch: 1024
11/06 01:47:07     num_hn_samples_per_batch: 256
11/06 01:47:07     neg_thresh: 1.4
11/06 01:47:07     pos_thresh: 0.1
11/06 01:47:07     neg_weight: 1
11/06 01:47:07     use_random_scale: False
11/06 01:47:07     min_scale: 0.8
11/06 01:47:07     max_scale: 1.2
11/06 01:47:07     use_random_rotation: True
11/06 01:47:07     rotation_range: 360
11/06 01:47:07     train_phase: train
11/06 01:47:07     val_phase: val
11/06 01:47:07     test_phase: test
11/06 01:47:07     stat_freq: 40
11/06 01:47:07     test_valid: True
11/06 01:47:07     val_max_iter: 400
11/06 01:47:07     val_epoch_freq: 1
11/06 01:47:07     positive_pair_search_voxel_size_multiplier: 0.5
11/06 01:47:07     hit_ratio_thresh: 0.3
11/06 01:47:07     triplet_num_pos: 256
11/06 01:47:07     triplet_num_hn: 512
11/06 01:47:07     triplet_num_rand: 1024
11/06 01:47:07     model: ResUNetBN2C
11/06 01:47:07     model_n_out: 16
11/06 01:47:07     conv1_kernel_size: 5
11/06 01:47:07     normalize_feature: True
11/06 01:47:07     dist_type: L2
11/06 01:47:07     best_val_metric: feat_match_ratio
11/06 01:47:07     optimizer: SGD
11/06 01:47:07     max_epoch: 200
11/06 01:47:07     lr: 0.1
11/06 01:47:07     momentum: 0.8
11/06 01:47:07     sgd_momentum: 0.9
11/06 01:47:07     sgd_dampening: 0.1
11/06 01:47:07     adam_beta1: 0.9
11/06 01:47:07     adam_beta2: 0.999
11/06 01:47:07     weight_decay: 0.0001
11/06 01:47:07     iter_size: 1
11/06 01:47:07     bn_momentum: 0.05
11/06 01:47:07     exp_gamma: 0.99
11/06 01:47:07     scheduler: ExpLR
11/06 01:47:07     icp_cache_path: /home/chrischoy/datasets/FCGF/kitti/icp/
11/06 01:47:07     use_gpu: True
11/06 01:47:07     weights: 
11/06 01:47:07     weights_dir: None
11/06 01:47:07     resume: None
11/06 01:47:07     resume_dir: None
11/06 01:47:07     train_num_thread: 8
11/06 01:47:07     val_num_thread: 8
11/06 01:47:07     test_num_thread: 8
11/06 01:47:07     fast_validation: False
11/06 01:47:07     nn_max_n: 500
11/06 01:47:07     dataset: KITTIMapDataset
11/06 01:47:07     voxel_size: 0.3
11/06 01:47:07     threed_match_dir: /home/chrischoy/datasets/FCGF/threedmatch
11/06 01:47:07     kitti_root: /home/allie/dataset/kitti_odometry/
11/06 01:47:07     kitti_max_time_diff: 3
11/06 01:47:07     kitti_date: 2011_09_26
11/06 01:47:07     path_cmrdata: /home/allie/dataset/cmr_original
11/06 01:47:07     depth_max: 50
11/06 01:47:07     num_min_map_points: 20000.0
