./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b8i1-modelnout16/2020-11-02_17-08-48
Host:  bb8
Conda  /home/allie/miniconda3/condabin/conda
/home/allie/code/benchmark/FCGF
Version:  f0863a9ba4a29f677c0ddd2248cf4e56b9318add
Git diff

diff --git a/config.py b/config.py
index 476402d..87abb73 100644
--- a/config.py
+++ b/config.py
@@ -112,14 +112,28 @@ data_arg.add_argument(
     '--threed_match_dir', type=str, default="/home/chrischoy/datasets/FCGF/threedmatch")
 data_arg.add_argument(
     '--kitti_root', type=str, default="/home/chrischoy/datasets/FCGF/kitti/")
+
 data_arg.add_argument(
     '--kitti_max_time_diff',
     type=int,
     default=3,
     help='max time difference between pairs (non inclusive)')
+
 data_arg.add_argument('--kitti_date', type=str, default='2011_09_26')
 
 
+#arguments for KITTI map dataset
+#for kitti ground truth poses (optimized by loop-closing SLAM)
+data_arg.add_argument(
+    '--path_cmrdata', type=str, default="/home/allie/dataset/cmr_original") 
+data_arg.add_argument(
+    '--depth_max', type=float, default=50) 
+data_arg.add_argument(
+    '--num_min_map_points', type=int, default=2e4) 
+
+
+
+
 def get_config():
   args = parser.parse_args()
   return args
diff --git a/lib/data_loaders.py b/lib/data_loaders.py
index 2bc475a..a45bee3 100644
--- a/lib/data_loaders.py
+++ b/lib/data_loaders.py
@@ -18,10 +18,42 @@ import lib.transforms as t
 import MinkowskiEngine as ME
 
 import open3d as o3d
+import pickle
 
 kitti_cache = {}
 kitti_icp_cache = {}
 
+eps = 1e-10
+import csv
+def read_csv_file(path_file):
+    lines = []
+    with open(path_file, "r") as f:
+        reader = csv.reader(f, delimiter="\t")
+        for i, line in enumerate(reader):
+            if i >= 1:
+                lines.append(np.asarray(line[0].split(',')[1:]).astype('float'))
+    return lines
+
+
+def pred_to_matrix_np(pred):
+
+    cam_T = np.tile(np.eye(4)[np.newaxis,:,:],[pred.shape[0], 1, 1])
+    cam_T[:,0:3, 3] = pred[:, 0:3]
+    s = np.tile(np.linalg.norm(pred[:,3:], axis=1)[:,np.newaxis],[1,4])
+
+    q = pred[:,3:] / (s+eps)
+
+    cam_T[:,0,0] = 1- 2*s[:,0]*(q[:,2]**2 + q[:,3]**2)
+    cam_T[:,0,1] = 2   *s[:,0]*(q[:,1] * q[:,2] - q[:,3] * q[:,0])
+    cam_T[:,0,2] = 2   *s[:,0]*(q[:,1] * q[:,3] + q[:,2] * q[:,0])
+    cam_T[:,1,0] = 2   *s[:,0]*(q[:,1]*q[:,2] + q[:,3]*q[:,0])
+    cam_T[:,1,1] = 1- 2*s[:,0]*(q[:,1]**2 + q[:,3]**2)
+    cam_T[:,1,2] = 2   *s[:,0]*(q[:,2] * q[:,3] - q[:,1] * q[:,0])
+    cam_T[:,2,0] = 2   *s[:,0]*(q[:,1] * q[:,3] - q[:,2] * q[:,0])
+    cam_T[:,2,1] = 2   *s[:,0]*(q[:,2] * q[:,3] + q[:,1] * q[:,0])
+    cam_T[:,2,2] = 1 -2*s[:,0]*(q[:,1]**2 + q[:,2]**2)
+
+    return cam_T
 
 def collate_pair_fn(list_data):
   xyz0, xyz1, coords0, coords1, feats0, feats1, matching_inds, trans = list(
@@ -632,8 +664,278 @@ class ThreeDMatchPairDataset(IndoorPairDataset):
       'test': './config/test_3dmatch.txt'
   }
 
+class KITTIMapDataset(PairDataset):
+    AUGMENT = None
+    DATA_FILES = {
+        'train': './config/train_kitti_map.txt', #log ids
+        'val': './config/val_kitti_map.txt',
+        'test': './config/test_kitti_map.txt'
+    }
+    TEST_RANDOM_ROTATION = False
+    IS_ODOMETRY = True
+    #MAX_TIME_DIFF = 3
+
+    def __init__(self,
+               phase,
+               transform=None,
+               random_rotation=True,
+               random_scale=True,
+               manual_seed=False,
+               config=None):
+
+
+    #(self, root, split, config, input_threads=8, first_subsampling_dl=0.30):#, load_test=False):
+        
+        PairDataset.__init__(self, phase, transform, random_rotation, random_scale,
+                         manual_seed, config)
+
+        self.root = root = os.path.join(config.kitti_root, 'dataset')
+        self.split = phase
+        self.config = config
+
+        self.path_map_dict = os.path.join(root, "kitti_map_files_d3feat_%s.pkl" % self.split)
+        self.read_map_data()
+        self.prepare_kitti_ply()#split=split)
+       
+
+    def __len__(self):
+        return self.num
+
+    def read_map_data(self):
+        if os.path.exists(self.path_map_dict):
+            with open(self.path_map_dict, 'rb') as f:
+                self.dict_maps = pickle.load(f)
+            return 
+
+
+        subset_names = open(self.DATA_FILES[self.split]).read().split()
+        self.dict_maps = {}
+        for id_log in subset_names:
+            path_map = os.path.join(self.root, "kitti_maps_cmr_new", "map-%02d_0.05.ply" % (int(id_log)))
+            print("Load map : ", path_map)
+            pcd = open3d.io.read_point_cloud(path_map)
+            pcd = pcd.voxel_down_sample(self.config.first_subsampling_dl)
+            pcd, ind = pcd.remove_radius_outlier(nb_points=7, radius=self.config.first_subsampling_dl*2)
+            self.dict_maps[id_log] = torch.Tensor(np.asarray(pcd.points))#.to(self.config.device)
+
+
+        with open(self.path_map_dict, 'wb') as f: 
+            print('Saving map file to ', self.path_map_dict)
+            pickle.dump(self.dict_maps, f)
+            print('Saved!')    
+
+    def get_local_map(self,T_lidar, drive):#, force_select_points=False):
+        dist = torch.sqrt(((self.dict_maps[drive] - T_lidar[0:3,3])**2).sum(axis=1))
+        ind_valid_local = dist < self.config.depth_max
+
+        return self.dict_maps[drive][ind_valid_local]
+
+            
+    def prepare_kitti_ply(self):#, split='train'):
+        #max_time_diff = self.MAX_TIME_DIFF
+        subset_names = open(self.DATA_FILES[self.split]).read().split()
+        self.all_pos = []
+        for dirname in subset_names:
+            drive_id = int(dirname)
+            fnames = glob.glob(self.root + '/sequences/%02d/velodyne/*.bin' % drive_id)
+
+            assert len(fnames) > 0, f"Make sure that the path {self.root} has data {dirname}"
+            inames = sorted([int(os.path.split(fname)[-1][:-4]) for fname in fnames])
+            path_poses = os.path.join(self.config.path_cmrdata, self.split, "kitti-%02d.csv" % drive_id)
+            list_gt_poses = read_csv_file(path_poses)
+
+            for i in range(0,len(inames),2):# curr_time in inames:
+                
+
+                T = pred_to_matrix_np(np.asarray(list_gt_poses[i][np.newaxis,[0,1,2,6,3,4,5]]))[0]
+                xyz0 = self.get_local_map(T, dirname)
+
+                #use the local map as the source
+                T = np.linalg.inv(T) 
+                if xyz0.shape[0] < self.config.num_min_map_points:
+                    continue
+                
+                self.files.append((drive_id, inames[i]))#, next_time))
+                self.all_pos.append( torch.Tensor(T))#.to(self.config.device))
+        self.num = len(self.files)
+
+    def __getitem__(self,idx):# split, idx):
+        drive = self.files[idx][0]
+        #t0, t1 = self.files[self.split][idx][1], self.files[self.split][idx][2]
+
+        #LiDAR is the target
+        fname1 = self._get_velodyne_fn(drive,  self.files[idx][1])
+        xyzr1 = np.fromfile(fname1, dtype=np.float32).reshape(-1, 4) 
+        xyz1 = xyzr1[:, :3]
+        
+        #map is the source
+        xyz0 = self.get_local_map( np.linalg.inv(self.all_pos[idx]), str(drive))
+        trans = self.all_pos[idx]# M2
+
+        matching_search_voxel_size = self.matching_search_voxel_size
+        if self.random_scale and random.random() < 0.95:
+            scale = self.min_scale + \
+                (self.max_scale - self.min_scale) * random.random()
+            matching_search_voxel_size *= scale
+            xyz0 = scale * xyz0
+            xyz1 = scale * xyz1
+
+        # Voxelization
+        xyz0_th = xyz0#torch.from_numpy(xyz0)
+        xyz1_th = torch.from_numpy(xyz1)
+    
+        sel0 = ME.utils.sparse_quantize(xyz0_th / self.voxel_size, return_index=True)
+        sel1 = ME.utils.sparse_quantize(xyz1_th / self.voxel_size, return_index=True)
+    
+        # Make point clouds using voxelized points
+        pcd0 = make_open3d_point_cloud(xyz0[sel0])
+        pcd1 = make_open3d_point_cloud(xyz1[sel1])
+    
+        # Get matches
+        matches = get_matching_indices(pcd0, pcd1, trans, matching_search_voxel_size)
+        #if len(matches) < 1000:
+        #  raise ValueError(f"{drive}, {t0}, {t1}")
+        matches = np.array(matches)
+
+
+        # Get features
+        npts0 = len(sel0)
+        npts1 = len(sel1)
+    
+        feats_train0, feats_train1 = [], []
+    
+        unique_xyz0_th = xyz0_th[sel0]
+        unique_xyz1_th = xyz1_th[sel1]
+    
+        feats_train0.append(torch.ones((npts0, 1)))
+        feats_train1.append(torch.ones((npts1, 1)))
+    
+        feats0 = torch.cat(feats_train0, 1)
+        feats1 = torch.cat(feats_train1, 1)
+    
+        coords0 = torch.floor(unique_xyz0_th / self.voxel_size)
+        coords1 = torch.floor(unique_xyz1_th / self.voxel_size)
+ 
+        #print("matches shape = ", matches.shape)
+        #print(coords0.shape)
+        #print(coords1.shape)
+        #print(coords0)
+#
+#
+        #pcd_target = o3d.geometry.PointCloud()
+        #pcd_target.points = o3d.utility.Vector3dVector(coords0)
+        #o3d.io.write_point_cloud("coords0_before.ply" , pcd_target) 
+#
+        #pcd_target = o3d.geometry.PointCloud()
+        #pcd_target.points = o3d.utility.Vector3dVector(coords1)
+        #o3d.io.write_point_cloud("coords1_before.ply" , pcd_target) 
+#
+
+        if self.transform:
+          coords0, feats0 = self.transform(coords0, feats0)
+          coords1, feats1 = self.transform(coords1, feats1)
+    
+        
+        #pcd_target = o3d.geometry.PointCloud()
+        #pcd_target.points = o3d.utility.Vector3dVector(coords0)
+        #o3d.io.write_point_cloud("coords0.ply" , pcd_target) 
+#
+        #pcd_target = o3d.geometry.PointCloud()
+        #pcd_target.points = o3d.utility.Vector3dVector(coords1)
+        #o3d.io.write_point_cloud("coords1.ply" , pcd_target) 
+#
+#
+
+
+        return (unique_xyz0_th.float(), unique_xyz1_th.float(), coords0.int(),
+                coords1.int(), feats0.float(), feats1.float(), matches, trans)
+    
+            #return (anc_points, pos_points, unaligned_anc_points, unaligned_pos_points, matches, trans, True)
+
+    #def apply_transform(self, pts, trans):
+    #    R = trans[:3, :3]
+    #    T = trans[:3, 3]
+    #    pts = pts @ R.T + T
+    #    return pts
+#
+    #@property
+    #def velo2cam(self):
+    #    try:
+    #        velo2cam = self._velo2cam
+    #    except AttributeError:
+    #        R = np.array([
+    #            7.533745e-03, -9.999714e-01, -6.166020e-04, 1.480249e-02, 7.280733e-04,
+    #            -9.998902e-01, 9.998621e-01, 7.523790e-03, 1.480755e-02
+    #        ]).reshape(3, 3)
+    #        T = np.array([-4.069766e-03, -7.631618e-02, -2.717806e-01]).reshape(3, 1)
+    #        velo2cam = np.hstack([R, T])
+    #        self._velo2cam = np.vstack((velo2cam, [0, 0, 0, 1])).T
+    #    return self._velo2cam
+#
+    #def get_video_odometry(self, drive, indices=None, ext='.txt', return_all=False):
+    #    if self.IS_ODOMETRY:
+    #        data_path = self.root + '/poses/%02d.txt' % drive
+    #        if data_path not in kitti_cache:
+    #            kitti_cache[data_path] = np.genfromtxt(data_path)
+    #        if return_all:
+    #            return kitti_cache[data_path]
+    #        else:
+    #            return kitti_cache[data_path][indices]
+    #    else:
+    #        data_path = self.root + '/' + self.date + '_drive_%04d_sync/oxts/data' % drive
+    #        odometry = []
+    #        if indices is None:
+    #            fnames = glob.glob(self.root + '/' + self.date +
+    #                               '_drive_%04d_sync/velodyne_points/data/*.bin' % drive)
+    #            indices = sorted([int(os.path.split(fname)[-1][:-4]) for fname in fnames])
+#
+    #        for index in indices:
+    #            filename = os.path.join(data_path, '%010d%s' % (index, ext))
+    #            if filename not in kitti_cache:
+    #                kitti_cache[filename] = np.genfromtxt(filename)
+    #                odometry.append(kitti_cache[filename])
+#
+    #        odometry = np.array(odometry)
+    #        return odometry
+#
+    #def odometry_to_positions(self, odometry):
+    #    if self.IS_ODOMETRY:
+    #        T_w_cam0 = odometry.reshape(3, 4)
+    #        T_w_cam0 = np.vstack((T_w_cam0, [0, 0, 0, 1]))
+    #        return T_w_cam0
+    #    else:
+    #        lat, lon, alt, roll, pitch, yaw = odometry.T[:6]
+#
+    #        R = 6378137  # Earth's radius in metres
+#
+    #        # convert to metres
+    #        lat, lon = np.deg2rad(lat), np.deg2rad(lon)
+    #        mx = R * lon * np.cos(lat)
+    #        my = R * lat
+#
+    #        times = odometry.T[-1]
+    #        return np.vstack([mx, my, alt, roll, pitch, yaw, times]).T
+#
+    def _get_velodyne_fn(self, drive, t):
+        if self.IS_ODOMETRY:
+            fname = self.root + '/sequences/%02d/velodyne/%06d.bin' % (drive, t)
+        else:
+            fname = self.root + \
+                    '/' + self.date + '_drive_%04d_sync/velodyne_points/data/%010d.bin' % (
+                        drive, t)
+        return fname
+
+    #def get_position_transform(self, pos0, pos1, invert=False):
+    #    T0 = self.pos_transform(pos0)
+    #    T1 = self.pos_transform(pos1)
+    #    return (np.dot(T1, np.linalg.inv(T0)).T if not invert else np.dot(
+    #        np.linalg.inv(T1), T0).T)
+#
+
+
+
 
-ALL_DATASETS = [ThreeDMatchPairDataset, KITTIPairDataset, KITTINMPairDataset]
+ALL_DATASETS = [ThreeDMatchPairDataset, KITTIPairDataset, KITTINMPairDataset, KITTIMapDataset]
 dataset_str_mapping = {d.__name__: d for d in ALL_DATASETS}
 
 
diff --git a/lib/trainer.py b/lib/trainer.py
index e4c230b..e6299f8 100644
--- a/lib/trainer.py
+++ b/lib/trainer.py
@@ -234,12 +234,12 @@ class ContrastiveLossTrainer(AlignmentTrainer):
         # pairs consist of (xyz1 index, xyz0 index)
         sinput0 = ME.SparseTensor(
             input_dict['sinput0_F'].to(self.device),
-            coordinates=input_dict['sinput0_C'].to(self.device))
+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
         F0 = self.model(sinput0).F
 
         sinput1 = ME.SparseTensor(
             input_dict['sinput1_F'].to(self.device),
-            coordinates=input_dict['sinput1_C'].to(self.device))
+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
         F1 = self.model(sinput1).F
 
         N0, N1 = len(sinput0), len(sinput1)
@@ -316,14 +316,17 @@ class ContrastiveLossTrainer(AlignmentTrainer):
 
       # pairs consist of (xyz1 index, xyz0 index)
       feat_timer.tic()
+      
+      coords=input_dict['sinput0_C'].to(self.device)
       sinput0 = ME.SparseTensor(
           input_dict['sinput0_F'].to(self.device),
-          coordinates=input_dict['sinput0_C'].to(self.device))
+          coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
+
       F0 = self.model(sinput0).F
 
       sinput1 = ME.SparseTensor(
           input_dict['sinput1_F'].to(self.device),
-          coordinates=input_dict['sinput1_C'].to(self.device))
+          coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
       F1 = self.model(sinput1).F
       feat_timer.toc()
 
@@ -473,12 +476,12 @@ class HardestContrastiveLossTrainer(ContrastiveLossTrainer):
 
         sinput0 = ME.SparseTensor(
             input_dict['sinput0_F'].to(self.device),
-            coordinates=input_dict['sinput0_C'].to(self.device))
+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
         F0 = self.model(sinput0).F
 
         sinput1 = ME.SparseTensor(
             input_dict['sinput1_F'].to(self.device),
-            coordinates=input_dict['sinput1_C'].to(self.device))
+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
 
         F1 = self.model(sinput1).F
 
@@ -604,12 +607,12 @@ class TripletLossTrainer(ContrastiveLossTrainer):
         # pairs consist of (xyz1 index, xyz0 index)
         sinput0 = ME.SparseTensor(
             input_dict['sinput0_F'].to(self.device),
-            coordinates=input_dict['sinput0_C'].to(self.device))
+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
         F0 = self.model(sinput0).F
 
         sinput1 = ME.SparseTensor(
             input_dict['sinput1_F'].to(self.device),
-            coordinates=input_dict['sinput1_C'].to(self.device))
+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
         F1 = self.model(sinput1).F
 
         pos_pairs = input_dict['correspondences']
diff --git a/model/residual_block.py b/model/residual_block.py
index f06fc5a..759597f 100644
--- a/model/residual_block.py
+++ b/model/residual_block.py
@@ -29,7 +29,7 @@ class BasicBlockBase(nn.Module):
         kernel_size=3,
         stride=1,
         dilation=dilation,
-        bias=False,
+        has_bias=False,
         dimension=D)
     self.norm2 = get_norm(self.NORM_TYPE, planes, bn_momentum=bn_momentum, D=D)
     self.downsample = downsample
diff --git a/model/resunet.py b/model/resunet.py
index 6a0e2e1..eb9a4e2 100644
--- a/model/resunet.py
+++ b/model/resunet.py
@@ -34,7 +34,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=conv1_kernel_size,
         stride=1,
         dilation=1,
-        bias=False,
+        has_bias=False,
         dimension=D)
     self.norm1 = get_norm(NORM_TYPE, CHANNELS[1], bn_momentum=bn_momentum, D=D)
 
@@ -47,7 +47,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        bias=False,
+        has_bias=False,
         dimension=D)
     self.norm2 = get_norm(NORM_TYPE, CHANNELS[2], bn_momentum=bn_momentum, D=D)
 
@@ -60,7 +60,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        bias=False,
+        has_bias=False,
         dimension=D)
     self.norm3 = get_norm(NORM_TYPE, CHANNELS[3], bn_momentum=bn_momentum, D=D)
 
@@ -73,7 +73,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        bias=False,
+        has_bias=False,
         dimension=D)
     self.norm4 = get_norm(NORM_TYPE, CHANNELS[4], bn_momentum=bn_momentum, D=D)
 
@@ -86,7 +86,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        bias=False,
+        has_bias=False,
         dimension=D)
     self.norm4_tr = get_norm(NORM_TYPE, TR_CHANNELS[4], bn_momentum=bn_momentum, D=D)
 
@@ -99,7 +99,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        bias=False,
+        has_bias=False,
         dimension=D)
     self.norm3_tr = get_norm(NORM_TYPE, TR_CHANNELS[3], bn_momentum=bn_momentum, D=D)
 
@@ -112,7 +112,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        bias=False,
+        has_bias=False,
         dimension=D)
     self.norm2_tr = get_norm(NORM_TYPE, TR_CHANNELS[2], bn_momentum=bn_momentum, D=D)
 
@@ -125,7 +125,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        bias=False,
+        has_bias=False,
         dimension=D)
 
     # self.block1_tr = BasicBlockBN(TR_CHANNELS[1], TR_CHANNELS[1], bn_momentum=bn_momentum, D=D)
@@ -136,7 +136,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        bias=True,
+        has_bias=True,
         dimension=D)
 
   def forward(self, x):
@@ -187,8 +187,8 @@ class ResUNet2(ME.MinkowskiNetwork):
     if self.normalize_feature:
       return ME.SparseTensor(
           out.F / torch.norm(out.F, p=2, dim=1, keepdim=True),
-          coordinate_map_key=out.coordinate_map_key,
-          coordinate_manager=out.coordinate_manager)
+          coords_key=out.coords_key,#out.coordinate_map_key,
+          coords_manager=out.coords_man)#out.coordinate_manager)
     else:
       return out
 
@@ -244,3 +244,8 @@ class ResUNetIN2D(ResUNetBN2D):
 class ResUNetIN2E(ResUNetBN2E):
   NORM_TYPE = 'BN'
   BLOCK_NORM_TYPE = 'IN'
+
+class ResUNetBN2C(ResUNet2):
+  NORM_TYPE = 'BN'
+  CHANNELS = [None, 32, 64, 128, 256]
+  TR_CHANNELS = [None, 64, 64, 64, 128]
\ No newline at end of file
diff --git a/scripts/train_fcgf_kitti.sh b/scripts/train_fcgf_kitti.sh
index de073fd..ed12044 100755
--- a/scripts/train_fcgf_kitti.sh
+++ b/scripts/train_fcgf_kitti.sh
@@ -3,7 +3,7 @@ export PATH_POSTFIX=$1
 export MISC_ARGS=$2
 
 export DATA_ROOT="./outputs/Experiments"
-export DATASET=${DATASET:-KITTINMPairDataset}
+export DATASET=${DATASET:-KITTIMapDataset} #KITTINMPairDataset}
 export TRAINER=${TRAINER:-HardestContrastiveLossTrainer}
 export MODEL=${MODEL:-ResUNetBN2C}
 export MODEL_N_OUT=${MODEL_N_OUT:-16}

Mon Nov  2 17:08:49 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX TIT...  On   | 00000000:05:00.0 Off |                  N/A |
| 50%   83C    P2   117W / 250W |  12207MiB / 12211MiB |    100%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX TIT...  On   | 00000000:06:00.0 Off |                  N/A |
| 24%   63C    P8    17W / 250W |     11MiB / 12212MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX TIT...  On   | 00000000:09:00.0 Off |                  N/A |
| 53%   83C    P2   110W / 250W |   9515MiB / 12212MiB |     97%      Default |
+-------------------------------+----------------------+----------------------+
|   3  GeForce GTX TIT...  On   | 00000000:0A:00.0 Off |                  N/A |
| 36%   70C    P8    21W / 250W |     11MiB / 12212MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      4990      C   python3                                    12196MiB |
|    2     14147      C   python3                                     9504MiB |
+-----------------------------------------------------------------------------+
11/02 17:08:50 ===> Configurations
11/02 17:08:50     out_dir: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b8i1-modelnout16/2020-11-02_17-08-48
11/02 17:08:50     trainer: HardestContrastiveLossTrainer
11/02 17:08:50     save_freq_epoch: 1
11/02 17:08:50     batch_size: 8
11/02 17:08:50     val_batch_size: 1
11/02 17:08:50     use_hard_negative: True
11/02 17:08:50     hard_negative_sample_ratio: 0.05
11/02 17:08:50     hard_negative_max_num: 3000
11/02 17:08:50     num_pos_per_batch: 1024
11/02 17:08:50     num_hn_samples_per_batch: 256
11/02 17:08:50     neg_thresh: 1.4
11/02 17:08:50     pos_thresh: 0.1
11/02 17:08:50     neg_weight: 1
11/02 17:08:50     use_random_scale: True
11/02 17:08:50     min_scale: 0.8
11/02 17:08:50     max_scale: 1.2
11/02 17:08:50     use_random_rotation: True
11/02 17:08:50     rotation_range: 360
11/02 17:08:50     train_phase: train
11/02 17:08:50     val_phase: val
11/02 17:08:50     test_phase: test
11/02 17:08:50     stat_freq: 40
11/02 17:08:50     test_valid: True
11/02 17:08:50     val_max_iter: 400
11/02 17:08:50     val_epoch_freq: 1
11/02 17:08:50     positive_pair_search_voxel_size_multiplier: 1.5
11/02 17:08:50     hit_ratio_thresh: 0.3
11/02 17:08:50     triplet_num_pos: 256
11/02 17:08:50     triplet_num_hn: 512
11/02 17:08:50     triplet_num_rand: 1024
11/02 17:08:50     model: ResUNetBN2C
11/02 17:08:50     model_n_out: 16
11/02 17:08:50     conv1_kernel_size: 5
11/02 17:08:50     normalize_feature: True
11/02 17:08:50     dist_type: L2
11/02 17:08:50     best_val_metric: feat_match_ratio
11/02 17:08:50     optimizer: SGD
11/02 17:08:50     max_epoch: 200
11/02 17:08:50     lr: 0.1
11/02 17:08:50     momentum: 0.8
11/02 17:08:50     sgd_momentum: 0.9
11/02 17:08:50     sgd_dampening: 0.1
11/02 17:08:50     adam_beta1: 0.9
11/02 17:08:50     adam_beta2: 0.999
11/02 17:08:50     weight_decay: 0.0001
11/02 17:08:50     iter_size: 1
11/02 17:08:50     bn_momentum: 0.05
11/02 17:08:50     exp_gamma: 0.99
11/02 17:08:50     scheduler: ExpLR
11/02 17:08:50     icp_cache_path: /home/chrischoy/datasets/FCGF/kitti/icp/
11/02 17:08:50     use_gpu: True
11/02 17:08:50     weights: None
11/02 17:08:50     weights_dir: None
11/02 17:08:50     resume: None
11/02 17:08:50     resume_dir: None
11/02 17:08:50     train_num_thread: 2
11/02 17:08:50     val_num_thread: 1
11/02 17:08:50     test_num_thread: 2
11/02 17:08:50     fast_validation: False
11/02 17:08:50     nn_max_n: 500
11/02 17:08:50     dataset: KITTIMapDataset
11/02 17:08:50     voxel_size: 0.3
11/02 17:08:50     threed_match_dir: /home/chrischoy/datasets/FCGF/threedmatch
11/02 17:08:50     kitti_root: /home/allie/dataset/kitti_odometry/
11/02 17:08:50     kitti_max_time_diff: 3
11/02 17:08:50     kitti_date: 2011_09_26
11/02 17:08:50     path_cmrdata: /home/allie/dataset/cmr_original
11/02 17:08:50     depth_max: 50
11/02 17:08:50     num_min_map_points: 20000.0
11/02 17:11:43 ResUNetBN2C(
  (conv1): MinkowskiConvolution(in=1, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block1): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=32, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=32, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv2): MinkowskiConvolution(in=32, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
  (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block2): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv3): MinkowskiConvolution(in=64, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
  (norm3): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block3): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv4): MinkowskiConvolution(in=128, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
  (norm4): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block4): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=256, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=256, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv4_tr): MinkowskiConvolutionTranspose(in=256, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
  (norm4_tr): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block4_tr): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv3_tr): MinkowskiConvolutionTranspose(in=256, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
  (norm3_tr): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block3_tr): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv2_tr): MinkowskiConvolutionTranspose(in=128, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
  (norm2_tr): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block2_tr): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv1_tr): MinkowskiConvolution(in=96, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
  (final): MinkowskiConvolution(in=64, out=16, region_type=RegionType.HYPERCUBE, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
)
11/02 17:11:45 Resetting the data loader seed to 0
/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/MinkowskiEngine/SparseTensor.py:260: UserWarning: Coords implicitly converted to torch.IntTensor. To remove this warning, use `.int()` to convert the coords into an torch.IntTensor
  'To remove this warning, use `.int()` to convert the ' +
/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/MinkowskiEngine/SparseTensor.py:267: UserWarning: Coords implicitly converted to CPU type. To remove this warning, use `.cpu()` to convert the coords into a CPU type
  'To remove this warning, use `.cpu()` to convert the ' +
11/02 17:18:03 Validation iter 101 / 400 : Data Loading Time: 2.147, Feature Extraction Time: 0.954, Matching Time: 0.619, Loss: 0.995, RTE: 257.727, RRE: 0.892, Hit Ratio: 0.000, Feat Match Ratio: 0.000
11/02 17:24:23 Validation iter 201 / 400 : Data Loading Time: 2.181, Feature Extraction Time: 0.954, Matching Time: 0.631, Loss: 0.990, RTE: 228.406, RRE: 0.844, Hit Ratio: 0.000, Feat Match Ratio: 0.000
11/02 17:31:11 Validation iter 301 / 400 : Data Loading Time: 2.429, Feature Extraction Time: 0.960, Matching Time: 0.641, Loss: 0.991, RTE: 222.431, RRE: 0.841, Hit Ratio: 0.000, Feat Match Ratio: 0.000
11/02 17:37:29 Final Loss: 0.992, RTE: 228.734, RRE: 0.859, Hit Ratio: 0.000, Feat Match Ratio: 0.000
/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:449: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  "please use `get_last_lr()`.", UserWarning)
11/02 17:37:30  Epoch: 1, LR: [0.1]
Traceback (most recent call last):
  File "train.py", line 84, in <module>
    main(config)
  File "train.py", line 63, in main
    trainer.train()
  File "/home/allie/code/benchmark/FCGF/lib/trainer.py", line 132, in train
    self._train_epoch(epoch)
  File "/home/allie/code/benchmark/FCGF/lib/trainer.py", line 474, in _train_epoch
    input_dict = data_loader_iter.next()
  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 435, in __next__
    data = self._next_data()
  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1085, in _next_data
    return self._process_data(data)
  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1111, in _process_data
    data.reraise()
  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/_utils.py", line 428, in reraise
    raise self.exc_type(msg)
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 198, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 47, in fetch
    return self.collate_fn(data)
  File "/home/allie/code/benchmark/FCGF/lib/data_loaders.py", line 85, in collate_pair_fn
    torch.from_numpy(np.array(matching_inds[batch_id]) + curr_start_inds))
ValueError: operands could not be broadcast together with shapes (0,) (1,2) 

Traceback (most recent call last):
  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/allie/code/benchmark/FCGF/scripts/test_kitti.py", line 144, in <module>
    main(config)
  File "/home/allie/code/benchmark/FCGF/scripts/test_kitti.py", line 27, in main
    config, config.test_phase, 1, num_threads=config.test_num_workers, shuffle=True)
AttributeError: 'EasyDict' object has no attribute 'test_num_workers'
./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-03_01-04-07
Host:  bb8
Conda  /home/allie/miniconda3/condabin/conda
/home/allie/code/benchmark/FCGF
Version:  f0863a9ba4a29f677c0ddd2248cf4e56b9318add
Git diff

diff --git a/config.py b/config.py
index 476402d..6c9fb68 100644
--- a/config.py
+++ b/config.py
@@ -94,9 +94,9 @@ misc_arg.add_argument('--weights', type=str, default=None)
 misc_arg.add_argument('--weights_dir', type=str, default=None)
 misc_arg.add_argument('--resume', type=str, default=None)
 misc_arg.add_argument('--resume_dir', type=str, default=None)
-misc_arg.add_argument('--train_num_thread', type=int, default=2)
-misc_arg.add_argument('--val_num_thread', type=int, default=1)
-misc_arg.add_argument('--test_num_thread', type=int, default=2)
+misc_arg.add_argument('--train_num_thread', type=int, default=8)#2)
+misc_arg.add_argument('--val_num_thread', type=int, default=8)
+misc_arg.add_argument('--test_num_thread', type=int, default=8)#2)
 misc_arg.add_argument('--fast_validation', type=str2bool, default=False)
 misc_arg.add_argument(
     '--nn_max_n',
@@ -112,14 +112,28 @@ data_arg.add_argument(
     '--threed_match_dir', type=str, default="/home/chrischoy/datasets/FCGF/threedmatch")
 data_arg.add_argument(
     '--kitti_root', type=str, default="/home/chrischoy/datasets/FCGF/kitti/")
+
 data_arg.add_argument(
     '--kitti_max_time_diff',
     type=int,
     default=3,
     help='max time difference between pairs (non inclusive)')
+
 data_arg.add_argument('--kitti_date', type=str, default='2011_09_26')
 
 
+#arguments for KITTI map dataset
+#for kitti ground truth poses (optimized by loop-closing SLAM)
+data_arg.add_argument(
+    '--path_cmrdata', type=str, default="/home/allie/dataset/cmr_original") 
+data_arg.add_argument(
+    '--depth_max', type=float, default=50) 
+data_arg.add_argument(
+    '--num_min_map_points', type=int, default=2e4) 
+
+
+
+
 def get_config():
   args = parser.parse_args()
   return args
diff --git a/lib/data_loaders.py b/lib/data_loaders.py
index 2bc475a..e0e264d 100644
--- a/lib/data_loaders.py
+++ b/lib/data_loaders.py
@@ -18,10 +18,42 @@ import lib.transforms as t
 import MinkowskiEngine as ME
 
 import open3d as o3d
+import pickle
 
 kitti_cache = {}
 kitti_icp_cache = {}
 
+eps = 1e-10
+import csv
+def read_csv_file(path_file):
+    lines = []
+    with open(path_file, "r") as f:
+        reader = csv.reader(f, delimiter="\t")
+        for i, line in enumerate(reader):
+            if i >= 1:
+                lines.append(np.asarray(line[0].split(',')[1:]).astype('float'))
+    return lines
+
+
+def pred_to_matrix_np(pred):
+
+    cam_T = np.tile(np.eye(4)[np.newaxis,:,:],[pred.shape[0], 1, 1])
+    cam_T[:,0:3, 3] = pred[:, 0:3]
+    s = np.tile(np.linalg.norm(pred[:,3:], axis=1)[:,np.newaxis],[1,4])
+
+    q = pred[:,3:] / (s+eps)
+
+    cam_T[:,0,0] = 1- 2*s[:,0]*(q[:,2]**2 + q[:,3]**2)
+    cam_T[:,0,1] = 2   *s[:,0]*(q[:,1] * q[:,2] - q[:,3] * q[:,0])
+    cam_T[:,0,2] = 2   *s[:,0]*(q[:,1] * q[:,3] + q[:,2] * q[:,0])
+    cam_T[:,1,0] = 2   *s[:,0]*(q[:,1]*q[:,2] + q[:,3]*q[:,0])
+    cam_T[:,1,1] = 1- 2*s[:,0]*(q[:,1]**2 + q[:,3]**2)
+    cam_T[:,1,2] = 2   *s[:,0]*(q[:,2] * q[:,3] - q[:,1] * q[:,0])
+    cam_T[:,2,0] = 2   *s[:,0]*(q[:,1] * q[:,3] - q[:,2] * q[:,0])
+    cam_T[:,2,1] = 2   *s[:,0]*(q[:,2] * q[:,3] + q[:,1] * q[:,0])
+    cam_T[:,2,2] = 1 -2*s[:,0]*(q[:,1]**2 + q[:,2]**2)
+
+    return cam_T
 
 def collate_pair_fn(list_data):
   xyz0, xyz1, coords0, coords1, feats0, feats1, matching_inds, trans = list(
@@ -48,7 +80,6 @@ def collate_pair_fn(list_data):
     xyz_batch1.append(to_tensor(xyz1[batch_id]))
 
     trans_batch.append(to_tensor(trans[batch_id]))
-
     matching_inds_batch.append(
         torch.from_numpy(np.array(matching_inds[batch_id]) + curr_start_inds))
     len_batch.append([N0, N1])
@@ -632,8 +663,231 @@ class ThreeDMatchPairDataset(IndoorPairDataset):
       'test': './config/test_3dmatch.txt'
   }
 
+class KITTIMapDataset(PairDataset):
+    AUGMENT = None
+    DATA_FILES = {
+        'train': './config/train_kitti_map.txt', #log ids
+        'val': './config/val_kitti_map.txt',
+        'test': './config/test_kitti_map.txt'
+    }
+    TEST_RANDOM_ROTATION = False
+    IS_ODOMETRY = True
+    #MAX_TIME_DIFF = 3
+
+    def __init__(self,
+               phase,
+               transform=None,
+               random_rotation=True,
+               random_scale=True,
+               manual_seed=False,
+               config=None):
+
+
+    #(self, root, split, config, input_threads=8, first_subsampling_dl=0.30):#, load_test=False):
+        
+        PairDataset.__init__(self, phase, transform, random_rotation, random_scale,
+                         manual_seed, config)
+
+        self.root = root = os.path.join(config.kitti_root, 'dataset')
+        self.split = phase
+        self.config = config
+
+        self.path_map_dict = os.path.join(root, "kitti_map_files_d3feat_%s.pkl" % self.split)
+        self.read_map_data()
+        self.prepare_kitti_ply()#split=split)
+       
+
+    def __len__(self):
+        return self.num
+
+    def read_map_data(self):
+        if os.path.exists(self.path_map_dict):
+            with open(self.path_map_dict, 'rb') as f:
+                self.dict_maps = pickle.load(f)
+            return 
+
+
+        subset_names = open(self.DATA_FILES[self.split]).read().split()
+        self.dict_maps = {}
+        for id_log in subset_names:
+            path_map = os.path.join(self.root, "kitti_maps_cmr_new", "map-%02d_0.05.ply" % (int(id_log)))
+            print("Load map : ", path_map)
+            pcd = open3d.io.read_point_cloud(path_map)
+            pcd = pcd.voxel_down_sample(self.config.first_subsampling_dl)
+            pcd, ind = pcd.remove_radius_outlier(nb_points=7, radius=self.config.first_subsampling_dl*2)
+            self.dict_maps[id_log] = torch.Tensor(np.asarray(pcd.points))#.to(self.config.device)
+
+
+        with open(self.path_map_dict, 'wb') as f: 
+            print('Saving map file to ', self.path_map_dict)
+            pickle.dump(self.dict_maps, f)
+            print('Saved!')    
+
+    def get_local_map(self,T_lidar, drive):#, force_select_points=False):
+        dist = torch.sqrt(((self.dict_maps[drive] - T_lidar[0:3,3])**2).sum(axis=1))
+        ind_valid_local = dist < self.config.depth_max
+
+        return self.dict_maps[drive][ind_valid_local]
+
+            
+    def prepare_kitti_ply(self):#, split='train'):
+        #max_time_diff = self.MAX_TIME_DIFF
+        subset_names = open(self.DATA_FILES[self.split]).read().split()
+        self.all_pos = []
+        for dirname in subset_names:
+            drive_id = int(dirname)
+            fnames = glob.glob(self.root + '/sequences/%02d/velodyne/*.bin' % drive_id)
+
+            assert len(fnames) > 0, f"Make sure that the path {self.root} has data {dirname}"
+            inames = sorted([int(os.path.split(fname)[-1][:-4]) for fname in fnames])
+            path_poses = os.path.join(self.config.path_cmrdata, self.split, "kitti-%02d.csv" % drive_id)
+            list_gt_poses = read_csv_file(path_poses)
+
+            for i in range(0,len(inames),2):# curr_time in inames:
+                
+
+                T = pred_to_matrix_np(np.asarray(list_gt_poses[i][np.newaxis,[0,1,2,6,3,4,5]]))[0]
+                xyz0 = self.get_local_map(T, dirname)
+
+                #use the local map as the source
+                T = np.linalg.inv(T) 
+                if xyz0.shape[0] < self.config.num_min_map_points:
+                    continue
+                
+                self.files.append((drive_id, inames[i]))#, next_time))
+                self.all_pos.append( torch.Tensor(T))#.to(self.config.device))
+        self.num = len(self.files)
+
+    def __getitem__(self,idx):# split, idx):
+        drive = self.files[idx][0]
+        #t0, t1 = self.files[self.split][idx][1], self.files[self.split][idx][2]
+
+        #LiDAR is the target
+        fname1 = self._get_velodyne_fn(drive,  self.files[idx][1])
+        xyzr1 = np.fromfile(fname1, dtype=np.float32).reshape(-1, 4) 
+        xyz1 = xyzr1[:, :3]
+        
+        #map is the source
+        xyz0 = self.get_local_map( np.linalg.inv(self.all_pos[idx]), str(drive))
+        trans = self.all_pos[idx]# M2
+
+        matching_search_voxel_size = self.matching_search_voxel_size
+        if self.random_scale and random.random() < 0.95:
+            scale = self.min_scale + \
+                (self.max_scale - self.min_scale) * random.random()
+            matching_search_voxel_size *= scale
+            xyz0 = scale * xyz0
+            xyz1 = scale * xyz1
+
+        # Voxelization
+        xyz0_th = xyz0#torch.from_numpy(xyz0)
+        xyz1_th = torch.from_numpy(xyz1)
+    
+        sel0 = ME.utils.sparse_quantize(xyz0_th / self.voxel_size, return_index=True)
+        sel1 = ME.utils.sparse_quantize(xyz1_th / self.voxel_size, return_index=True)
+    
+        # Make point clouds using voxelized points
+        pcd0 = make_open3d_point_cloud(xyz0[sel0])
+        pcd1 = make_open3d_point_cloud(xyz1[sel1])
+    
+        # Get matches
+        matches = get_matching_indices(pcd0, pcd1, trans, matching_search_voxel_size)
+        #if len(matches) < 1000:
+        #  raise ValueError(f"{drive}, {t0}, {t1}")
+        #matches = np.array(matches)
+
+
+        # Get features
+        npts0 = len(sel0)
+        npts1 = len(sel1)
+    
+        feats_train0, feats_train1 = [], []
+    
+        unique_xyz0_th = xyz0_th[sel0]
+        unique_xyz1_th = xyz1_th[sel1]
+    
+        feats_train0.append(torch.ones((npts0, 1)))
+        feats_train1.append(torch.ones((npts1, 1)))
+    
+        feats0 = torch.cat(feats_train0, 1)
+        feats1 = torch.cat(feats_train1, 1)
+    
+        coords0 = torch.floor(unique_xyz0_th / self.voxel_size)
+        coords1 = torch.floor(unique_xyz1_th / self.voxel_size)
+
+        #print("single batch = ")
+        #print(coords0.shape)
+        #print(coords1.shape)
+        #print(len(matches) )        
+        if False:#len(matches) < 10:#coords0.shape[0] < 10 or coords1.shape[0] < 10:
+            #print("matches shape = ", matches.shape)
+
+            print(coords0)
+#    
+#    
+            pcd_target = o3d.geometry.PointCloud()
+            pcd_target.points = o3d.utility.Vector3dVector(coords0)
+            o3d.io.write_point_cloud("coords0_before_%d.ply" % idx , pcd_target) 
+#    
+            pcd_target = o3d.geometry.PointCloud()
+            pcd_target.points = o3d.utility.Vector3dVector(coords1)
+            o3d.io.write_point_cloud("coords1_before_%d.ply" % idx, pcd_target) 
+#    
+    
+            pcd_target = o3d.geometry.PointCloud()
+            pcd_target.points = o3d.utility.Vector3dVector(unique_xyz1_th)
+            o3d.io.write_point_cloud("unique_xyz1_th_%d.ply"% idx , pcd_target) 
+#    
+    
+            pcd_target = o3d.geometry.PointCloud()
+            pcd_target.points = o3d.utility.Vector3dVector(unique_xyz0_th)
+            o3d.io.write_point_cloud("unique_xyz0_th_%d.ply"% idx , pcd_target)         
+#    
+            pcd_target = o3d.geometry.PointCloud()
+            pcd_target.points = o3d.utility.Vector3dVector(unique_xyz0_th)
+            pcd_target.transform(trans)
+    
+            o3d.io.write_point_cloud("unique_xyz0_th_trans_%d.ply" % idx, pcd_target) 
+#    
+
+            #import pdb; pdb.set_trace()
+            #pcd_target = o3d.geometry.PointCloud()
+            #pcd_target.points = o3d.utility.Vector3dVector(coords0)
+            #o3d.io.write_point_cloud("coords0.ply" , pcd_target) 
+#    
+            #pcd_target = o3d.geometry.PointCloud()
+            #pcd_target.points = o3d.utility.Vector3dVector(coords1)
+            #o3d.io.write_point_cloud("coords1.ply" , pcd_target) 
+
+
+        if self.transform: #add noises to the point clouds
+          coords0, feats0 = self.transform(coords0, feats0)
+          coords1, feats1 = self.transform(coords1, feats1)
+        
+
+        return (unique_xyz0_th.float(), unique_xyz1_th.float(), coords0.int(),
+                coords1.int(), feats0.float(), feats1.float(), matches, trans)
+
+    def _get_velodyne_fn(self, drive, t):
+        if self.IS_ODOMETRY:
+            fname = self.root + '/sequences/%02d/velodyne/%06d.bin' % (drive, t)
+        else:
+            fname = self.root + \
+                    '/' + self.date + '_drive_%04d_sync/velodyne_points/data/%010d.bin' % (
+                        drive, t)
+        return fname
+
+    #def get_position_transform(self, pos0, pos1, invert=False):
+    #    T0 = self.pos_transform(pos0)
+    #    T1 = self.pos_transform(pos1)
+    #    return (np.dot(T1, np.linalg.inv(T0)).T if not invert else np.dot(
+    #        np.linalg.inv(T1), T0).T)
+#
+
+
+
 
-ALL_DATASETS = [ThreeDMatchPairDataset, KITTIPairDataset, KITTINMPairDataset]
+ALL_DATASETS = [ThreeDMatchPairDataset, KITTIPairDataset, KITTINMPairDataset, KITTIMapDataset]
 dataset_str_mapping = {d.__name__: d for d in ALL_DATASETS}
 
 
diff --git a/lib/trainer.py b/lib/trainer.py
index e4c230b..e6299f8 100644
--- a/lib/trainer.py
+++ b/lib/trainer.py
@@ -234,12 +234,12 @@ class ContrastiveLossTrainer(AlignmentTrainer):
         # pairs consist of (xyz1 index, xyz0 index)
         sinput0 = ME.SparseTensor(
             input_dict['sinput0_F'].to(self.device),
-            coordinates=input_dict['sinput0_C'].to(self.device))
+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
         F0 = self.model(sinput0).F
 
         sinput1 = ME.SparseTensor(
             input_dict['sinput1_F'].to(self.device),
-            coordinates=input_dict['sinput1_C'].to(self.device))
+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
         F1 = self.model(sinput1).F
 
         N0, N1 = len(sinput0), len(sinput1)
@@ -316,14 +316,17 @@ class ContrastiveLossTrainer(AlignmentTrainer):
 
       # pairs consist of (xyz1 index, xyz0 index)
       feat_timer.tic()
+      
+      coords=input_dict['sinput0_C'].to(self.device)
       sinput0 = ME.SparseTensor(
           input_dict['sinput0_F'].to(self.device),
-          coordinates=input_dict['sinput0_C'].to(self.device))
+          coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
+
       F0 = self.model(sinput0).F
 
       sinput1 = ME.SparseTensor(
           input_dict['sinput1_F'].to(self.device),
-          coordinates=input_dict['sinput1_C'].to(self.device))
+          coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
       F1 = self.model(sinput1).F
       feat_timer.toc()
 
@@ -473,12 +476,12 @@ class HardestContrastiveLossTrainer(ContrastiveLossTrainer):
 
         sinput0 = ME.SparseTensor(
             input_dict['sinput0_F'].to(self.device),
-            coordinates=input_dict['sinput0_C'].to(self.device))
+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
         F0 = self.model(sinput0).F
 
         sinput1 = ME.SparseTensor(
             input_dict['sinput1_F'].to(self.device),
-            coordinates=input_dict['sinput1_C'].to(self.device))
+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
 
         F1 = self.model(sinput1).F
 
@@ -604,12 +607,12 @@ class TripletLossTrainer(ContrastiveLossTrainer):
         # pairs consist of (xyz1 index, xyz0 index)
         sinput0 = ME.SparseTensor(
             input_dict['sinput0_F'].to(self.device),
-            coordinates=input_dict['sinput0_C'].to(self.device))
+            coords=input_dict['sinput0_C'].to(self.device).type(torch.float))
         F0 = self.model(sinput0).F
 
         sinput1 = ME.SparseTensor(
             input_dict['sinput1_F'].to(self.device),
-            coordinates=input_dict['sinput1_C'].to(self.device))
+            coords=input_dict['sinput1_C'].to(self.device).type(torch.float))
         F1 = self.model(sinput1).F
 
         pos_pairs = input_dict['correspondences']
diff --git a/model/residual_block.py b/model/residual_block.py
index f06fc5a..759597f 100644
--- a/model/residual_block.py
+++ b/model/residual_block.py
@@ -29,7 +29,7 @@ class BasicBlockBase(nn.Module):
         kernel_size=3,
         stride=1,
         dilation=dilation,
-        bias=False,
+        has_bias=False,
         dimension=D)
     self.norm2 = get_norm(self.NORM_TYPE, planes, bn_momentum=bn_momentum, D=D)
     self.downsample = downsample
diff --git a/model/resunet.py b/model/resunet.py
index 6a0e2e1..eb9a4e2 100644
--- a/model/resunet.py
+++ b/model/resunet.py
@@ -34,7 +34,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=conv1_kernel_size,
         stride=1,
         dilation=1,
-        bias=False,
+        has_bias=False,
         dimension=D)
     self.norm1 = get_norm(NORM_TYPE, CHANNELS[1], bn_momentum=bn_momentum, D=D)
 
@@ -47,7 +47,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        bias=False,
+        has_bias=False,
         dimension=D)
     self.norm2 = get_norm(NORM_TYPE, CHANNELS[2], bn_momentum=bn_momentum, D=D)
 
@@ -60,7 +60,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        bias=False,
+        has_bias=False,
         dimension=D)
     self.norm3 = get_norm(NORM_TYPE, CHANNELS[3], bn_momentum=bn_momentum, D=D)
 
@@ -73,7 +73,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        bias=False,
+        has_bias=False,
         dimension=D)
     self.norm4 = get_norm(NORM_TYPE, CHANNELS[4], bn_momentum=bn_momentum, D=D)
 
@@ -86,7 +86,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        bias=False,
+        has_bias=False,
         dimension=D)
     self.norm4_tr = get_norm(NORM_TYPE, TR_CHANNELS[4], bn_momentum=bn_momentum, D=D)
 
@@ -99,7 +99,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        bias=False,
+        has_bias=False,
         dimension=D)
     self.norm3_tr = get_norm(NORM_TYPE, TR_CHANNELS[3], bn_momentum=bn_momentum, D=D)
 
@@ -112,7 +112,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        bias=False,
+        has_bias=False,
         dimension=D)
     self.norm2_tr = get_norm(NORM_TYPE, TR_CHANNELS[2], bn_momentum=bn_momentum, D=D)
 
@@ -125,7 +125,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        bias=False,
+        has_bias=False,
         dimension=D)
 
     # self.block1_tr = BasicBlockBN(TR_CHANNELS[1], TR_CHANNELS[1], bn_momentum=bn_momentum, D=D)
@@ -136,7 +136,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        bias=True,
+        has_bias=True,
         dimension=D)
 
   def forward(self, x):
@@ -187,8 +187,8 @@ class ResUNet2(ME.MinkowskiNetwork):
     if self.normalize_feature:
       return ME.SparseTensor(
           out.F / torch.norm(out.F, p=2, dim=1, keepdim=True),
-          coordinate_map_key=out.coordinate_map_key,
-          coordinate_manager=out.coordinate_manager)
+          coords_key=out.coords_key,#out.coordinate_map_key,
+          coords_manager=out.coords_man)#out.coordinate_manager)
     else:
       return out
 
@@ -244,3 +244,8 @@ class ResUNetIN2D(ResUNetBN2D):
 class ResUNetIN2E(ResUNetBN2E):
   NORM_TYPE = 'BN'
   BLOCK_NORM_TYPE = 'IN'
+
+class ResUNetBN2C(ResUNet2):
+  NORM_TYPE = 'BN'
+  CHANNELS = [None, 32, 64, 128, 256]
+  TR_CHANNELS = [None, 64, 64, 64, 128]
\ No newline at end of file
diff --git a/scripts/train_fcgf_kitti.sh b/scripts/train_fcgf_kitti.sh
index de073fd..64a0e8e 100755
--- a/scripts/train_fcgf_kitti.sh
+++ b/scripts/train_fcgf_kitti.sh
@@ -3,20 +3,20 @@ export PATH_POSTFIX=$1
 export MISC_ARGS=$2
 
 export DATA_ROOT="./outputs/Experiments"
-export DATASET=${DATASET:-KITTINMPairDataset}
+export DATASET=${DATASET:-KITTIMapDataset} #KITTINMPairDataset}
 export TRAINER=${TRAINER:-HardestContrastiveLossTrainer}
 export MODEL=${MODEL:-ResUNetBN2C}
 export MODEL_N_OUT=${MODEL_N_OUT:-16}
 export OPTIMIZER=${OPTIMIZER:-SGD}
 export LR=${LR:-1e-1}
 export MAX_EPOCH=${MAX_EPOCH:-200}
-export BATCH_SIZE=${BATCH_SIZE:-8}
+export BATCH_SIZE=${BATCH_SIZE:-6}
 export ITER_SIZE=${ITER_SIZE:-1}
 export VOXEL_SIZE=${VOXEL_SIZE:-0.3}
 export POSITIVE_PAIR_SEARCH_VOXEL_SIZE_MULTIPLIER=${POSITIVE_PAIR_SEARCH_VOXEL_SIZE_MULTIPLIER:-1.5}
 export CONV1_KERNEL_SIZE=${CONV1_KERNEL_SIZE:-5}
 export EXP_GAMMA=${EXP_GAMMA:-0.99}
-export RANDOM_SCALE=${RANDOM_SCALE:-True}
+export RANDOM_SCALE=${RANDOM_SCALE:-False} #scale doesn't work for the local map
 export TIME=$(date +"%Y-%m-%d_%H-%M-%S")
 export KITTI_PATH=${KITTI_PATH:-/home/chrischoy/datasets/KITTI_FCGF}
 export VERSION=$(git rev-parse HEAD)

Tue Nov  3 01:04:07 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX TIT...  On   | 00000000:05:00.0 Off |                  N/A |
| 50%   83C    P2   139W / 250W |  12207MiB / 12211MiB |     93%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX TIT...  On   | 00000000:06:00.0 Off |                  N/A |
| 27%   65C    P8    17W / 250W |     11MiB / 12212MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX TIT...  On   | 00000000:09:00.0 Off |                  N/A |
| 52%   83C    P2   102W / 250W |   9539MiB / 12212MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  GeForce GTX TIT...  On   | 00000000:0A:00.0 Off |                  N/A |
| 40%   77C    P5    25W / 250W |     11MiB / 12212MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      4990      C   python3                                    12196MiB |
|    2     14147      C   python3                                     9528MiB |
+-----------------------------------------------------------------------------+
11/03 01:04:09 ===> Configurations
11/03 01:04:09     out_dir: ./outputs/Experiments/KITTIMapDataset-v0.3/HardestContrastiveLossTrainer/ResUNetBN2C/SGD-lr1e-1-e200-b6i1-modelnout16/2020-11-03_01-04-07
11/03 01:04:09     trainer: HardestContrastiveLossTrainer
11/03 01:04:09     save_freq_epoch: 1
11/03 01:04:09     batch_size: 6
11/03 01:04:09     val_batch_size: 1
11/03 01:04:09     use_hard_negative: True
11/03 01:04:09     hard_negative_sample_ratio: 0.05
11/03 01:04:09     hard_negative_max_num: 3000
11/03 01:04:09     num_pos_per_batch: 1024
11/03 01:04:09     num_hn_samples_per_batch: 256
11/03 01:04:09     neg_thresh: 1.4
11/03 01:04:09     pos_thresh: 0.1
11/03 01:04:09     neg_weight: 1
11/03 01:04:09     use_random_scale: False
11/03 01:04:09     min_scale: 0.8
11/03 01:04:09     max_scale: 1.2
11/03 01:04:09     use_random_rotation: True
11/03 01:04:09     rotation_range: 360
11/03 01:04:09     train_phase: train
11/03 01:04:09     val_phase: val
11/03 01:04:09     test_phase: test
11/03 01:04:09     stat_freq: 40
11/03 01:04:09     test_valid: True
11/03 01:04:09     val_max_iter: 400
11/03 01:04:09     val_epoch_freq: 1
11/03 01:04:09     positive_pair_search_voxel_size_multiplier: 1.5
11/03 01:04:09     hit_ratio_thresh: 0.3
11/03 01:04:09     triplet_num_pos: 256
11/03 01:04:09     triplet_num_hn: 512
11/03 01:04:09     triplet_num_rand: 1024
11/03 01:04:09     model: ResUNetBN2C
11/03 01:04:09     model_n_out: 16
11/03 01:04:09     conv1_kernel_size: 5
11/03 01:04:09     normalize_feature: True
11/03 01:04:09     dist_type: L2
11/03 01:04:09     best_val_metric: feat_match_ratio
11/03 01:04:09     optimizer: SGD
11/03 01:04:09     max_epoch: 200
11/03 01:04:09     lr: 0.1
11/03 01:04:09     momentum: 0.8
11/03 01:04:09     sgd_momentum: 0.9
11/03 01:04:09     sgd_dampening: 0.1
11/03 01:04:09     adam_beta1: 0.9
11/03 01:04:09     adam_beta2: 0.999
11/03 01:04:09     weight_decay: 0.0001
11/03 01:04:09     iter_size: 1
11/03 01:04:09     bn_momentum: 0.05
11/03 01:04:09     exp_gamma: 0.99
11/03 01:04:09     scheduler: ExpLR
11/03 01:04:09     icp_cache_path: /home/chrischoy/datasets/FCGF/kitti/icp/
11/03 01:04:09     use_gpu: True
11/03 01:04:09     weights: None
11/03 01:04:09     weights_dir: None
11/03 01:04:09     resume: None
11/03 01:04:09     resume_dir: None
11/03 01:04:09     train_num_thread: 8
11/03 01:04:09     val_num_thread: 8
11/03 01:04:09     test_num_thread: 8
11/03 01:04:09     fast_validation: False
11/03 01:04:09     nn_max_n: 500
11/03 01:04:09     dataset: KITTIMapDataset
11/03 01:04:09     voxel_size: 0.3
11/03 01:04:09     threed_match_dir: /home/chrischoy/datasets/FCGF/threedmatch
11/03 01:04:09     kitti_root: /home/allie/dataset/kitti_odometry/
11/03 01:04:09     kitti_max_time_diff: 3
11/03 01:04:09     kitti_date: 2011_09_26
11/03 01:04:09     path_cmrdata: /home/allie/dataset/cmr_original
11/03 01:04:09     depth_max: 50
11/03 01:04:09     num_min_map_points: 20000.0
11/03 01:06:57 ResUNetBN2C(
  (conv1): MinkowskiConvolution(in=1, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])
  (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block1): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=32, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=32, out=32, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv2): MinkowskiConvolution(in=32, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
  (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block2): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv3): MinkowskiConvolution(in=64, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
  (norm3): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block3): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv4): MinkowskiConvolution(in=128, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
  (norm4): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block4): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=256, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=256, out=256, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv4_tr): MinkowskiConvolutionTranspose(in=256, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
  (norm4_tr): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block4_tr): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=128, out=128, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv3_tr): MinkowskiConvolutionTranspose(in=256, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
  (norm3_tr): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block3_tr): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv2_tr): MinkowskiConvolutionTranspose(in=128, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[2, 2, 2], dilation=[1, 1, 1])
  (norm2_tr): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (block2_tr): BasicBlockBN(
    (conv1): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (conv2): MinkowskiConvolution(in=64, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])
    (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  )
  (conv1_tr): MinkowskiConvolution(in=96, out=64, region_type=RegionType.HYPERCUBE, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
  (final): MinkowskiConvolution(in=64, out=16, region_type=RegionType.HYPERCUBE, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])
)
11/03 01:07:00 Resetting the data loader seed to 0
/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/MinkowskiEngine/SparseTensor.py:260: UserWarning: Coords implicitly converted to torch.IntTensor. To remove this warning, use `.int()` to convert the coords into an torch.IntTensor
  'To remove this warning, use `.int()` to convert the ' +
/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/MinkowskiEngine/SparseTensor.py:267: UserWarning: Coords implicitly converted to CPU type. To remove this warning, use `.cpu()` to convert the coords into a CPU type
  'To remove this warning, use `.cpu()` to convert the ' +
11/03 01:10:36 Validation iter 101 / 400 : Data Loading Time: 0.062, Feature Extraction Time: 1.172, Matching Time: 0.883, Loss: 0.999, RTE: 250.249, RRE: 0.855, Hit Ratio: 0.000, Feat Match Ratio: 0.000
11/03 01:14:04 Validation iter 201 / 400 : Data Loading Time: 0.014, Feature Extraction Time: 1.170, Matching Time: 0.879, Loss: 0.998, RTE: 222.577, RRE: 0.821, Hit Ratio: 0.000, Feat Match Ratio: 0.000
11/03 01:17:31 Validation iter 301 / 400 : Data Loading Time: 0.017, Feature Extraction Time: 1.159, Matching Time: 0.880, Loss: 0.995, RTE: 217.632, RRE: 0.824, Hit Ratio: 0.000, Feat Match Ratio: 0.000
11/03 01:20:47 Final Loss: 0.995, RTE: 224.363, RRE: 0.844, Hit Ratio: 0.000, Feat Match Ratio: 0.000
/home/allie/miniconda3/envs/py3-fcgf/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:449: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  "please use `get_last_lr()`.", UserWarning)
11/03 01:20:47  Epoch: 1, LR: [0.1]
11/03 01:21:22 Train Epoch: 1 [0/477], Current Loss: 1.704e+00 Pos: 0.724 Neg: 0.980	Data time: 26.4148, Train time: 8.3080, Iter time: 34.7228
11/03 01:26:58 Train Epoch: 1 [40/477], Current Loss: 1.344e+00 Pos: 0.288 Neg: 1.057	Data time: 0.1094, Train time: 8.2677, Iter time: 8.3771
